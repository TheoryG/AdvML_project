{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16 6.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"hn2cCFn00Jzn","colab_type":"code","outputId":"a99f67e4-adbe-4ff6-cba0-03d0c7ca3202","executionInfo":{"status":"ok","timestamp":1544908150630,"user_tz":300,"elapsed":72136,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 110377 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"UnT8hnZn0bew","colab_type":"code","outputId":"f68dda96-75be-46b2-cc60-a980e4098d94","executionInfo":{"status":"ok","timestamp":1544908156497,"user_tz":300,"elapsed":3937,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["!mkdir drive\n","!google-drive-ocamlfuse drive\n","!ls drive/DL1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'16 6.ipynb'   w_resnet   wresnet.h5\n"],"name":"stdout"}]},{"metadata":{"id":"3fAYXLAO0cME","colab_type":"code","outputId":"d2032767-8bd0-4c5e-9778-208af3a52324","executionInfo":{"status":"ok","timestamp":1544839937891,"user_tz":300,"elapsed":821,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["cd /content/drive/DL1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/DL1\n"],"name":"stdout"}]},{"metadata":{"id":"u9QdKQT90duK","colab_type":"code","outputId":"7915e409-e114-476e-c3a6-7504213ca241","executionInfo":{"status":"ok","timestamp":1544857203827,"user_tz":300,"elapsed":17259167,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":9315}},"cell_type":"code","source":["import keras\n","import numpy as np\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers import Conv2D, Dense, Input, add, Activation, Flatten, AveragePooling2D\n","from keras.callbacks import LearningRateScheduler, TensorBoard\n","from keras.regularizers import l2\n","from keras import optimizers\n","from keras.models import Model\n","\n","\n","## Build a Wide Residual Network with Depth = 16 and Wide = 6\n","DEPTH              = 16\n","WIDE               = 6\n","\n","IN_FILTERS         = 16\n","\n","CLASS_NUM          = 10\n","IMG_ROWS, IMG_COLS = 32, 32\n","IMG_CHANNELS       = 3\n","\n","BATCH_SIZE         = 128\n","EPOCHS             = 200\n","ITERATIONS         = 30000 // BATCH_SIZE + 1\n","WEIGHT_DECAY       = 0.0005\n","LOG_FILE_PATH      = './w_resnet/'\n","\n","\n","from keras import backend as K\n","# set up the GPU memory \n","\n","\n","if('tensorflow' == K.backend()):\n","    import tensorflow as tf\n","    from keras.backend.tensorflow_backend import set_session\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    sess = tf.Session(config=config)\n","\n","def scheduler(epoch):\n","    if epoch < 60:\n","        return 0.1\n","    if epoch < 120:\n","        return 0.02\n","    if epoch < 160:\n","        return 0.004\n","    return 0.0008\n","\n","def color_preprocessing(x_train,x_test):\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    mean = [125.3, 123.0, 113.9]\n","    std  = [63.0,  62.1,  66.7]\n","    for i in range(3):\n","        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n","        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n","\n","    return x_train, x_test\n","\n","  \n","## Determine the structure for Wide residual network\n","\n","def wide_residual_network(img_input,classes_num,depth,k):\n","    print('Wide-Resnet %dx%d' %(depth, k))\n","    n_filters  = [16, 16*k, 32*k, 64*k]\n","    n_stack    = (depth - 4) // 6\n","\n","    def conv3x3(x,filters):\n","        return Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1), padding='same',\n","        kernel_initializer='he_normal',\n","        kernel_regularizer=l2(WEIGHT_DECAY),\n","        use_bias=False)(x)\n","\n","    def bn_relu(x):\n","        x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n","        x = Activation('relu')(x)\n","        return x\n","\n","    def residual_block(x,out_filters,increase=False):\n","        global IN_FILTERS\n","        stride = (1,1)\n","        if increase:\n","            stride = (2,2)\n","            \n","        o1 = bn_relu(x)\n","        \n","        conv_1 = Conv2D(out_filters,\n","            kernel_size=(3,3),strides=stride,padding='same',\n","            kernel_initializer='he_normal',\n","            kernel_regularizer=l2(WEIGHT_DECAY),\n","            use_bias=False)(o1)\n","\n","        o2 = bn_relu(conv_1)\n","        \n","        conv_2 = Conv2D(out_filters, \n","            kernel_size=(3,3), strides=(1,1), padding='same',\n","            kernel_initializer='he_normal',\n","            kernel_regularizer=l2(WEIGHT_DECAY),\n","            use_bias=False)(o2)\n","        if increase or IN_FILTERS != out_filters:\n","            proj = Conv2D(out_filters,\n","                                kernel_size=(1,1),strides=stride,padding='same',\n","                                kernel_initializer='he_normal',\n","                                kernel_regularizer=l2(WEIGHT_DECAY),\n","                                use_bias=False)(o1)\n","            block = add([conv_2, proj])\n","        else:\n","            block = add([conv_2,x])\n","        return block\n","\n","    def wide_residual_layer(x,out_filters,increase=False):\n","        global IN_FILTERS\n","        x = residual_block(x,out_filters,increase)\n","        IN_FILTERS = out_filters\n","        for _ in range(1,int(n_stack)):\n","            x = residual_block(x,out_filters)\n","        return x\n","\n","\n","    x = conv3x3(img_input,n_filters[0])\n","    x = wide_residual_layer(x,n_filters[1])\n","    x = wide_residual_layer(x,n_filters[2],increase=True)\n","    x = wide_residual_layer(x,n_filters[3],increase=True)\n","    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = AveragePooling2D((8,8))(x)\n","    x = Flatten()(x)\n","    x = Dense(classes_num,\n","        activation='softmax',\n","        kernel_initializer='he_normal',\n","        kernel_regularizer=l2(WEIGHT_DECAY),\n","        use_bias=False)(x)\n","    return x\n","\n","if __name__ == '__main__':\n","\n","    # load data\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","    y_train = keras.utils.to_categorical(y_train, CLASS_NUM)\n","    y_test = keras.utils.to_categorical(y_test, CLASS_NUM)\n","    \n","    # color preprocessing\n","    x_train, x_test = color_preprocessing(x_train, x_test)\n","\n","    # build network\n","    img_input = Input(shape=(IMG_ROWS,IMG_COLS,IMG_CHANNELS))\n","    output = wide_residual_network(img_input,CLASS_NUM,DEPTH,WIDE)\n","    resnet = Model(img_input, output)\n","    print(resnet.summary())\n","    # set optimizer\n","    sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n","    resnet.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","    # set callback\n","    tb_cb = TensorBoard(log_dir=LOG_FILE_PATH, histogram_freq=0)\n","    change_lr = LearningRateScheduler(scheduler)\n","    cbks = [change_lr,tb_cb]\n","\n","    # set data augmentation\n","    print('Using real-time data augmentation.')\n","    datagen = ImageDataGenerator(horizontal_flip=True,\n","            width_shift_range=0.125,height_shift_range=0.125,fill_mode='reflect')\n","\n","    datagen.fit(x_train)\n","\n","    # start training\n","    resnet.fit_generator(datagen.flow(x_train, y_train,batch_size=BATCH_SIZE),\n","                        steps_per_epoch=ITERATIONS,\n","                        epochs=EPOCHS,\n","                        callbacks=cbks,\n","                        validation_data=(x_test, y_test))\n","    resnet.save('wresnet.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 33s 0us/step\n","Wide-Resnet 16x6\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 16)   432         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 96)   13824       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 96)   384         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 96)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 96)   82944       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 96)   1536        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 32, 32, 96)   0           conv2d_3[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 96)   384         add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 96)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 96)   82944       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 96)   384         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 96)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 96)   82944       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 32, 32, 96)   0           conv2d_6[0][0]                   \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 96)   384         add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 96)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 192)  165888      activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 192)  768         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 16, 16, 192)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 192)  331776      activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 16, 16, 192)  18432       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 16, 16, 192)  0           conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 16, 16, 192)  768         add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 16, 16, 192)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 16, 16, 192)  331776      activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 16, 16, 192)  768         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 16, 16, 192)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 16, 16, 192)  331776      activation_8[0][0]               \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 16, 16, 192)  0           conv2d_11[0][0]                  \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 16, 16, 192)  768         add_4[0][0]                      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 16, 16, 192)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 8, 8, 384)    663552      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 8, 8, 384)    1536        conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 8, 8, 384)    0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 8, 8, 384)    1327104     activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 8, 8, 384)    73728       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 8, 8, 384)    0           conv2d_13[0][0]                  \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 8, 8, 384)    1536        add_5[0][0]                      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 8, 8, 384)    0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 8, 8, 384)    1327104     activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 8, 8, 384)    1536        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 8, 8, 384)    0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 8, 8, 384)    1327104     activation_12[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 8, 8, 384)    0           conv2d_16[0][0]                  \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 8, 8, 384)    1536        add_6[0][0]                      \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 8, 8, 384)    0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 1, 1, 384)    0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 384)          0           average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 10)           3840        flatten_1[0][0]                  \n","==================================================================================================\n","Total params: 6,177,520\n","Trainable params: 6,172,112\n","Non-trainable params: 5,408\n","__________________________________________________________________________________________________\n","None\n","Using real-time data augmentation.\n","Epoch 1/200\n","235/235 [==============================] - 92s 391ms/step - loss: 4.2183 - acc: 0.4767 - val_loss: 3.4810 - val_acc: 0.5828\n","Epoch 2/200\n","235/235 [==============================] - 86s 368ms/step - loss: 2.8600 - acc: 0.6390 - val_loss: 2.5304 - val_acc: 0.6535\n","Epoch 3/200\n","235/235 [==============================] - 85s 364ms/step - loss: 2.0929 - acc: 0.7036 - val_loss: 2.7678 - val_acc: 0.5532\n","Epoch 4/200\n","235/235 [==============================] - 85s 364ms/step - loss: 1.6342 - acc: 0.7422 - val_loss: 1.4413 - val_acc: 0.7682\n","Epoch 5/200\n","235/235 [==============================] - 85s 364ms/step - loss: 1.3538 - acc: 0.7669 - val_loss: 1.5853 - val_acc: 0.6841\n","Epoch 6/200\n","235/235 [==============================] - 86s 364ms/step - loss: 1.1766 - acc: 0.7794 - val_loss: 1.3073 - val_acc: 0.7233\n","Epoch 7/200\n","235/235 [==============================] - 86s 364ms/step - loss: 1.0499 - acc: 0.7927 - val_loss: 1.1398 - val_acc: 0.7645\n","Epoch 8/200\n","235/235 [==============================] - 86s 364ms/step - loss: 0.9863 - acc: 0.7998 - val_loss: 1.3715 - val_acc: 0.7083\n","Epoch 9/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.9313 - acc: 0.8098 - val_loss: 1.2154 - val_acc: 0.7455\n","Epoch 10/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.9156 - acc: 0.8106 - val_loss: 1.1704 - val_acc: 0.7536\n","Epoch 11/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.8661 - acc: 0.8244 - val_loss: 1.1510 - val_acc: 0.7523\n","Epoch 12/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8795 - acc: 0.8195 - val_loss: 1.0277 - val_acc: 0.7783\n","Epoch 13/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.8549 - acc: 0.8284 - val_loss: 1.1134 - val_acc: 0.7651\n","Epoch 14/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8416 - acc: 0.8352 - val_loss: 1.2290 - val_acc: 0.7228\n","Epoch 15/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8421 - acc: 0.8369 - val_loss: 0.9408 - val_acc: 0.8033\n","Epoch 16/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8352 - acc: 0.8380 - val_loss: 0.9534 - val_acc: 0.8027\n","Epoch 17/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8432 - acc: 0.8367 - val_loss: 0.9917 - val_acc: 0.8037\n","Epoch 18/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.8305 - acc: 0.8440 - val_loss: 0.8385 - val_acc: 0.8424\n","Epoch 19/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.8293 - acc: 0.8452 - val_loss: 1.3316 - val_acc: 0.7038\n","Epoch 20/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8478 - acc: 0.8447 - val_loss: 1.1888 - val_acc: 0.7642\n","Epoch 21/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8369 - acc: 0.8452 - val_loss: 0.9804 - val_acc: 0.8042\n","Epoch 22/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8202 - acc: 0.8557 - val_loss: 0.9539 - val_acc: 0.8166\n","Epoch 23/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8377 - acc: 0.8480 - val_loss: 1.1354 - val_acc: 0.7677\n","Epoch 24/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8257 - acc: 0.8573 - val_loss: 1.0965 - val_acc: 0.7717\n","Epoch 25/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8436 - acc: 0.8514 - val_loss: 0.8958 - val_acc: 0.8329\n","Epoch 26/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8314 - acc: 0.8570 - val_loss: 1.1401 - val_acc: 0.7817\n","Epoch 27/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8257 - acc: 0.8590 - val_loss: 1.0711 - val_acc: 0.7843\n","Epoch 28/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8469 - acc: 0.8546 - val_loss: 0.9064 - val_acc: 0.8277\n","Epoch 29/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8296 - acc: 0.8593 - val_loss: 1.0292 - val_acc: 0.7968\n","Epoch 30/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8506 - acc: 0.8546 - val_loss: 0.9461 - val_acc: 0.8323\n","Epoch 31/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8414 - acc: 0.8605 - val_loss: 0.9442 - val_acc: 0.8325\n","Epoch 32/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8452 - acc: 0.8594 - val_loss: 0.9432 - val_acc: 0.8328\n","Epoch 33/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8502 - acc: 0.8569 - val_loss: 1.1096 - val_acc: 0.7932\n","Epoch 34/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8418 - acc: 0.8620 - val_loss: 1.1070 - val_acc: 0.7711\n","Epoch 35/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8513 - acc: 0.8625 - val_loss: 1.2702 - val_acc: 0.7363\n","Epoch 36/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8515 - acc: 0.8619 - val_loss: 1.1208 - val_acc: 0.7876\n","Epoch 37/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8407 - acc: 0.8653 - val_loss: 1.2005 - val_acc: 0.7744\n","Epoch 38/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8573 - acc: 0.8603 - val_loss: 1.0689 - val_acc: 0.8037\n","Epoch 39/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8465 - acc: 0.8651 - val_loss: 1.2880 - val_acc: 0.7526\n","Epoch 40/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8581 - acc: 0.8609 - val_loss: 0.9556 - val_acc: 0.8278\n","Epoch 41/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8519 - acc: 0.8671 - val_loss: 0.9482 - val_acc: 0.8392\n","Epoch 42/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8626 - acc: 0.8627 - val_loss: 1.1506 - val_acc: 0.7848\n","Epoch 43/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8527 - acc: 0.8656 - val_loss: 1.0029 - val_acc: 0.8252\n","Epoch 44/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8533 - acc: 0.8665 - val_loss: 1.0655 - val_acc: 0.8099\n","Epoch 45/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8692 - acc: 0.8637 - val_loss: 1.0538 - val_acc: 0.8156\n","Epoch 46/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8499 - acc: 0.8689 - val_loss: 0.9927 - val_acc: 0.8258\n","Epoch 47/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8585 - acc: 0.8667 - val_loss: 0.9716 - val_acc: 0.8378\n","Epoch 48/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8546 - acc: 0.8722 - val_loss: 0.9932 - val_acc: 0.8243\n","Epoch 49/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8674 - acc: 0.8661 - val_loss: 1.0757 - val_acc: 0.8072\n","Epoch 50/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8734 - acc: 0.8674 - val_loss: 0.9632 - val_acc: 0.8439\n","Epoch 51/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8601 - acc: 0.8710 - val_loss: 1.3113 - val_acc: 0.7609\n","Epoch 52/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8628 - acc: 0.8685 - val_loss: 1.0995 - val_acc: 0.8077\n","Epoch 53/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8764 - acc: 0.8665 - val_loss: 1.1305 - val_acc: 0.7953\n","Epoch 54/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8614 - acc: 0.8739 - val_loss: 1.1314 - val_acc: 0.7866\n","Epoch 55/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8759 - acc: 0.8693 - val_loss: 0.9914 - val_acc: 0.8312\n","Epoch 56/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8673 - acc: 0.8727 - val_loss: 1.1983 - val_acc: 0.7707\n","Epoch 57/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8765 - acc: 0.8701 - val_loss: 0.9861 - val_acc: 0.8340\n","Epoch 58/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8763 - acc: 0.8683 - val_loss: 1.0066 - val_acc: 0.8325\n","Epoch 59/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.8680 - acc: 0.8732 - val_loss: 1.0379 - val_acc: 0.8278\n","Epoch 60/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.8845 - acc: 0.8699 - val_loss: 1.0637 - val_acc: 0.8225\n","Epoch 61/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.7334 - acc: 0.9150 - val_loss: 0.7338 - val_acc: 0.9124\n","Epoch 62/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.6388 - acc: 0.9362 - val_loss: 0.6761 - val_acc: 0.9178\n","Epoch 63/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.5843 - acc: 0.9444 - val_loss: 0.6703 - val_acc: 0.9111\n","Epoch 64/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.5433 - acc: 0.9469 - val_loss: 0.6223 - val_acc: 0.9181\n","Epoch 65/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.5175 - acc: 0.9491 - val_loss: 0.6099 - val_acc: 0.9161\n","Epoch 66/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4805 - acc: 0.9541 - val_loss: 0.5964 - val_acc: 0.9138\n","Epoch 67/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4670 - acc: 0.9521 - val_loss: 0.5746 - val_acc: 0.9182\n","Epoch 68/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4521 - acc: 0.9520 - val_loss: 0.6213 - val_acc: 0.9015\n","Epoch 69/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4339 - acc: 0.9541 - val_loss: 0.5519 - val_acc: 0.9157\n","Epoch 70/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4353 - acc: 0.9510 - val_loss: 0.5548 - val_acc: 0.9146\n","Epoch 71/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4149 - acc: 0.9549 - val_loss: 0.6134 - val_acc: 0.8953\n","Epoch 72/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4202 - acc: 0.9515 - val_loss: 0.5879 - val_acc: 0.9005\n","Epoch 73/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4046 - acc: 0.9533 - val_loss: 0.5776 - val_acc: 0.9011\n","Epoch 74/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4073 - acc: 0.9525 - val_loss: 0.6060 - val_acc: 0.8991\n","Epoch 75/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4180 - acc: 0.9495 - val_loss: 0.5632 - val_acc: 0.9042\n","Epoch 76/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4055 - acc: 0.9510 - val_loss: 0.5678 - val_acc: 0.9038\n","Epoch 77/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4126 - acc: 0.9493 - val_loss: 0.5475 - val_acc: 0.9112\n","Epoch 78/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4101 - acc: 0.9501 - val_loss: 0.5941 - val_acc: 0.8966\n","Epoch 79/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4015 - acc: 0.9517 - val_loss: 0.5740 - val_acc: 0.9051\n","Epoch 80/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4052 - acc: 0.9501 - val_loss: 0.5548 - val_acc: 0.9108\n","Epoch 81/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4041 - acc: 0.9523 - val_loss: 0.6004 - val_acc: 0.8999\n","Epoch 82/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4062 - acc: 0.9517 - val_loss: 0.5984 - val_acc: 0.8984\n","Epoch 83/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4093 - acc: 0.9491 - val_loss: 0.5664 - val_acc: 0.9030\n","Epoch 84/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.3951 - acc: 0.9545 - val_loss: 0.5828 - val_acc: 0.9051\n","Epoch 85/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4066 - acc: 0.9526 - val_loss: 0.5773 - val_acc: 0.9005\n","Epoch 86/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4058 - acc: 0.9513 - val_loss: 0.5964 - val_acc: 0.8962\n","Epoch 87/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4032 - acc: 0.9537 - val_loss: 0.6660 - val_acc: 0.8794\n","Epoch 88/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4137 - acc: 0.9525 - val_loss: 0.6216 - val_acc: 0.8949\n","Epoch 89/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4014 - acc: 0.9548 - val_loss: 0.5548 - val_acc: 0.9093\n","Epoch 90/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4084 - acc: 0.9534 - val_loss: 0.5578 - val_acc: 0.9103\n","Epoch 91/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4017 - acc: 0.9558 - val_loss: 0.5841 - val_acc: 0.9051\n","Epoch 92/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4000 - acc: 0.9569 - val_loss: 0.5950 - val_acc: 0.9032\n","Epoch 93/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4164 - acc: 0.9511 - val_loss: 0.6015 - val_acc: 0.8973\n","Epoch 94/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4028 - acc: 0.9574 - val_loss: 0.5831 - val_acc: 0.9081\n","Epoch 95/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4126 - acc: 0.9534 - val_loss: 0.5980 - val_acc: 0.9012\n","Epoch 96/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4063 - acc: 0.9567 - val_loss: 0.5697 - val_acc: 0.9094\n","Epoch 97/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4005 - acc: 0.9590 - val_loss: 0.5562 - val_acc: 0.9141\n","Epoch 98/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4143 - acc: 0.9544 - val_loss: 0.5851 - val_acc: 0.9041\n","Epoch 99/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4044 - acc: 0.9583 - val_loss: 0.6142 - val_acc: 0.8974\n","Epoch 100/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4183 - acc: 0.9536 - val_loss: 0.5825 - val_acc: 0.9069\n","Epoch 101/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4093 - acc: 0.9566 - val_loss: 0.5799 - val_acc: 0.9084\n","Epoch 102/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4039 - acc: 0.9589 - val_loss: 0.6158 - val_acc: 0.9028\n","Epoch 103/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4161 - acc: 0.9549 - val_loss: 0.6044 - val_acc: 0.9010\n","Epoch 104/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4028 - acc: 0.9597 - val_loss: 0.5985 - val_acc: 0.9026\n","Epoch 105/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4132 - acc: 0.9567 - val_loss: 0.5942 - val_acc: 0.9065\n","Epoch 106/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4080 - acc: 0.9587 - val_loss: 0.5860 - val_acc: 0.9060\n","Epoch 107/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4147 - acc: 0.9558 - val_loss: 0.6033 - val_acc: 0.9016\n","Epoch 108/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4165 - acc: 0.9545 - val_loss: 0.5879 - val_acc: 0.9090\n","Epoch 109/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4080 - acc: 0.9595 - val_loss: 0.5765 - val_acc: 0.9120\n","Epoch 110/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4126 - acc: 0.9587 - val_loss: 0.6052 - val_acc: 0.9049\n","Epoch 111/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4098 - acc: 0.9599 - val_loss: 0.6535 - val_acc: 0.8918\n","Epoch 112/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4111 - acc: 0.9602 - val_loss: 0.5592 - val_acc: 0.9161\n","Epoch 113/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4181 - acc: 0.9571 - val_loss: 0.6098 - val_acc: 0.9039\n","Epoch 114/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4100 - acc: 0.9604 - val_loss: 0.5948 - val_acc: 0.9094\n","Epoch 115/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4226 - acc: 0.9551 - val_loss: 0.5724 - val_acc: 0.9128\n","Epoch 116/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4097 - acc: 0.9601 - val_loss: 0.5970 - val_acc: 0.9076\n","Epoch 117/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4128 - acc: 0.9597 - val_loss: 0.5843 - val_acc: 0.9099\n","Epoch 118/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.4149 - acc: 0.9588 - val_loss: 0.5908 - val_acc: 0.9070\n","Epoch 119/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4055 - acc: 0.9610 - val_loss: 0.6122 - val_acc: 0.9053\n","Epoch 120/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.4148 - acc: 0.9577 - val_loss: 0.6015 - val_acc: 0.9104\n","Epoch 121/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.3624 - acc: 0.9777 - val_loss: 0.5033 - val_acc: 0.9329\n","Epoch 122/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.3306 - acc: 0.9876 - val_loss: 0.4910 - val_acc: 0.9375\n","Epoch 123/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.3170 - acc: 0.9907 - val_loss: 0.4823 - val_acc: 0.9380\n","Epoch 124/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.3051 - acc: 0.9936 - val_loss: 0.4805 - val_acc: 0.9396\n","Epoch 125/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2998 - acc: 0.9935 - val_loss: 0.4699 - val_acc: 0.9393\n","Epoch 126/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2909 - acc: 0.9948 - val_loss: 0.4654 - val_acc: 0.9392\n","Epoch 127/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2849 - acc: 0.9958 - val_loss: 0.4622 - val_acc: 0.9405\n","Epoch 128/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.2781 - acc: 0.9961 - val_loss: 0.4522 - val_acc: 0.9416\n","Epoch 129/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2714 - acc: 0.9967 - val_loss: 0.4569 - val_acc: 0.9410\n","Epoch 130/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2676 - acc: 0.9966 - val_loss: 0.4457 - val_acc: 0.9416\n","Epoch 131/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2609 - acc: 0.9974 - val_loss: 0.4371 - val_acc: 0.9422\n","Epoch 132/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2568 - acc: 0.9970 - val_loss: 0.4345 - val_acc: 0.9446\n","Epoch 133/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2521 - acc: 0.9973 - val_loss: 0.4326 - val_acc: 0.9442\n","Epoch 134/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2472 - acc: 0.9974 - val_loss: 0.4350 - val_acc: 0.9417\n","Epoch 135/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2427 - acc: 0.9973 - val_loss: 0.4281 - val_acc: 0.9427\n","Epoch 136/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2373 - acc: 0.9978 - val_loss: 0.4213 - val_acc: 0.9438\n","Epoch 137/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2340 - acc: 0.9981 - val_loss: 0.4216 - val_acc: 0.9429\n","Epoch 138/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2297 - acc: 0.9979 - val_loss: 0.4209 - val_acc: 0.9418\n","Epoch 139/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2239 - acc: 0.9987 - val_loss: 0.4178 - val_acc: 0.9427\n","Epoch 140/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2204 - acc: 0.9987 - val_loss: 0.4096 - val_acc: 0.9439\n","Epoch 141/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2162 - acc: 0.9988 - val_loss: 0.4102 - val_acc: 0.9425\n","Epoch 142/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2130 - acc: 0.9984 - val_loss: 0.4011 - val_acc: 0.9443\n","Epoch 143/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.2094 - acc: 0.9985 - val_loss: 0.3951 - val_acc: 0.9466\n","Epoch 144/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2048 - acc: 0.9988 - val_loss: 0.3993 - val_acc: 0.9434\n","Epoch 145/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.2010 - acc: 0.9991 - val_loss: 0.3948 - val_acc: 0.9437\n","Epoch 146/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1989 - acc: 0.9986 - val_loss: 0.3960 - val_acc: 0.9440\n","Epoch 147/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1947 - acc: 0.9992 - val_loss: 0.3854 - val_acc: 0.9445\n","Epoch 148/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1918 - acc: 0.9987 - val_loss: 0.3776 - val_acc: 0.9464\n","Epoch 149/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1878 - acc: 0.9991 - val_loss: 0.3820 - val_acc: 0.9457\n","Epoch 150/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1846 - acc: 0.9992 - val_loss: 0.3777 - val_acc: 0.9456\n","Epoch 151/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1817 - acc: 0.9990 - val_loss: 0.3744 - val_acc: 0.9461\n","Epoch 152/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1791 - acc: 0.9991 - val_loss: 0.3680 - val_acc: 0.9460\n","Epoch 153/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1757 - acc: 0.9992 - val_loss: 0.3652 - val_acc: 0.9457\n","Epoch 154/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1723 - acc: 0.9994 - val_loss: 0.3648 - val_acc: 0.9458\n","Epoch 155/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1703 - acc: 0.9990 - val_loss: 0.3584 - val_acc: 0.9455\n","Epoch 156/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1671 - acc: 0.9989 - val_loss: 0.3571 - val_acc: 0.9459\n","Epoch 157/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1643 - acc: 0.9991 - val_loss: 0.3592 - val_acc: 0.9450\n","Epoch 158/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1620 - acc: 0.9988 - val_loss: 0.3566 - val_acc: 0.9444\n","Epoch 159/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1581 - acc: 0.9994 - val_loss: 0.3538 - val_acc: 0.9443\n","Epoch 160/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1570 - acc: 0.9989 - val_loss: 0.3602 - val_acc: 0.9448\n","Epoch 161/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1539 - acc: 0.9995 - val_loss: 0.3529 - val_acc: 0.9457\n","Epoch 162/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1529 - acc: 0.9995 - val_loss: 0.3544 - val_acc: 0.9447\n","Epoch 163/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1519 - acc: 0.9994 - val_loss: 0.3476 - val_acc: 0.9447\n","Epoch 164/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1515 - acc: 0.9996 - val_loss: 0.3452 - val_acc: 0.9456\n","Epoch 165/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1503 - acc: 0.9997 - val_loss: 0.3449 - val_acc: 0.9456\n","Epoch 166/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1502 - acc: 0.9995 - val_loss: 0.3444 - val_acc: 0.9467\n","Epoch 167/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1494 - acc: 0.9996 - val_loss: 0.3454 - val_acc: 0.9467\n","Epoch 168/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1488 - acc: 0.9996 - val_loss: 0.3425 - val_acc: 0.9464\n","Epoch 169/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1479 - acc: 0.9998 - val_loss: 0.3408 - val_acc: 0.9458\n","Epoch 170/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1471 - acc: 0.9998 - val_loss: 0.3401 - val_acc: 0.9474\n","Epoch 171/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1470 - acc: 0.9997 - val_loss: 0.3390 - val_acc: 0.9461\n","Epoch 172/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1463 - acc: 0.9997 - val_loss: 0.3427 - val_acc: 0.9463\n","Epoch 173/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1459 - acc: 0.9995 - val_loss: 0.3382 - val_acc: 0.9473\n","Epoch 174/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1452 - acc: 0.9997 - val_loss: 0.3388 - val_acc: 0.9478\n","Epoch 175/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1450 - acc: 0.9996 - val_loss: 0.3369 - val_acc: 0.9475\n","Epoch 176/200\n","235/235 [==============================] - 85s 364ms/step - loss: 0.1440 - acc: 0.9998 - val_loss: 0.3370 - val_acc: 0.9473\n","Epoch 177/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1435 - acc: 0.9999 - val_loss: 0.3333 - val_acc: 0.9475\n","Epoch 178/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1429 - acc: 0.9998 - val_loss: 0.3338 - val_acc: 0.9474\n","Epoch 179/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1425 - acc: 0.9997 - val_loss: 0.3343 - val_acc: 0.9481\n","Epoch 180/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1421 - acc: 0.9997 - val_loss: 0.3335 - val_acc: 0.9475\n","Epoch 181/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1416 - acc: 0.9998 - val_loss: 0.3327 - val_acc: 0.9478\n","Epoch 182/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1410 - acc: 0.9997 - val_loss: 0.3307 - val_acc: 0.9490\n","Epoch 183/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1407 - acc: 0.9996 - val_loss: 0.3316 - val_acc: 0.9481\n","Epoch 184/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1402 - acc: 0.9997 - val_loss: 0.3305 - val_acc: 0.9489\n","Epoch 185/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1395 - acc: 0.9998 - val_loss: 0.3313 - val_acc: 0.9481\n","Epoch 186/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1390 - acc: 0.9998 - val_loss: 0.3326 - val_acc: 0.9471\n","Epoch 187/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1384 - acc: 0.9997 - val_loss: 0.3327 - val_acc: 0.9464\n","Epoch 188/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1376 - acc: 0.9999 - val_loss: 0.3318 - val_acc: 0.9468\n","Epoch 189/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1374 - acc: 0.9999 - val_loss: 0.3350 - val_acc: 0.9477\n","Epoch 190/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1370 - acc: 0.9998 - val_loss: 0.3297 - val_acc: 0.9476\n","Epoch 191/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1362 - acc: 0.9999 - val_loss: 0.3282 - val_acc: 0.9481\n","Epoch 192/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1359 - acc: 0.9998 - val_loss: 0.3258 - val_acc: 0.9476\n","Epoch 193/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1354 - acc: 0.9998 - val_loss: 0.3279 - val_acc: 0.9484\n","Epoch 194/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1350 - acc: 0.9998 - val_loss: 0.3265 - val_acc: 0.9471\n","Epoch 195/200\n","235/235 [==============================] - 85s 362ms/step - loss: 0.1344 - acc: 0.9999 - val_loss: 0.3230 - val_acc: 0.9482\n","Epoch 196/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1337 - acc: 0.9999 - val_loss: 0.3240 - val_acc: 0.9482\n","Epoch 197/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1334 - acc: 0.9999 - val_loss: 0.3253 - val_acc: 0.9475\n","Epoch 198/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1327 - acc: 0.9998 - val_loss: 0.3234 - val_acc: 0.9480\n","Epoch 199/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1325 - acc: 0.9998 - val_loss: 0.3240 - val_acc: 0.9473\n","Epoch 200/200\n","235/235 [==============================] - 85s 363ms/step - loss: 0.1317 - acc: 1.0000 - val_loss: 0.3229 - val_acc: 0.9481\n"],"name":"stdout"}]},{"metadata":{"id":"qtEMUddEuPqc","colab_type":"code","outputId":"645fdabe-1ca5-405d-ed3e-2175d59a4350","executionInfo":{"status":"ok","timestamp":1544909031510,"user_tz":300,"elapsed":1065,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["cd /content/drive/DL1/event"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/DL1/event\n"],"name":"stdout"}]},{"metadata":{"id":"aKfZ4zzjvzTi","colab_type":"code","outputId":"fbb5e6f7-8370-497e-aa60-de8bd51774f6","executionInfo":{"status":"ok","timestamp":1544908930883,"user_tz":300,"elapsed":1275,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["!ls /content/drive/DL1/event"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ngrok  ngrok-stable-linux-amd64.zip  result\n"],"name":"stdout"}]},{"metadata":{"id":"rm2OvcLJkTA5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run Tensorflow in the background - note that we specify the log \n","# directory we want to look at\n","LOG_DIR = 'result/'\n","\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dupv7EKKkUpX","colab_type":"code","outputId":"837435b9-eee5-4e41-c0ea-5bc69850d559","executionInfo":{"status":"ok","timestamp":1544909124777,"user_tz":300,"elapsed":23178,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"cell_type":"code","source":["# Download and unzip ngrok - you will only need to do this once per session\n","! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-12-15 21:25:01--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.201.75.180, 52.203.102.189, 52.2.175.150, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.201.75.180|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5363700 (5.1M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n","\n","ngrok-stable-linux- 100%[===================>]   5.11M  8.50MB/s    in 0.6s    \n","\n","2018-12-15 21:25:05 (8.50 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [5363700/5363700]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"metadata":{"id":"9m53zpOokVAO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Launch the ngrok background process\n","get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9pmVoA7bkVH-","colab_type":"code","outputId":"37e07dd9-2dd8-45dd-8a57-a863ff2e42f0","executionInfo":{"status":"ok","timestamp":1544909134831,"user_tz":300,"elapsed":1454,"user":{"displayName":"Jianfeng Zhang","photoUrl":"","userId":"00276569247713701028"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# Get the public URL and be sorted!\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["http://67b90266.ngrok.io\n"],"name":"stdout"}]}]}