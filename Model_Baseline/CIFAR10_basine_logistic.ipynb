{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=images_train[:5000,:,:,:]\n",
    "y_onehot_val=labels_train[:5000,:]\n",
    "X_train=images_train[5000:,:,:,:]\n",
    "y_onehot=labels_train[5000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance on some data \n",
    "def perf_eval(logit_pred, y_true):\n",
    "    \"\"\"a function to evaluate performance of predicted y values vs true class labels\"\"\"\n",
    "    # now look at some data\n",
    "    print('    sample pred: {0}\\n    sample true: {1}'.format(np.argmax(logit_pred[0:20],1),np.argmax(y_true[0:20],1)))\n",
    "    # avg accuracy\n",
    "    is_correct_vals = np.equal(np.argmax(logit_pred,1),np.argmax(y_true,1))\n",
    "    #accuracy_vals = np.mean(is_correct_vals)\n",
    "    #print('    mean classification accuracy: {0}%'.format(100*accuracy_vals))\n",
    "    # Dig in a little deeper.  Where did we make correct predictions?  Does this seem reasonable?\n",
    "    print('    correct predictions by class: {0}'.format(y_true[is_correct_vals,:].sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn conv stuff\n",
    "def conv(x, W):\n",
    "    \"\"\"simple wrapper for tf.nn.conv2d\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def maxpool(x):\n",
    "    \"\"\"simple wrapper for tf.nn.max_pool with stride size 2\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def norm(x): \n",
    "    \"\"\"simple wrapper for tf.nn.lrn... See section 3.3 of Krizhevsky 2012 for details\"\"\"\n",
    "    return tf.nn.lrn(x, depth_radius=5, bias=2, alpha=1e-4, beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elaborate the compute_logits code to include a variety of models\n",
    "def compute_logits(x, model_type, pkeep):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "    if model_type=='lr':\n",
    "        W = tf.get_variable('W', shape=[32*32*3, 10])\n",
    "        b = tf.get_variable('b', shape=[10])\n",
    "        logits = tf.add(tf.matmul(x, W), b, name='logits_lr')\n",
    "    elif model_type=='cnn_cf':\n",
    "        # try a 1 layer cnn\n",
    "        n1 = 64\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # fc layer to logits\n",
    "        h_conv1_flat = tf.reshape(h_conv1, [-1, 32*32*n1])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_conv1_flat, W_fc1), b_fc1, name='logits_cnn_cf')\n",
    "    elif model_type=='cnn_cnf':\n",
    "        # try a 1 layer cnn with a normalization layer\n",
    "        n1 = 64\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # norm layer 1\n",
    "        h_norm1 = norm(h_conv1)\n",
    "        # fc layer to logits\n",
    "        h_flat = tf.reshape(h_norm1, [-1, 32*32*n1])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_flat, W_fc1), b_fc1, name='logits_cnn_cnf')     \n",
    "    elif model_type=='cnn_cpncpnff':\n",
    "        # 2 layer cnn\n",
    "        n1 = 32\n",
    "        n2 = 64\n",
    "        n3 = 1024\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # pool 1\n",
    "        h_pool1 = maxpool(h_conv1)\n",
    "        # norm 1\n",
    "        h_norm1 = norm(h_pool1)\n",
    "        # cnn layer 2\n",
    "        W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, n1, n2])\n",
    "        b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "        h_conv2 = tf.nn.relu(tf.add(conv(h_norm1, W_conv2), b_conv2))\n",
    "        # pool 2\n",
    "        h_pool2 = maxpool(h_conv2)\n",
    "        # norm 2\n",
    "        h_norm2 = norm(h_pool2)\n",
    "        # fc layer to logits (8x8 since 2 rounds of maxpool)\n",
    "        h_norm2_flat = tf.reshape(h_norm2, [-1, 8*8*n2])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, n3])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[n3])\n",
    "        h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_norm2_flat, W_fc1), b_fc1))\n",
    "        # one more fc layer\n",
    "        # ... again, this is the logistic layer with softmax readout\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape=[n3,10])\n",
    "        b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2, name='logits_cnn_cpncpnff')\n",
    "    elif model_type=='cnn_cpncpnfdf':\n",
    "        # same as above but add dropout.\n",
    "        # 2 layer cnn\n",
    "        n1 = 32\n",
    "        n2 = 64\n",
    "        n3 = 1024\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # pool 1\n",
    "        h_pool1 = maxpool(h_conv1)\n",
    "        # norm 1\n",
    "        h_norm1 = norm(h_pool1)\n",
    "        # cnn layer 2\n",
    "        W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, n1, n2])\n",
    "        b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "        h_conv2 = tf.nn.relu(tf.add(conv(h_norm1, W_conv2), b_conv2))\n",
    "        # pool 2\n",
    "        h_pool2 = maxpool(h_conv2)\n",
    "        # norm 2\n",
    "        h_norm2 = norm(h_pool2)\n",
    "        # fc layer to logits (8x8 since 2 rounds of maxpool)\n",
    "        h_norm2_flat = tf.reshape(h_norm2, [-1, 8*8*n2])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, n3])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[n3])\n",
    "        h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_norm2_flat, W_fc1), b_fc1))\n",
    "        # insert a dropout layer here.\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, pkeep)\n",
    "        # one more fc layer\n",
    "        # ... again, this is the logistic layer with softmax readout\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape=[n3,10])\n",
    "        b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_fc1_drop, W_fc2), b_fc2, name='logits_cnn_cpncpnfdf')\n",
    "    elif model_type=='vgg16':\n",
    "        x = tf.reshape(x, [-1,32,32,3])\n",
    "        #layer1\n",
    "        #cnn layer 1.1\n",
    "        W_conv11 = tf.get_variable('W_conv11', shape=[3, 3, 3, 64])\n",
    "        b_conv11 = tf.get_variable('b_conv11', shape=[64])\n",
    "        print(W_conv11,b_conv11)\n",
    "        h_conv11 = tf.nn.relu(tf.add(conv(x, W_conv11), b_conv11))  #[batch,32,32,64]\n",
    "        print(h_conv11)\n",
    "        #cnn layer 1.2\n",
    "        W_conv12 = tf.get_variable('W_conv12', shape=[3, 3, 64, 64])\n",
    "        b_conv12 = tf.get_variable('b_conv12', shape=[64])\n",
    "        h_conv12 = tf.nn.relu(tf.add(conv(h_conv11, W_conv12), b_conv12))\n",
    "        #pool 1\n",
    "        pool1=maxpool(h_conv12)\n",
    "\n",
    "        #cnn layer 2.1\n",
    "        W_conv21 = tf.get_variable('W_conv21', shape=[3, 3, 64, 128])\n",
    "        b_conv21 = tf.get_variable('b_conv21', shape=[128])\n",
    "        h_conv21 = tf.nn.relu(tf.add(conv(pool1, W_conv21), b_conv21))  \n",
    "        #cnn layer 2.2\n",
    "        W_conv22 = tf.get_variable('W_conv22', shape=[3, 3, 128, 128])\n",
    "        b_conv22 = tf.get_variable('b_conv22', shape=[128])\n",
    "        h_conv22 = tf.nn.relu(tf.add(conv(h_conv21, W_conv22), b_conv22))\n",
    "        #pool 2\n",
    "        pool2=maxpool(h_conv22)\n",
    "\n",
    "        #cnn layer 3.1\n",
    "        W_conv31 = tf.get_variable('W_conv31', shape=[3, 3, 128, 256])\n",
    "        b_conv31 = tf.get_variable('b_conv31', shape=[256])\n",
    "        h_conv31 = tf.nn.relu(tf.add(conv(pool2, W_conv31), b_conv31))  \n",
    "        #cnn layer 3.2\n",
    "        W_conv32 = tf.get_variable('W_conv32', shape=[3, 3, 256, 256])\n",
    "        b_conv32 = tf.get_variable('b_conv32', shape=[256])\n",
    "        h_conv32 = tf.nn.relu(tf.add(conv(h_conv31, W_conv32), b_conv32))\n",
    "        #cnn layer 3.3\n",
    "        W_conv33 = tf.get_variable('W_conv33', shape=[3, 3, 256, 256])\n",
    "        b_conv33 = tf.get_variable('b_conv33', shape=[256])\n",
    "        h_conv33 = tf.nn.relu(tf.add(conv(h_conv32, W_conv33), b_conv33))\n",
    "        #pool 3\n",
    "        pool3=maxpool(h_conv33)\n",
    "\n",
    "        #cnn layer 4.1\n",
    "        W_conv41 = tf.get_variable('W_conv41', shape=[3, 3, 256, 512])\n",
    "        b_conv41 = tf.get_variable('b_conv41', shape=[512])\n",
    "        h_conv41 = tf.nn.relu(tf.add(conv(pool3, W_conv41), b_conv41))  \n",
    "        #cnn layer 4.2\n",
    "        W_conv42 = tf.get_variable('W_conv42', shape=[3, 3, 512, 512])\n",
    "        b_conv42 = tf.get_variable('b_conv42', shape=[512])\n",
    "        h_conv42 = tf.nn.relu(tf.add(conv(h_conv41, W_conv42), b_conv42))\n",
    "        #cnn layer 4.3\n",
    "        W_conv43 = tf.get_variable('W_conv43', shape=[3, 3, 512, 512])\n",
    "        b_conv43 = tf.get_variable('b_conv43', shape=[512])\n",
    "        h_conv43 = tf.nn.relu(tf.add(conv(h_conv42, W_conv43), b_conv43))\n",
    "        #pool4\n",
    "        pool4=maxpool(h_conv43)\n",
    "\n",
    "        #cnn layer 5.1\n",
    "        W_conv51 = tf.get_variable('W_conv51', shape=[3, 3, 512, 512])\n",
    "        b_conv51 = tf.get_variable('b_conv51', shape=[512])\n",
    "        h_conv51 = tf.nn.relu(tf.add(conv(pool4, W_conv51), b_conv51))  \n",
    "        #cnn layer 5.2\n",
    "        W_conv52 = tf.get_variable('W_conv52', shape=[3, 3, 512, 512])\n",
    "        b_conv52 = tf.get_variable('b_conv52', shape=[512])\n",
    "        h_conv52 = tf.nn.relu(tf.add(conv(h_conv51, W_conv52), b_conv52))\n",
    "        #cnn layer 5.3\n",
    "        W_conv53 = tf.get_variable('W_conv53', shape=[3, 3, 512, 512])\n",
    "        b_conv53 = tf.get_variable('b_conv53', shape=[512])\n",
    "        h_conv53 = tf.nn.relu(tf.add(conv(h_conv52, W_conv53), b_conv53))\n",
    "        #pool 5\n",
    "        pool5=maxpool(h_conv53)\n",
    "\n",
    "        #fc1-4096\n",
    "        shape=int(np.prod(pool5.get_shape()[1:]))\n",
    "        pool5_flat=tf.reshape(pool5,[-1,shape])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[shape,4096])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[4096])\n",
    "        h_fc1 = tf.nn.relu(tf.add(tf.matmul(pool5_flat, W_fc1), b_fc1))\n",
    "\n",
    "        #fc2-4096\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape=[4096,4096])\n",
    "        b_fc2 = tf.get_variable('b_fc2', shape=[4096])\n",
    "        h_fc2 = tf.nn.relu(tf.add(tf.matmul(h_fc1, W_fc2), b_fc2))\n",
    "\n",
    "        #fc3-1000\n",
    "        W_fc3 = tf.get_variable('W_fc3', shape=[4096,1000])\n",
    "        b_fc3 = tf.get_variable('b_fc3', shape=[1000])\n",
    "        h_fc3 = tf.nn.relu(tf.add(tf.matmul(h_fc2, W_fc3), b_fc3))\n",
    "        \n",
    "        #from softmax to logits\n",
    "        W_sf = tf.get_variable('W_sf', shape=[1000,10])\n",
    "        b_sf = tf.get_variable('b_sf', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_fc3, W_sf), b_sf, name='logits_vgg16')\n",
    "    else: \n",
    "        print('error not a valid model type')\n",
    "    print(logits)\n",
    "    return logits\n",
    "\n",
    "def compute_cross_entropy(logits, y):\n",
    "    # Compute the average cross-entropy across all the examples.\n",
    "    numerical_instability_example = 0\n",
    "    if numerical_instability_example:\n",
    "        y_pred = tf.nn.softmax(logits, name='y_pred') # the predicted probability for each example.\n",
    "        cross_ent = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "    else:\n",
    "        print(logits,y)\n",
    "        sm_ce = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits, name='cross_ent_terms')\n",
    "        cross_ent = tf.reduce_mean(sm_ce, name='cross_ent')\n",
    "    return cross_ent\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose case to run \n",
    "opt_method = 'sgd'\n",
    "model_type =  'vgg16'\n",
    "dir_name = 'logs/scratch04x/'\n",
    "batch_size = 50\n",
    "n=50000\n",
    "n_val=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W_conv11:0' shape=(3, 3, 3, 64) dtype=float32_ref> <tf.Variable 'b_conv11:0' shape=(64,) dtype=float32_ref>\n",
      "Tensor(\"model/Relu:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "Tensor(\"model/logits_vgg16:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"model/logits_vgg16:0\", shape=(?, 10), dtype=float32) Tensor(\"y:0\", shape=(?, 10), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-8-d8b0b9c95c57>:209: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Step   0: training accuracy 0.0910\n",
      "    sample pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 91.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Step   0: val accuracy 0.0920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-29f1f16b8046>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m# now run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             _ , summary = sess.run((train_step, summary_op),\n\u001b[1;32m---> 48\u001b[1;33m                                       feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m# write the summary output to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    pkeep = tf.placeholder(tf.float32, name='pkeep')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits(x, model_type, pkeep)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        if opt_method == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "        elif opt_method == 'rms':\n",
    "            opt = tf.train.RMSPropOptimizer(.001)\n",
    "        elif opt_method == 'adam':\n",
    "            opt = tf.train.AdamOptimizer(1e-4)\n",
    "        train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        # create summary for logits\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        # create summary for input image\n",
    "        tf.summary.image('input', tf.reshape(x, [-1, 32, 32, 3]))\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for i in range(301):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(n-n_val)).astype(int)\n",
    "            X_batch = X_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_onehot[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%100 == 0:\n",
    "                X_batch = X_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_onehot[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "                # further diagnostics\n",
    "                perf_eval(train_logits, y_batch)\n",
    "                \n",
    "            if i%100 == 0:\n",
    "                X_batch = X_val.reshape([n_val,-1])\n",
    "                y_batch = y_onehot_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"model/logits_lr:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"model/logits_lr:0\", shape=(?, 10), dtype=float32) Tensor(\"y:0\", shape=(?, 10), dtype=float32)\n",
      "Step   0: training accuracy 0.0970\n",
      "    sample pred: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  0.  0.  0.  0. 97.  0.  0.  0.]\n",
      "Step   0: val accuracy 0.1052\n",
      "Step 100: training accuracy 0.1640\n",
      "    sample pred: [1 9 1 1 1 1 1 1 9 1 0 9 1 1 1 0 1 1 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 71.  9.  0.  0.  0.  5.  0.  0. 19.]\n",
      "Step 100: val accuracy 0.1702\n",
      "Step 200: training accuracy 0.1900\n",
      "    sample pred: [7 8 1 1 3 3 3 3 8 8 8 8 3 1 1 3 8 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 27.  0. 64.  0.  0.  0. 15. 84.  0.]\n",
      "Step 200: val accuracy 0.1940\n",
      "Step 300: training accuracy 0.1770\n",
      "    sample pred: [7 8 8 5 5 5 5 5 8 8 8 5 5 5 8 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  4.  0.  0. 85.  0. 26. 62.  0.]\n",
      "Step 300: val accuracy 0.1860\n"
     ]
    }
   ],
   "source": [
    "model_type =  'lr'\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    pkeep = tf.placeholder(tf.float32, name='pkeep')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits(x, model_type, pkeep)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        if opt_method == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "        elif opt_method == 'rms':\n",
    "            opt = tf.train.RMSPropOptimizer(.001)\n",
    "        elif opt_method == 'adam':\n",
    "            opt = tf.train.AdamOptimizer(1e-4)\n",
    "        train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        # create summary for logits\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        # create summary for input image\n",
    "        tf.summary.image('input', tf.reshape(x, [-1, 32, 32, 3]))\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for i in range(301):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(n-n_val)).astype(int)\n",
    "            X_batch = X_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_onehot[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%100 == 0:\n",
    "                X_batch = X_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_onehot[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "                # further diagnostics\n",
    "                perf_eval(train_logits, y_batch)\n",
    "                \n",
    "            if i%100 == 0:\n",
    "                X_batch = X_val.reshape([n_val,-1])\n",
    "                y_batch = y_onehot_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"model/logits_lr:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"model/logits_lr:0\", shape=(?, 10), dtype=float32) Tensor(\"y:0\", shape=(?, 10), dtype=float32)\n",
      "Step   0: training accuracy 0.1050\n",
      "    sample pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [105.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Step   0: val accuracy 0.1016\n",
      "Step 100: training accuracy 0.1250\n",
      "    sample pred: [6 6 9 6 6 6 6 6 6 6 0 6 6 6 6 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [10.  0.  2.  0.  0.  0. 97.  0.  8.  8.]\n",
      "Step 100: val accuracy 0.1364\n",
      "Step 200: training accuracy 0.1420\n",
      "    sample pred: [6 6 1 6 6 6 6 6 6 6 0 6 6 1 1 4 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 19.  0.  0. 23.  1. 93.  1.  0.  0.]\n",
      "Step 200: val accuracy 0.1516\n",
      "Step 300: training accuracy 0.1570\n",
      "    sample pred: [5 5 1 5 5 5 5 5 8 8 8 5 5 1 1 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 19.  0.  0.  0. 92.  5.  1. 38.  2.]\n",
      "Step 300: val accuracy 0.1744\n",
      "Step 400: training accuracy 0.2200\n",
      "    sample pred: [2 9 9 9 2 2 2 2 9 9 8 9 9 9 9 2 2 2 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.  76.   0.   0.   1.   0.   2.  38. 103.]\n",
      "Step 400: val accuracy 0.1998\n",
      "Step 500: training accuracy 0.2520\n",
      "    sample pred: [7 7 9 5 5 5 5 5 7 9 8 9 5 1 1 7 5 5 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 25.  0.  0.  0. 58. 22. 82. 30. 34.]\n",
      "Step 500: val accuracy 0.2642\n",
      "Step 600: training accuracy 0.2750\n",
      "    sample pred: [4 0 9 1 6 6 4 4 9 9 0 9 4 1 1 0 0 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [85. 28.  0.  0. 53.  0. 58.  3.  0. 48.]\n",
      "Step 600: val accuracy 0.2688\n",
      "Step 700: training accuracy 0.2330\n",
      "    sample pred: [4 0 9 5 5 5 5 5 9 9 0 9 5 9 9 0 0 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [87.  0.  0.  0. 27. 75.  0.  0.  0. 44.]\n",
      "Step 700: val accuracy 0.2272\n",
      "Step 800: training accuracy 0.2890\n",
      "    sample pred: [6 3 9 3 3 6 3 3 9 9 8 9 3 1 1 3 3 6 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 31.  2. 49.  0. 14. 71. 34. 30. 58.]\n",
      "Step 800: val accuracy 0.2812\n",
      "Step 900: training accuracy 0.3320\n",
      "    sample pred: [7 9 9 1 3 6 3 3 9 9 0 9 9 9 1 7 3 7 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [28. 36. 32. 39.  0.  0. 31. 67.  0. 99.]\n",
      "Step 900: val accuracy 0.2978\n",
      "Step 1000: training accuracy 0.2110\n",
      "    sample pred: [9 9 9 9 3 4 3 3 9 9 0 9 9 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 24.   0.   1.  46.  20.   2.   3.   4.   0. 111.]\n",
      "Step 1000: val accuracy 0.1984\n",
      "Step 1100: training accuracy 0.1830\n",
      "    sample pred: [2 2 9 2 2 2 2 2 8 8 8 9 2 9 9 2 2 7 2 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0. 91.  0.  0.  0.  0. 23. 43. 26.]\n",
      "Step 1100: val accuracy 0.1818\n",
      "Step 1200: training accuracy 0.2360\n",
      "    sample pred: [4 8 9 1 3 4 3 3 8 8 8 9 8 1 1 8 8 4 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 29.  0. 31. 53.  1. 15.  0. 93. 14.]\n",
      "Step 1200: val accuracy 0.2394\n",
      "Step 1300: training accuracy 0.2740\n",
      "    sample pred: [6 5 9 1 5 6 6 6 2 9 8 9 6 9 9 5 5 6 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 11. 43.  0.  0. 57. 67.  7. 20. 69.]\n",
      "Step 1300: val accuracy 0.2606\n",
      "Step 1400: training accuracy 0.2730\n",
      "    sample pred: [2 8 9 8 3 4 3 3 8 8 8 9 3 9 9 0 8 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [13.  6. 22. 33. 55.  0.  0.  1. 92. 51.]\n",
      "Step 1400: val accuracy 0.2652\n",
      "Step 1500: training accuracy 0.2270\n",
      "    sample pred: [7 8 9 5 5 5 5 5 8 8 8 5 5 9 8 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  1.  5.  0.  0. 78.  0. 51. 82. 10.]\n",
      "Step 1500: val accuracy 0.2192\n",
      "Step 1600: training accuracy 0.2330\n",
      "    sample pred: [7 7 9 1 5 5 7 5 7 7 0 9 7 1 1 7 0 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 47.  28.   0.   0.   0.  12.   0. 102.  14.  30.]\n",
      "Step 1600: val accuracy 0.2206\n",
      "Step 1700: training accuracy 0.2360\n",
      "    sample pred: [7 7 1 1 5 5 3 3 1 1 8 5 3 1 1 7 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 69.  4. 29.  0. 45. 21. 58. 10.  0.]\n",
      "Step 1700: val accuracy 0.2438\n",
      "Step 1800: training accuracy 0.2400\n",
      "    sample pred: [7 4 1 1 3 4 4 4 1 1 0 9 1 1 1 4 3 7 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [11. 69.  0. 15. 73.  3. 10. 44.  0. 15.]\n",
      "Step 1800: val accuracy 0.2414\n",
      "Step 1900: training accuracy 0.2710\n",
      "    sample pred: [7 3 1 1 3 4 3 3 8 1 8 3 3 1 1 7 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 47.  0. 62. 52. 10. 13. 58. 29.  0.]\n",
      "Step 1900: val accuracy 0.2846\n",
      "Step 2000: training accuracy 0.2270\n",
      "    sample pred: [5 3 9 3 5 5 3 3 9 9 0 9 3 9 9 3 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [25.  0.  7. 55.  0. 49.  0.  1. 23. 67.]\n",
      "Step 2000: val accuracy 0.2180\n",
      "Step 2100: training accuracy 0.2870\n",
      "    sample pred: [7 9 9 1 2 4 2 4 9 9 8 9 2 9 1 2 2 7 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 43. 62.  3. 30.  0.  0. 58.  2. 89.]\n",
      "Step 2100: val accuracy 0.2598\n",
      "Step 2200: training accuracy 0.2280\n",
      "    sample pred: [9 9 9 9 3 4 9 3 9 9 0 9 9 9 9 0 0 3 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 64.   5.   0.  22.  29.   0.   0.   3.   0. 105.]\n",
      "Step 2200: val accuracy 0.2140\n",
      "Step 2300: training accuracy 0.2390\n",
      "    sample pred: [7 7 1 1 3 7 7 3 8 7 8 9 7 9 1 7 3 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 31.  0. 18.  0.  0.  1. 99. 55. 35.]\n",
      "Step 2300: val accuracy 0.2394\n",
      "Step 2400: training accuracy 0.2060\n",
      "    sample pred: [7 8 1 8 8 8 8 8 8 8 8 8 8 8 1 8 8 7 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 26. 14.  1.  0.  0.  0. 66. 96.  3.]\n",
      "Step 2400: val accuracy 0.2004\n",
      "Step 2500: training accuracy 0.2150\n",
      "    sample pred: [7 0 0 8 5 5 0 8 8 8 0 9 0 9 1 0 0 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [69. 25.  0.  0. 11. 20.  0.  8. 69. 13.]\n",
      "Step 2500: val accuracy 0.2162\n",
      "Step 2600: training accuracy 0.2230\n",
      "    sample pred: [6 2 1 1 6 6 6 6 2 1 8 6 6 1 1 2 2 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 58. 57.  1.  0.  0. 80. 26.  1.  0.]\n",
      "Step 2600: val accuracy 0.2300\n",
      "Step 2700: training accuracy 0.2360\n",
      "    sample pred: [8 8 9 1 3 8 3 8 8 8 0 9 8 9 1 0 8 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [36. 26.  0. 38.  1.  5.  0. 10. 90. 30.]\n",
      "Step 2700: val accuracy 0.2226\n",
      "Step 2800: training accuracy 0.3080\n",
      "    sample pred: [4 9 9 1 5 4 5 5 9 9 0 9 9 9 9 0 3 5 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [59. 27.  0. 20. 46. 53.  0.  1.  5. 97.]\n",
      "Step 2800: val accuracy 0.2928\n",
      "Step 2900: training accuracy 0.2500\n",
      "    sample pred: [7 8 8 8 3 6 3 3 8 8 8 3 3 8 8 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [55.  1.  0. 53.  3.  0. 55. 17. 66.  0.]\n",
      "Step 2900: val accuracy 0.2570\n",
      "Step 3000: training accuracy 0.2370\n",
      "    sample pred: [7 0 9 0 3 4 7 3 7 7 0 9 0 9 9 0 0 7 7 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [96.  1.  0. 22.  2.  0.  0. 81.  1. 34.]\n",
      "Step 3000: val accuracy 0.2122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100: training accuracy 0.3070\n",
      "    sample pred: [7 4 1 1 6 4 4 4 8 1 0 9 4 9 1 4 4 7 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31. 41.  0.  3. 77.  0. 21. 42. 61. 31.]\n",
      "Step 3100: val accuracy 0.3080\n",
      "Step 3200: training accuracy 0.2160\n",
      "    sample pred: [7 4 8 8 5 4 4 5 8 8 8 4 4 4 8 4 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  1.  0. 15. 84. 26.  0. 19. 71.  0.]\n",
      "Step 3200: val accuracy 0.2246\n",
      "Step 3300: training accuracy 0.1720\n",
      "    sample pred: [8 8 1 1 5 8 8 8 8 8 8 8 8 1 1 8 8 5 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 37.  0.  0. 12. 18.  6.  2. 97.  0.]\n",
      "Step 3300: val accuracy 0.1814\n",
      "Step 3400: training accuracy 0.3250\n",
      "    sample pred: [7 0 9 9 3 6 3 3 9 9 0 9 7 9 9 7 0 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [54.  0.  9. 24. 18.  3. 32. 94. 16. 75.]\n",
      "Step 3400: val accuracy 0.3022\n",
      "Step 3500: training accuracy 0.2860\n",
      "    sample pred: [2 0 1 1 3 1 3 3 8 9 8 9 3 9 1 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [41. 43. 19. 61.  0.  0. 10.  0. 65. 47.]\n",
      "Step 3500: val accuracy 0.2896\n",
      "Step 3600: training accuracy 0.1770\n",
      "    sample pred: [4 0 0 1 0 4 0 0 0 0 0 0 0 9 1 0 0 4 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [102.  27.   0.   0.  34.   0.   5.   0.   3.   6.]\n",
      "Step 3600: val accuracy 0.1894\n",
      "Step 3700: training accuracy 0.2210\n",
      "    sample pred: [7 5 1 1 5 5 5 5 7 1 8 7 5 1 1 5 5 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 44.  2.  0.  0. 80.  1. 53. 41.  0.]\n",
      "Step 3700: val accuracy 0.2456\n",
      "Step 3800: training accuracy 0.2240\n",
      "    sample pred: [5 9 9 9 5 5 5 5 9 9 8 9 9 9 9 3 3 5 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   3.   0.  12.   0.  64.  19.   0.  21. 105.]\n",
      "Step 3800: val accuracy 0.2222\n",
      "Step 3900: training accuracy 0.2560\n",
      "    sample pred: [7 9 1 1 3 1 7 1 1 9 8 9 7 9 1 7 1 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 62.  0. 15.  0.  0.  8. 86. 14. 71.]\n",
      "Step 3900: val accuracy 0.2404\n",
      "Step 4000: training accuracy 0.2920\n",
      "    sample pred: [7 8 1 1 5 1 5 5 1 1 0 9 1 1 1 0 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 66. 27.  1.  0. 45. 27. 34. 54. 15.]\n",
      "Step 4000: val accuracy 0.3090\n",
      "Step 4100: training accuracy 0.2320\n",
      "    sample pred: [4 0 1 1 5 4 4 5 1 1 0 1 0 1 1 0 0 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [97. 47.  0.  0. 45. 33.  1.  4.  1.  4.]\n",
      "Step 4100: val accuracy 0.2410\n",
      "Step 4200: training accuracy 0.3400\n",
      "    sample pred: [7 0 9 3 3 6 3 3 2 9 0 9 3 9 9 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [78.  3. 30. 49.  0.  7. 46. 67.  7. 53.]\n",
      "Step 4200: val accuracy 0.3204\n",
      "Step 4300: training accuracy 0.2430\n",
      "    sample pred: [7 9 9 1 3 1 9 1 9 9 8 9 9 9 9 9 9 7 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.  24.   0.  17.  25.   0.   0.  23.  46. 108.]\n",
      "Step 4300: val accuracy 0.2246\n",
      "Step 4400: training accuracy 0.1950\n",
      "    sample pred: [2 2 1 1 5 4 2 4 2 1 8 2 2 1 1 2 2 4 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 40. 80.  3. 24. 14.  2.  0. 32.  0.]\n",
      "Step 4400: val accuracy 0.2230\n",
      "Step 4500: training accuracy 0.2520\n",
      "    sample pred: [2 2 1 1 5 2 2 5 2 1 0 5 2 1 1 2 2 6 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 35. 77.  0.  1. 30. 54. 21.  4.  7.]\n",
      "Step 4500: val accuracy 0.2630\n",
      "Step 4600: training accuracy 0.2790\n",
      "    sample pred: [7 3 9 3 3 4 3 3 8 9 8 9 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6. 16.  0. 71. 51.  0.  0. 55. 46. 34.]\n",
      "Step 4600: val accuracy 0.2760\n",
      "Step 4700: training accuracy 0.2690\n",
      "    sample pred: [7 9 9 8 6 6 6 8 9 9 8 9 9 9 9 8 8 6 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  2.  0.  0.  0.  0. 63. 35. 85. 84.]\n",
      "Step 4700: val accuracy 0.2534\n",
      "Step 4800: training accuracy 0.3350\n",
      "    sample pred: [7 9 9 5 5 5 5 5 7 9 0 9 5 9 1 0 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [29. 25.  0.  0.  4. 70. 34. 70. 54. 49.]\n",
      "Step 4800: val accuracy 0.3358\n",
      "Step 4900: training accuracy 0.2630\n",
      "    sample pred: [6 9 1 1 6 6 6 6 1 1 0 9 6 9 1 0 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [32. 60.  0.  4. 11.  0. 88. 17. 30. 21.]\n",
      "Step 4900: val accuracy 0.2682\n",
      "Step 5000: training accuracy 0.3100\n",
      "    sample pred: [4 9 9 1 3 4 4 8 8 9 8 9 4 9 1 4 8 3 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 26.  0. 18. 71.  1. 28.  5. 83. 78.]\n",
      "Step 5000: val accuracy 0.2936\n",
      "Step 5100: training accuracy 0.2040\n",
      "    sample pred: [5 5 1 1 5 1 5 5 1 1 0 1 1 1 1 0 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [21. 79. 21.  1.  4. 53.  0. 11. 14.  0.]\n",
      "Step 5100: val accuracy 0.2114\n",
      "Step 5200: training accuracy 0.3340\n",
      "    sample pred: [7 9 9 1 5 6 6 5 9 9 8 9 6 9 9 7 5 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 22.  0.  0.  0. 42. 68. 80. 26. 96.]\n",
      "Step 5200: val accuracy 0.2942\n",
      "Step 5300: training accuracy 0.2630\n",
      "    sample pred: [6 0 1 1 3 6 3 3 1 1 8 1 1 1 1 0 1 6 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [44. 72.  0. 25. 40.  0. 59. 15.  8.  0.]\n",
      "Step 5300: val accuracy 0.2720\n",
      "Step 5400: training accuracy 0.2320\n",
      "    sample pred: [7 5 7 5 5 5 5 5 8 8 8 5 5 5 8 5 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  1.  3. 15.  6. 71. 24. 51. 58.  3.]\n",
      "Step 5400: val accuracy 0.2514\n",
      "Step 5500: training accuracy 0.1730\n",
      "    sample pred: [7 8 8 8 5 8 8 8 8 8 8 8 8 8 8 8 8 5 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 14.  0.  0.  0. 22. 27. 11. 98.  0.]\n",
      "Step 5500: val accuracy 0.1858\n",
      "Step 5600: training accuracy 0.2400\n",
      "    sample pred: [2 0 1 1 5 5 5 5 1 1 0 9 5 1 1 0 5 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [29. 63. 29.  2.  0. 68. 19. 17.  1. 12.]\n",
      "Step 5600: val accuracy 0.2446\n",
      "Step 5700: training accuracy 0.2480\n",
      "    sample pred: [7 8 1 1 5 6 6 8 1 1 8 1 1 1 1 8 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 55.  0.  0.  0. 24. 59. 18. 90.  1.]\n",
      "Step 5700: val accuracy 0.2606\n",
      "Step 5800: training accuracy 0.2610\n",
      "    sample pred: [2 8 1 1 5 1 5 1 1 1 0 1 1 1 1 0 1 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [44. 62. 35.  0.  0. 20. 20. 13. 67.  0.]\n",
      "Step 5800: val accuracy 0.2792\n",
      "Step 5900: training accuracy 0.2340\n",
      "    sample pred: [7 0 0 5 5 5 5 5 0 0 0 5 0 0 0 0 0 5 3 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [99.  2.  0.  8. 13. 61. 11. 37.  2.  1.]\n",
      "Step 5900: val accuracy 0.2180\n",
      "Step 6000: training accuracy 0.1890\n",
      "    sample pred: [7 7 7 1 5 5 7 5 7 7 0 7 7 9 1 7 7 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 25.  31.   1.   0.   1.  15.   0. 107.   1.   8.]\n",
      "Step 6000: val accuracy 0.1800\n",
      "Step 6100: training accuracy 0.3030\n",
      "    sample pred: [7 0 1 1 2 2 2 8 2 8 8 9 2 9 1 0 2 7 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [32. 25. 67.  3. 13.  0. 17. 39. 90. 17.]\n",
      "Step 6100: val accuracy 0.2916\n",
      "Step 6200: training accuracy 0.3170\n",
      "    sample pred: [6 0 1 1 3 6 3 3 1 9 0 9 3 9 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 27.  7. 58.  0.  6. 54.  0. 58. 47.]\n",
      "Step 6200: val accuracy 0.3128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6300: training accuracy 0.2530\n",
      "    sample pred: [5 9 1 1 5 5 5 5 1 9 8 9 5 9 1 5 5 5 9 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 31.  0.  0.  0. 87.  1. 18. 34. 82.]\n",
      "Step 6300: val accuracy 0.2446\n",
      "Step 6400: training accuracy 0.2190\n",
      "    sample pred: [6 9 9 1 6 6 6 6 9 9 8 9 6 9 1 6 3 6 3 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 13.  0.  9.  1.  2. 91.  0. 33. 70.]\n",
      "Step 6400: val accuracy 0.2196\n",
      "Step 6500: training accuracy 0.2200\n",
      "    sample pred: [6 0 0 3 3 6 3 3 3 9 0 3 0 9 0 0 0 3 3 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [98.  0.  0. 35.  0.  0. 55.  7. 13. 12.]\n",
      "Step 6500: val accuracy 0.2146\n",
      "Step 6600: training accuracy 0.2470\n",
      "    sample pred: [7 1 1 1 5 4 5 5 1 1 1 1 1 1 1 4 1 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 76.  0.  9. 45. 42. 26. 49.  0.  0.]\n",
      "Step 6600: val accuracy 0.2448\n",
      "Step 6700: training accuracy 0.3050\n",
      "    sample pred: [7 7 1 1 3 4 4 4 1 1 0 9 4 1 1 0 4 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [49. 47.  1. 20. 76.  1. 14. 67.  2. 28.]\n",
      "Step 6700: val accuracy 0.2920\n",
      "Step 6800: training accuracy 0.2430\n",
      "    sample pred: [2 9 9 3 3 3 3 3 9 9 0 9 3 9 9 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [25.  6.  5. 82. 18.  0.  9.  4.  7. 87.]\n",
      "Step 6800: val accuracy 0.2426\n",
      "Step 6900: training accuracy 0.2560\n",
      "    sample pred: [2 2 1 1 5 6 2 8 2 8 8 8 2 1 1 2 2 5 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 27. 77.  1.  3. 21. 39.  6. 82.  0.]\n",
      "Step 6900: val accuracy 0.2634\n",
      "Step 7000: training accuracy 0.2780\n",
      "    sample pred: [7 9 9 1 3 4 3 4 9 9 8 9 3 9 1 3 3 4 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 44.  1. 42. 61.  0. 15. 21.  3. 91.]\n",
      "Step 7000: val accuracy 0.2690\n",
      "Step 7100: training accuracy 0.2850\n",
      "    sample pred: [7 0 0 8 5 4 4 8 2 8 0 8 2 9 8 0 8 7 8 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [57. 12. 39.  1. 36.  6.  0. 53. 77.  4.]\n",
      "Step 7100: val accuracy 0.2872\n",
      "Step 7200: training accuracy 0.2450\n",
      "    sample pred: [6 9 9 9 3 6 3 3 9 9 0 9 3 9 9 3 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 13.   6.   0.  54.   0.   0.  52.  15.   1. 104.]\n",
      "Step 7200: val accuracy 0.2324\n",
      "Step 7300: training accuracy 0.2450\n",
      "    sample pred: [7 3 9 3 3 3 3 3 8 9 8 9 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  6.  7. 78.  0.  0.  0. 35. 76. 43.]\n",
      "Step 7300: val accuracy 0.2392\n",
      "Step 7400: training accuracy 0.2370\n",
      "    sample pred: [5 0 0 5 5 5 5 5 2 5 0 5 5 5 0 0 3 5 5 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [74.  0.  7. 29.  0. 69. 24. 34.  0.  0.]\n",
      "Step 7400: val accuracy 0.2254\n",
      "Step 7500: training accuracy 0.2390\n",
      "    sample pred: [2 2 1 1 5 2 2 8 2 8 8 8 2 1 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 31. 89.  0.  9.  5. 17. 10. 78.  0.]\n",
      "Step 7500: val accuracy 0.2366\n",
      "Step 7600: training accuracy 0.3070\n",
      "    sample pred: [2 9 1 1 3 4 4 1 1 9 0 9 2 9 1 0 1 4 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [58. 61. 46.  3. 41.  0. 16.  3. 14. 65.]\n",
      "Step 7600: val accuracy 0.2976\n",
      "Step 7700: training accuracy 0.2570\n",
      "    sample pred: [7 5 7 5 5 6 5 5 8 8 8 5 5 5 8 5 5 5 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  4.  0.  0.  0. 65. 62. 52. 74.  0.]\n",
      "Step 7700: val accuracy 0.2648\n",
      "Step 7800: training accuracy 0.2910\n",
      "    sample pred: [6 9 1 1 6 6 6 6 9 9 0 9 9 9 1 0 0 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [80. 43.  0. 10.  0.  0. 74.  0.  0. 84.]\n",
      "Step 7800: val accuracy 0.2760\n",
      "Step 7900: training accuracy 0.2430\n",
      "    sample pred: [7 9 9 1 9 1 9 1 9 9 0 9 9 9 9 0 9 7 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 39.  29.   4.   4.   3.   1.   1.  53.   2. 107.]\n",
      "Step 7900: val accuracy 0.2130\n",
      "Step 8000: training accuracy 0.2410\n",
      "    sample pred: [2 9 9 1 6 6 6 1 9 9 0 9 1 9 1 9 1 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 58. 18.  5.  0.  0. 66.  0.  0. 89.]\n",
      "Step 8000: val accuracy 0.2322\n",
      "Step 8100: training accuracy 0.2720\n",
      "    sample pred: [7 3 1 1 3 3 3 3 2 1 0 3 3 1 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [25. 40. 42. 76.  9.  2.  0. 34. 29. 15.]\n",
      "Step 8100: val accuracy 0.2768\n",
      "Step 8200: training accuracy 0.3190\n",
      "    sample pred: [7 0 0 1 3 3 3 3 3 9 0 9 3 9 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [84. 25.  0. 67. 15. 15.  0. 27. 21. 65.]\n",
      "Step 8200: val accuracy 0.2900\n",
      "Step 8300: training accuracy 0.2990\n",
      "    sample pred: [7 2 1 1 5 4 3 3 2 8 8 5 2 9 1 2 3 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 36. 51. 22. 39. 32.  0. 38. 75.  6.]\n",
      "Step 8300: val accuracy 0.3184\n",
      "Step 8400: training accuracy 0.3450\n",
      "    sample pred: [6 0 1 1 5 6 5 5 9 9 0 9 0 9 1 0 0 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [80. 28.  0.  0.  0. 53. 60. 36. 42. 46.]\n",
      "Step 8400: val accuracy 0.3292\n",
      "Step 8500: training accuracy 0.1940\n",
      "    sample pred: [2 2 1 1 3 2 2 3 2 8 8 2 2 2 1 2 2 2 3 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 23. 92. 20.  0.  0.  6.  0. 53.  0.]\n",
      "Step 8500: val accuracy 0.2110\n",
      "Step 8600: training accuracy 0.2720\n",
      "    sample pred: [7 9 1 1 6 6 6 6 9 9 1 9 9 9 1 9 1 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 44.  0.  0. 25.  0. 60. 48.  0. 95.]\n",
      "Step 8600: val accuracy 0.2422\n",
      "Step 8700: training accuracy 0.2690\n",
      "    sample pred: [6 3 9 1 3 6 3 3 3 9 8 9 3 9 1 3 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 28.  3. 59. 16. 18. 48.  2. 13. 82.]\n",
      "Step 8700: val accuracy 0.2676\n",
      "Step 8800: training accuracy 0.2370\n",
      "    sample pred: [6 6 1 1 6 6 6 6 1 1 0 6 6 1 1 0 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [43. 59.  0.  5.  0.  0. 84.  4. 42.  0.]\n",
      "Step 8800: val accuracy 0.2568\n",
      "Step 8900: training accuracy 0.2890\n",
      "    sample pred: [7 0 1 1 5 1 5 1 1 1 0 1 1 1 1 0 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [49. 67.  0.  1. 17. 49.  0. 57. 42.  7.]\n",
      "Step 8900: val accuracy 0.2868\n",
      "Step 9000: training accuracy 0.2780\n",
      "    sample pred: [6 9 1 1 6 6 6 6 9 9 8 9 6 9 1 6 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 35.  0.  7.  7.  0. 92.  6. 61. 69.]\n",
      "Step 9000: val accuracy 0.2676\n",
      "Step 9100: training accuracy 0.2840\n",
      "    sample pred: [7 3 9 9 3 3 3 3 9 9 8 9 3 9 9 3 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  7. 67. 13.  0.  3. 52. 44. 98.]\n",
      "Step 9100: val accuracy 0.2666\n",
      "Step 9200: training accuracy 0.2530\n",
      "    sample pred: [7 9 9 9 3 4 3 3 9 9 0 9 9 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 23.   3.   0.  34.  28.   2.   9.  31.  12. 111.]\n",
      "Step 9200: val accuracy 0.2328\n",
      "Step 9300: training accuracy 0.1960\n",
      "    sample pred: [6 4 0 4 6 4 4 6 4 6 0 4 4 9 1 4 4 6 4 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [45.  4.  0.  3. 69.  0. 71.  0.  1.  3.]\n",
      "Step 9300: val accuracy 0.2074\n",
      "Step 9400: training accuracy 0.3010\n",
      "    sample pred: [7 0 1 1 6 6 6 8 1 1 0 9 0 1 1 0 0 6 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [75. 50.  0.  0.  0.  0. 69. 40. 57. 10.]\n",
      "Step 9400: val accuracy 0.3028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500: training accuracy 0.3110\n",
      "    sample pred: [7 0 9 1 6 4 0 4 9 9 0 9 0 9 9 0 0 7 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [90. 19.  0.  3. 40.  0. 27. 46.  2. 84.]\n",
      "Step 9500: val accuracy 0.2746\n",
      "Step 9600: training accuracy 0.2780\n",
      "    sample pred: [7 1 1 1 6 6 7 1 1 1 8 1 1 1 1 7 1 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 63. 29.  0.  1.  0. 57. 86. 42.  0.]\n",
      "Step 9600: val accuracy 0.2772\n",
      "Step 9700: training accuracy 0.2890\n",
      "    sample pred: [7 3 1 1 3 6 3 3 7 1 0 9 3 1 1 7 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 52. 36. 66.  0.  5. 20. 76.  0. 31.]\n",
      "Step 9700: val accuracy 0.2810\n",
      "Step 9800: training accuracy 0.1930\n",
      "    sample pred: [7 5 1 5 5 5 5 5 1 5 8 5 5 1 1 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 41.  0.  0.  0. 90. 18. 27.  3. 14.]\n",
      "Step 9800: val accuracy 0.2002\n",
      "Step 9900: training accuracy 0.3380\n",
      "    sample pred: [7 0 1 1 6 6 2 6 2 1 0 9 2 1 1 0 2 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [57. 49. 60.  3.  0.  0. 56. 78. 18. 17.]\n",
      "Step 9900: val accuracy 0.3232\n",
      "Step 10000: training accuracy 0.2270\n",
      "    sample pred: [4 9 1 1 3 1 3 1 1 9 8 9 9 9 1 9 3 3 9 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 64.  0. 34. 24.  0.  7.  3.  1. 94.]\n",
      "Step 10000: val accuracy 0.2102\n",
      "Step 10100: training accuracy 0.3190\n",
      "    sample pred: [7 9 1 1 6 1 2 1 2 9 0 9 9 9 1 0 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [20. 65. 59.  0. 11.  3. 18. 56. 15. 72.]\n",
      "Step 10100: val accuracy 0.2918\n",
      "Step 10200: training accuracy 0.2670\n",
      "    sample pred: [7 9 1 1 6 4 4 4 1 9 8 9 4 9 1 4 4 4 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 56.  0.  4. 74.  4. 32. 35.  0. 62.]\n",
      "Step 10200: val accuracy 0.2692\n",
      "Step 10300: training accuracy 0.2770\n",
      "    sample pred: [6 0 9 8 6 6 6 6 6 9 0 9 6 9 9 0 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [83.  7.  1.  0.  0.  5. 89.  0. 51. 41.]\n",
      "Step 10300: val accuracy 0.2610\n",
      "Step 10400: training accuracy 0.2880\n",
      "    sample pred: [7 3 7 1 3 4 3 3 2 7 0 3 7 9 1 7 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [15. 25. 30. 52. 48.  0.  1. 84. 13. 20.]\n",
      "Step 10400: val accuracy 0.2686\n",
      "Step 10500: training accuracy 0.3110\n",
      "    sample pred: [7 9 9 1 6 6 6 6 1 9 0 9 6 9 1 0 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [63. 40.  0.  0.  0.  0. 84. 39.  2. 83.]\n",
      "Step 10500: val accuracy 0.2902\n",
      "Step 10600: training accuracy 0.2370\n",
      "    sample pred: [5 5 9 5 5 5 5 5 9 9 8 9 5 9 9 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 2. 12.  0.  3.  0. 86.  0. 13. 47. 74.]\n",
      "Step 10600: val accuracy 0.2286\n",
      "Step 10700: training accuracy 0.2310\n",
      "    sample pred: [7 4 7 1 4 4 4 4 2 1 8 7 4 1 1 4 4 7 4 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 27.  8.  0. 78.  0.  0. 56. 57.  5.]\n",
      "Step 10700: val accuracy 0.2372\n",
      "Step 10800: training accuracy 0.3320\n",
      "    sample pred: [7 9 9 1 3 2 2 1 2 9 0 9 7 9 1 0 0 7 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [67. 38. 43.  3.  0.  0. 20. 70.  0. 91.]\n",
      "Step 10800: val accuracy 0.2948\n",
      "Step 10900: training accuracy 0.1910\n",
      "    sample pred: [7 7 7 1 5 6 7 5 7 7 8 7 7 9 9 7 7 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.  10.   0.   7.   0.  10.  19. 103.   1.  41.]\n",
      "Step 10900: val accuracy 0.1780\n",
      "Step 11000: training accuracy 0.2500\n",
      "    sample pred: [7 7 7 6 6 6 6 6 7 7 0 7 7 9 9 7 6 7 7 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [50.  1.  2.  0.  0.  2. 82. 91.  6. 16.]\n",
      "Step 11000: val accuracy 0.2302\n",
      "Step 11100: training accuracy 0.3070\n",
      "    sample pred: [7 5 9 1 5 6 6 5 1 1 0 9 6 9 1 0 1 7 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [29. 67.  2. 10.  0. 44. 69. 53.  0. 33.]\n",
      "Step 11100: val accuracy 0.2940\n",
      "Step 11200: training accuracy 0.2760\n",
      "    sample pred: [7 2 1 1 3 2 2 8 2 1 0 9 2 9 1 2 2 7 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [21. 38. 91.  5.  6.  0.  0. 52. 37. 26.]\n",
      "Step 11200: val accuracy 0.2626\n",
      "Step 11300: training accuracy 0.2050\n",
      "    sample pred: [5 3 1 1 3 3 3 3 3 3 0 3 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [12. 23.  0. 89.  0.  7. 10.  3. 51. 10.]\n",
      "Step 11300: val accuracy 0.2156\n",
      "Step 11400: training accuracy 0.3040\n",
      "    sample pred: [7 9 9 1 5 2 2 8 2 9 8 9 9 9 1 8 1 7 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 43. 70.  0.  0.  4.  0. 36. 75. 76.]\n",
      "Step 11400: val accuracy 0.2880\n",
      "Step 11500: training accuracy 0.2600\n",
      "    sample pred: [2 8 1 1 6 6 6 8 1 1 8 9 8 9 1 8 1 6 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 44. 18.  3.  3.  1. 74.  1. 92. 24.]\n",
      "Step 11500: val accuracy 0.2586\n",
      "Step 11600: training accuracy 0.2620\n",
      "    sample pred: [6 9 9 9 5 6 6 5 9 9 0 9 9 9 9 0 9 5 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 39.   4.   0.   0.   0.  40.  69.   0.   5. 105.]\n",
      "Step 11600: val accuracy 0.2476\n",
      "Step 11700: training accuracy 0.2630\n",
      "    sample pred: [4 3 1 1 3 4 3 3 1 1 8 8 3 1 1 8 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 49.  0. 59. 42.  2. 29.  6. 76.  0.]\n",
      "Step 11700: val accuracy 0.2854\n",
      "Step 11800: training accuracy 0.2760\n",
      "    sample pred: [7 7 9 1 5 4 7 4 2 9 0 9 7 9 9 7 2 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31.  9. 41.  5. 14.  4.  0. 97.  1. 74.]\n",
      "Step 11800: val accuracy 0.2534\n",
      "Step 11900: training accuracy 0.2210\n",
      "    sample pred: [7 3 9 1 3 3 3 3 1 1 0 3 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 30.  8. 85.  2.  0. 10. 35.  0. 50.]\n",
      "Step 11900: val accuracy 0.2130\n",
      "Step 12000: training accuracy 0.2110\n",
      "    sample pred: [2 2 1 1 5 2 2 2 2 1 8 1 2 1 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7. 61. 89.  6.  0. 10.  0.  4. 26.  8.]\n",
      "Step 12000: val accuracy 0.2168\n",
      "Step 12100: training accuracy 0.2020\n",
      "    sample pred: [7 4 9 4 4 4 4 4 2 9 0 9 4 9 9 4 4 4 4 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [39.  5.  1.  0. 88.  0.  3. 12. 17. 37.]\n",
      "Step 12100: val accuracy 0.2008\n",
      "Step 12200: training accuracy 0.2600\n",
      "    sample pred: [6 6 1 5 5 6 6 6 6 9 8 6 6 9 1 5 6 5 3 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6. 15.  0.  3.  0. 47. 87. 25. 52. 25.]\n",
      "Step 12200: val accuracy 0.2662\n",
      "Step 12300: training accuracy 0.2360\n",
      "    sample pred: [2 9 9 9 3 2 2 8 2 9 8 9 9 9 9 9 9 7 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  4.   6.  62.   8.   0.   0.   0.  25.  21. 110.]\n",
      "Step 12300: val accuracy 0.2240\n",
      "Step 12400: training accuracy 0.2790\n",
      "    sample pred: [6 0 9 8 6 6 6 8 2 9 8 9 6 9 8 0 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [35.  7. 16.  0.  0.  0. 87.  9. 81. 44.]\n",
      "Step 12400: val accuracy 0.2832\n",
      "Step 12500: training accuracy 0.2680\n",
      "    sample pred: [5 5 9 5 5 6 5 5 2 9 8 5 5 9 1 5 5 5 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 20.  5.  0.  3. 78. 52. 18. 39. 48.]\n",
      "Step 12500: val accuracy 0.2746\n",
      "Step 12600: training accuracy 0.2090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample pred: [7 9 9 9 3 4 9 9 9 9 8 9 9 9 9 9 9 7 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.  22.   1.   6.  32.   0.   0.  35.   1. 112.]\n",
      "Step 12600: val accuracy 0.1810\n",
      "Step 12700: training accuracy 0.3080\n",
      "    sample pred: [2 2 1 1 5 2 5 5 2 1 8 9 2 9 1 2 2 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 37. 72. 14.  0. 48. 25. 20. 54. 38.]\n",
      "Step 12700: val accuracy 0.3096\n",
      "Step 12800: training accuracy 0.2150\n",
      "    sample pred: [6 6 1 1 6 6 6 6 6 6 0 9 6 9 1 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [13. 21.  0.  0.  0.  0. 95. 14. 38. 34.]\n",
      "Step 12800: val accuracy 0.2150\n",
      "Step 12900: training accuracy 0.3180\n",
      "    sample pred: [7 8 9 5 5 4 5 5 9 9 8 9 7 9 9 0 5 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [19.  2.  0.  0. 40. 41.  0. 74. 85. 57.]\n",
      "Step 12900: val accuracy 0.3014\n",
      "Step 13000: training accuracy 0.2520\n",
      "    sample pred: [7 8 8 8 6 8 8 8 2 9 8 8 8 9 8 8 8 7 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  9. 18.  0.  4.  0. 30. 69. 97. 25.]\n",
      "Step 13000: val accuracy 0.2452\n",
      "Step 13100: training accuracy 0.3380\n",
      "    sample pred: [7 0 0 5 3 4 3 5 2 9 0 7 7 9 9 0 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [82.  5.  1. 29. 67. 27. 33. 50.  9. 35.]\n",
      "Step 13100: val accuracy 0.3188\n",
      "Step 13200: training accuracy 0.2560\n",
      "    sample pred: [6 3 1 1 3 6 3 3 1 1 8 1 6 1 1 6 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 52.  0. 41. 23.  0. 74.  0. 66.  0.]\n",
      "Step 13200: val accuracy 0.2690\n",
      "Step 13300: training accuracy 0.2890\n",
      "    sample pred: [2 8 8 8 3 4 3 4 2 8 8 3 4 6 1 4 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 11. 25. 30. 65. 13. 47. 12. 86.  0.]\n",
      "Step 13300: val accuracy 0.2874\n",
      "Step 13400: training accuracy 0.2360\n",
      "    sample pred: [7 3 7 3 3 4 3 3 2 3 8 3 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  9.  2. 71. 53.  0.  1. 45. 53.  2.]\n",
      "Step 13400: val accuracy 0.2488\n",
      "Step 13500: training accuracy 0.2580\n",
      "    sample pred: [7 1 1 1 5 1 7 1 1 1 0 1 1 1 1 7 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 9. 81. 16.  1. 22. 20.  0. 69. 25. 15.]\n",
      "Step 13500: val accuracy 0.2490\n",
      "Step 13600: training accuracy 0.3050\n",
      "    sample pred: [7 0 1 1 5 5 5 5 1 1 8 5 5 1 1 0 5 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 47.  0.  0.  0. 72. 13. 61. 52.  0.]\n",
      "Step 13600: val accuracy 0.2940\n",
      "Step 13700: training accuracy 0.3020\n",
      "    sample pred: [6 0 9 1 3 3 3 3 1 1 0 9 3 9 1 0 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [74. 52.  0. 60. 14.  0. 28.  3. 17. 54.]\n",
      "Step 13700: val accuracy 0.3050\n",
      "Step 13800: training accuracy 0.2850\n",
      "    sample pred: [2 2 9 1 6 4 2 4 2 9 0 9 2 9 1 0 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [36. 45. 85.  0. 13.  0. 41.  0. 19. 46.]\n",
      "Step 13800: val accuracy 0.2814\n",
      "Step 13900: training accuracy 0.2650\n",
      "    sample pred: [6 3 9 3 3 6 3 6 2 9 8 3 3 9 1 6 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  9. 13. 43.  0.  0. 79. 32. 57. 32.]\n",
      "Step 13900: val accuracy 0.2570\n",
      "Step 14000: training accuracy 0.3640\n",
      "    sample pred: [7 9 9 1 6 4 4 4 1 9 0 9 4 9 1 0 1 4 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [64. 45.  1.  3. 68.  0. 33. 35. 35. 80.]\n",
      "Step 14000: val accuracy 0.3294\n",
      "Step 14100: training accuracy 0.3230\n",
      "    sample pred: [7 0 7 1 6 6 6 6 1 1 0 9 7 9 1 0 0 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [92. 37.  5.  0.  0.  0. 65. 74. 26. 24.]\n",
      "Step 14100: val accuracy 0.3036\n",
      "Step 14200: training accuracy 0.2490\n",
      "    sample pred: [5 9 9 8 5 8 8 8 9 9 8 9 9 9 9 8 8 5 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  6.  0.  0. 40. 17.  4. 16. 93. 73.]\n",
      "Step 14200: val accuracy 0.2380\n",
      "Step 14300: training accuracy 0.2020\n",
      "    sample pred: [4 4 1 1 4 4 4 4 1 1 8 1 4 1 1 4 1 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 69.  0.  0. 80.  0.  7.  5. 38.  0.]\n",
      "Step 14300: val accuracy 0.2212\n",
      "Step 14400: training accuracy 0.3190\n",
      "    sample pred: [7 9 9 1 3 8 2 8 2 9 8 9 7 9 1 0 8 7 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [15. 29. 41.  4.  5.  0.  1. 71. 90. 63.]\n",
      "Step 14400: val accuracy 0.2914\n",
      "Step 14500: training accuracy 0.2680\n",
      "    sample pred: [7 3 7 1 3 3 3 3 7 7 8 7 3 9 1 7 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 34. 31. 68.  0.  0.  2. 83. 20. 30.]\n",
      "Step 14500: val accuracy 0.2636\n",
      "Step 14600: training accuracy 0.3140\n",
      "    sample pred: [7 7 7 1 5 6 2 5 2 7 8 7 7 1 1 7 2 5 7 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 26. 58.  0. 14. 33. 59. 78. 46.  0.]\n",
      "Step 14600: val accuracy 0.2978\n",
      "Step 14700: training accuracy 0.2990\n",
      "    sample pred: [2 0 1 1 5 1 4 8 1 9 0 9 1 9 1 0 1 4 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [69. 53. 11.  1. 50.  5.  3.  3. 49. 55.]\n",
      "Step 14700: val accuracy 0.2932\n",
      "Step 14800: training accuracy 0.2950\n",
      "    sample pred: [2 9 9 5 5 5 5 5 2 9 0 9 5 9 9 5 5 5 9 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [14.  2. 47.  0.  0. 66. 29. 41.  8. 88.]\n",
      "Step 14800: val accuracy 0.2726\n",
      "Step 14900: training accuracy 0.2250\n",
      "    sample pred: [2 0 0 0 6 6 0 6 2 9 0 9 0 9 1 0 0 6 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [104.  15.   8.   1.   5.   0.  60.   7.   1.  24.]\n",
      "Step 14900: val accuracy 0.2146\n",
      "Step 15000: training accuracy 0.3100\n",
      "    sample pred: [2 0 1 1 6 6 6 6 2 8 0 8 6 9 1 0 6 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [52. 38. 13.  0.  0.  0. 84. 42. 72.  9.]\n",
      "Step 15000: val accuracy 0.3080\n",
      "Step 15100: training accuracy 0.1690\n",
      "    sample pred: [4 4 1 1 4 4 4 4 4 1 8 4 4 9 1 4 4 4 4 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 35.  0.  0. 91.  0.  0.  7. 30.  6.]\n",
      "Step 15100: val accuracy 0.1842\n",
      "Step 15200: training accuracy 0.2910\n",
      "    sample pred: [5 0 9 1 5 4 5 5 9 9 0 9 5 9 9 0 0 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [88. 19.  0.  0. 27. 74. 21.  6.  1. 55.]\n",
      "Step 15200: val accuracy 0.2790\n",
      "Step 15300: training accuracy 0.2550\n",
      "    sample pred: [7 0 0 1 3 4 0 0 1 9 0 9 0 9 9 0 0 7 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [100.  20.   0.  10.  30.   0.  13.  37.   3.  42.]\n",
      "Step 15300: val accuracy 0.2438\n",
      "Step 15400: training accuracy 0.2380\n",
      "    sample pred: [2 5 1 1 5 5 5 5 1 1 0 5 1 1 1 5 1 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [14. 74. 47. 19.  0. 49. 23.  0.  2. 10.]\n",
      "Step 15400: val accuracy 0.2294\n",
      "Step 15500: training accuracy 0.2850\n",
      "    sample pred: [2 8 1 1 5 4 4 4 2 8 8 8 4 9 1 4 4 7 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 37. 18.  1. 69. 10.  5. 40. 87. 18.]\n",
      "Step 15500: val accuracy 0.2874\n",
      "Step 15600: training accuracy 0.2490\n",
      "    sample pred: [7 3 1 1 3 1 3 3 3 1 8 3 3 1 1 3 3 7 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 67.  0. 75. 20.  7.  0. 66.  8.  1.]\n",
      "Step 15600: val accuracy 0.2398\n",
      "Step 15700: training accuracy 0.2860\n",
      "    sample pred: [7 3 1 5 5 5 3 5 3 5 8 3 3 9 1 5 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 23.  0. 40. 34. 60.  1. 48. 68. 12.]\n",
      "Step 15700: val accuracy 0.2796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15800: training accuracy 0.3170\n",
      "    sample pred: [7 0 9 1 6 6 6 6 9 9 0 9 0 9 9 0 0 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [86. 21.  0.  0.  0.  0. 74. 54. 11. 71.]\n",
      "Step 15800: val accuracy 0.2938\n",
      "Step 15900: training accuracy 0.2670\n",
      "    sample pred: [2 0 1 1 5 1 2 1 2 1 0 9 0 9 1 0 1 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [89. 57. 50.  1.  0. 27.  5.  0. 21. 17.]\n",
      "Step 15900: val accuracy 0.2588\n",
      "Step 16000: training accuracy 0.3220\n",
      "    sample pred: [7 0 1 1 5 5 3 5 1 9 0 9 0 9 1 0 3 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [95. 44.  0. 28.  0. 47. 26. 34.  2. 46.]\n",
      "Step 16000: val accuracy 0.2970\n",
      "Step 16100: training accuracy 0.2870\n",
      "    sample pred: [7 3 1 1 3 4 3 3 1 1 0 9 3 9 1 7 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 9. 57.  1. 66. 50.  7.  0. 68.  0. 29.]\n",
      "Step 16100: val accuracy 0.2724\n",
      "Step 16200: training accuracy 0.2260\n",
      "    sample pred: [2 1 1 1 6 1 6 1 2 1 8 1 1 1 1 1 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 77. 35.  0.  0.  4. 63. 17. 26.  4.]\n",
      "Step 16200: val accuracy 0.2270\n",
      "Step 16300: training accuracy 0.3080\n",
      "    sample pred: [2 9 9 1 5 6 6 5 2 9 0 9 9 9 9 0 2 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [63. 15. 42.  0.  6. 20. 57.  3.  4. 98.]\n",
      "Step 16300: val accuracy 0.2938\n",
      "Step 16400: training accuracy 0.2120\n",
      "    sample pred: [2 8 8 1 5 8 5 8 2 8 8 8 8 1 1 8 8 5 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 27. 37.  0.  9. 31.  8.  3. 96.  0.]\n",
      "Step 16400: val accuracy 0.2110\n",
      "Step 16500: training accuracy 0.2260\n",
      "    sample pred: [6 0 1 1 3 6 3 3 1 1 0 1 0 1 1 0 0 3 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [99. 31.  0. 27.  1.  6. 60.  0.  1.  1.]\n",
      "Step 16500: val accuracy 0.2442\n",
      "Step 16600: training accuracy 0.2880\n",
      "    sample pred: [7 0 1 1 5 1 7 1 1 1 0 1 7 1 1 0 1 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [86. 61. 23.  4.  0. 10. 24. 79.  1.  0.]\n",
      "Step 16600: val accuracy 0.2778\n",
      "Step 16700: training accuracy 0.2710\n",
      "    sample pred: [6 0 1 1 3 6 3 3 1 1 0 3 6 1 1 0 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [76. 58.  3. 43.  0.  7. 69.  7.  8.  0.]\n",
      "Step 16700: val accuracy 0.2688\n",
      "Step 16800: training accuracy 0.2950\n",
      "    sample pred: [2 0 1 1 3 4 3 3 2 1 0 3 3 1 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [87. 37. 18. 60. 22. 36.  9. 10.  8.  8.]\n",
      "Step 16800: val accuracy 0.2916\n",
      "Step 16900: training accuracy 0.2000\n",
      "    sample pred: [6 1 1 1 5 1 3 5 1 1 0 1 1 1 1 1 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 2. 79.  8. 12.  0. 49. 35.  5.  0. 10.]\n",
      "Step 16900: val accuracy 0.2038\n",
      "Step 17000: training accuracy 0.3590\n",
      "    sample pred: [7 0 9 1 5 4 4 4 2 9 0 9 9 9 1 0 0 7 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [84. 34. 13. 10. 49. 25.  3. 50. 11. 80.]\n",
      "Step 17000: val accuracy 0.3178\n",
      "Step 17100: training accuracy 0.2360\n",
      "    sample pred: [6 8 9 8 3 6 3 8 3 9 8 9 8 9 1 8 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 11.  0. 50.  0.  0. 47.  0. 93. 32.]\n",
      "Step 17100: val accuracy 0.2422\n",
      "Step 17200: training accuracy 0.2660\n",
      "    sample pred: [6 6 1 1 3 6 3 3 2 1 8 3 3 9 1 3 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 56. 28. 44.  0.  0. 68.  7. 49. 14.]\n",
      "Step 17200: val accuracy 0.2682\n",
      "Step 17300: training accuracy 0.1970\n",
      "    sample pred: [7 8 8 8 8 8 8 8 8 8 8 8 8 9 1 8 8 4 1 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 27.  0.  1. 42.  0.  0. 19. 99.  9.]\n",
      "Step 17300: val accuracy 0.1968\n",
      "Step 17400: training accuracy 0.3320\n",
      "    sample pred: [2 0 0 3 3 6 3 3 2 9 0 3 3 9 9 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [82.  7. 46. 47.  0.  0. 49. 39. 25. 37.]\n",
      "Step 17400: val accuracy 0.3118\n",
      "Step 17500: training accuracy 0.2890\n",
      "    sample pred: [7 5 1 1 5 1 5 5 1 1 8 9 5 9 1 5 1 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 64.  1.  6.  0. 72.  0. 68. 45. 33.]\n",
      "Step 17500: val accuracy 0.2676\n",
      "Step 17600: training accuracy 0.2670\n",
      "    sample pred: [2 2 1 1 6 6 2 1 2 9 8 9 2 9 1 2 1 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 53. 77.  0.  0.  0. 49. 26. 27. 35.]\n",
      "Step 17600: val accuracy 0.2702\n",
      "Step 17700: training accuracy 0.2410\n",
      "    sample pred: [4 8 1 1 3 4 3 8 9 8 8 8 8 9 1 8 8 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 35.  0. 43. 48.  0.  0.  1. 97. 17.]\n",
      "Step 17700: val accuracy 0.2322\n",
      "Step 17800: training accuracy 0.3020\n",
      "    sample pred: [7 9 9 1 3 3 3 3 9 9 8 9 3 9 1 3 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 46.  0. 70.  0.  0. 20. 65. 20. 81.]\n",
      "Step 17800: val accuracy 0.2752\n",
      "Step 17900: training accuracy 0.2670\n",
      "    sample pred: [2 9 9 5 5 5 5 5 2 9 8 9 5 9 9 5 2 5 9 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7.  5. 51.  0. 16. 72.  9.  0. 36. 71.]\n",
      "Step 17900: val accuracy 0.2636\n",
      "Step 18000: training accuracy 0.3190\n",
      "    sample pred: [7 0 1 1 6 6 6 6 1 9 0 9 6 9 1 0 0 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [81. 44.  2.  7.  0.  0. 83. 20. 53. 29.]\n",
      "Step 18000: val accuracy 0.3076\n",
      "Step 18100: training accuracy 0.2300\n",
      "    sample pred: [7 9 9 1 5 1 5 5 9 9 0 9 9 9 9 9 1 5 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  6.  30.   0.   0.   0.  60.   4.  20.   8. 102.]\n",
      "Step 18100: val accuracy 0.2158\n",
      "Step 18200: training accuracy 0.2590\n",
      "    sample pred: [2 0 1 1 5 5 5 5 2 1 0 5 5 9 1 0 2 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [68. 42. 49.  4.  0. 61.  3. 11.  6. 15.]\n",
      "Step 18200: val accuracy 0.2746\n",
      "Step 18300: training accuracy 0.2040\n",
      "    sample pred: [2 3 2 3 3 3 3 3 2 3 8 3 3 9 3 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31.  0. 64. 71.  3.  0.  2.  0. 32.  1.]\n",
      "Step 18300: val accuracy 0.2162\n",
      "Step 18400: training accuracy 0.2870\n",
      "    sample pred: [5 9 9 5 3 4 3 3 9 9 8 9 5 9 9 5 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  2.  0. 24. 43. 63. 48. 23. 19. 65.]\n",
      "Step 18400: val accuracy 0.2746\n",
      "Step 18500: training accuracy 0.3360\n",
      "    sample pred: [7 3 1 1 3 4 3 3 2 1 0 3 3 1 1 0 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [33. 45. 27. 71. 27.  5. 16. 63. 47.  2.]\n",
      "Step 18500: val accuracy 0.3276\n",
      "Step 18600: training accuracy 0.3130\n",
      "    sample pred: [7 0 9 1 6 6 6 6 2 9 0 9 6 9 9 0 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [75. 14.  6.  0.  6.  0. 88. 55.  1. 68.]\n",
      "Step 18600: val accuracy 0.2930\n",
      "Step 18700: training accuracy 0.2250\n",
      "    sample pred: [2 9 9 9 3 3 3 3 9 9 0 9 9 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 22.   3.  39.  37.   0.   0.   0.   4.   8. 112.]\n",
      "Step 18700: val accuracy 0.2082\n",
      "Step 18800: training accuracy 0.3000\n",
      "    sample pred: [7 0 9 1 6 6 6 6 9 9 0 9 6 9 1 0 0 6 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [91. 22.  0.  1. 25.  0. 80. 27. 36. 18.]\n",
      "Step 18800: val accuracy 0.3018\n",
      "Step 18900: training accuracy 0.3040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample pred: [7 0 9 1 5 4 4 4 4 9 0 9 4 9 1 0 4 5 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [83. 37.  0. 14. 74. 43.  0. 16.  2. 35.]\n",
      "Step 18900: val accuracy 0.2916\n",
      "Step 19000: training accuracy 0.2330\n",
      "    sample pred: [7 0 0 1 5 5 7 5 7 7 0 7 7 9 1 0 0 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [98. 24.  0.  0.  0. 32.  0. 75.  2.  2.]\n",
      "Step 19000: val accuracy 0.2180\n",
      "Step 19100: training accuracy 0.3510\n",
      "    sample pred: [7 2 9 1 5 2 2 5 2 9 0 9 2 9 1 0 1 7 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [39. 52. 67.  1.  1. 34. 25. 73.  0. 59.]\n",
      "Step 19100: val accuracy 0.3274\n",
      "Step 19200: training accuracy 0.2450\n",
      "    sample pred: [4 1 1 1 3 4 4 4 1 1 8 1 1 1 1 4 1 4 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 73.  5. 12. 65. 14. 21.  2. 42. 10.]\n",
      "Step 19200: val accuracy 0.2524\n",
      "Step 19300: training accuracy 0.2140\n",
      "    sample pred: [6 6 9 6 6 6 6 6 6 9 0 6 6 9 9 0 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [61.  0.  0.  0.  4.  0. 93.  0. 27. 29.]\n",
      "Step 19300: val accuracy 0.2170\n",
      "Step 19400: training accuracy 0.2800\n",
      "    sample pred: [6 0 1 1 3 6 3 3 3 1 0 3 3 1 1 0 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [91. 46.  1. 52. 34.  0. 51.  0.  5.  0.]\n",
      "Step 19400: val accuracy 0.2820\n",
      "Step 19500: training accuracy 0.3460\n",
      "    sample pred: [7 9 9 1 5 1 3 5 9 9 0 9 9 9 1 0 1 7 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [26. 48.  2. 13. 29. 35. 29. 72.  0. 92.]\n",
      "Step 19500: val accuracy 0.3124\n",
      "Step 19600: training accuracy 0.2650\n",
      "    sample pred: [7 8 1 1 3 1 4 8 1 1 8 1 1 1 1 0 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8. 67.  0.  5. 43.  0.  1. 58. 81.  2.]\n",
      "Step 19600: val accuracy 0.2650\n",
      "Step 19700: training accuracy 0.2280\n",
      "    sample pred: [5 9 9 9 3 1 3 5 9 9 0 9 9 9 9 0 9 5 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 33.  15.   2.  23.   2.  26.   8.   7.   2. 110.]\n",
      "Step 19700: val accuracy 0.2112\n",
      "Step 19800: training accuracy 0.2330\n",
      "    sample pred: [7 0 1 1 6 1 6 1 1 1 0 1 0 1 1 0 1 6 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [90. 64.  0.  1.  0.  0. 63. 13.  2.  0.]\n",
      "Step 19800: val accuracy 0.2382\n",
      "Step 19900: training accuracy 0.2760\n",
      "    sample pred: [7 5 1 1 5 6 5 5 1 1 8 5 5 1 1 5 4 5 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 39.  1.  0. 32. 74. 52. 12. 66.  0.]\n",
      "Step 19900: val accuracy 0.2924\n",
      "Step 20000: training accuracy 0.2440\n",
      "    sample pred: [7 0 0 1 3 4 7 5 7 9 0 9 0 9 1 0 0 7 3 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [100.  17.   0.  13.  15.  19.   3.  65.   1.  11.]\n",
      "Step 20000: val accuracy 0.2278\n",
      "Step 20100: training accuracy 0.2730\n",
      "    sample pred: [7 0 0 1 5 4 0 4 1 9 0 9 0 9 1 0 0 7 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [101.  34.   0.   1.  36.  23.   6.  27.   1.  44.]\n",
      "Step 20100: val accuracy 0.2472\n",
      "Step 20200: training accuracy 0.3010\n",
      "    sample pred: [7 9 9 1 2 1 2 2 2 9 8 9 2 9 1 2 2 7 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 48. 76.  1.  2.  0.  3. 68. 48. 55.]\n",
      "Step 20200: val accuracy 0.2928\n",
      "Step 20300: training accuracy 0.2330\n",
      "    sample pred: [2 9 9 9 3 2 3 3 9 9 0 9 9 9 9 2 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  7.   0.  59.  45.   1.   0.   2.  11.   0. 108.]\n",
      "Step 20300: val accuracy 0.2162\n",
      "Step 20400: training accuracy 0.2480\n",
      "    sample pred: [2 0 1 1 2 1 2 1 1 1 0 1 1 1 1 0 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [74. 65. 41.  0. 29.  1.  0. 32.  6.  0.]\n",
      "Step 20400: val accuracy 0.2608\n",
      "Step 20500: training accuracy 0.3020\n",
      "    sample pred: [7 0 1 1 5 1 5 5 1 1 0 1 1 1 1 0 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [66. 70.  1.  0. 43. 47. 22. 49.  4.  0.]\n",
      "Step 20500: val accuracy 0.2968\n",
      "Step 20600: training accuracy 0.2520\n",
      "    sample pred: [7 9 9 1 3 1 3 3 1 9 0 9 9 9 1 1 1 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 57.  3. 44.  0.  0. 11. 43.  0. 93.]\n",
      "Step 20600: val accuracy 0.2174\n",
      "Step 20700: training accuracy 0.2770\n",
      "    sample pred: [7 5 9 5 5 4 5 5 7 9 8 5 5 9 9 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  0.  0. 34. 82. 13. 58. 57. 33.]\n",
      "Step 20700: val accuracy 0.2618\n",
      "Step 20800: training accuracy 0.2760\n",
      "    sample pred: [7 6 9 5 6 6 6 6 6 9 8 6 6 9 9 6 6 5 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  3.  1.  0. 35. 38. 81. 22. 78. 18.]\n",
      "Step 20800: val accuracy 0.2752\n",
      "Step 20900: training accuracy 0.2660\n",
      "    sample pred: [7 5 7 5 5 5 5 5 7 7 0 5 5 9 1 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 10. 20.  3.  0. 61.  6. 75. 63.  5.]\n",
      "Step 20900: val accuracy 0.2702\n",
      "Step 21000: training accuracy 0.2430\n",
      "    sample pred: [6 6 6 6 6 6 6 6 6 6 0 6 6 6 1 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8. 11.  0.  0. 35.  0. 90. 29. 69.  1.]\n",
      "Step 21000: val accuracy 0.2494\n",
      "Step 21100: training accuracy 0.3000\n",
      "    sample pred: [7 9 9 1 6 6 6 6 1 9 0 9 9 9 1 0 6 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [36. 51.  0.  0.  0.  0. 77. 44.  4. 88.]\n",
      "Step 21100: val accuracy 0.2818\n",
      "Step 21200: training accuracy 0.2970\n",
      "    sample pred: [7 9 1 1 5 1 5 5 1 9 8 9 1 9 1 5 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 64. 21.  8.  1. 51.  0. 23. 64. 65.]\n",
      "Step 21200: val accuracy 0.2810\n",
      "Step 21300: training accuracy 0.2990\n",
      "    sample pred: [6 0 1 1 3 4 3 3 1 1 0 1 1 1 1 0 1 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [45. 66.  0. 29. 51.  0. 46.  5. 57.  0.]\n",
      "Step 21300: val accuracy 0.3098\n",
      "Step 21400: training accuracy 0.2170\n",
      "    sample pred: [2 2 9 8 3 2 2 8 2 9 8 9 2 9 9 2 2 2 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7.  0. 89.  8.  1.  1.  7.  0. 77. 27.]\n",
      "Step 21400: val accuracy 0.2184\n",
      "Step 21500: training accuracy 0.2620\n",
      "    sample pred: [7 0 1 1 5 5 5 5 1 1 0 5 5 1 1 0 1 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [58. 55.  2.  3.  1. 77.  0. 52.  8.  6.]\n",
      "Step 21500: val accuracy 0.2646\n",
      "Step 21600: training accuracy 0.3120\n",
      "    sample pred: [6 0 9 1 6 6 6 6 2 9 0 9 6 9 1 0 6 5 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [81. 31. 14.  0.  6. 35. 83.  0.  1. 61.]\n",
      "Step 21600: val accuracy 0.2940\n",
      "Step 21700: training accuracy 0.2840\n",
      "    sample pred: [7 9 9 5 5 5 5 5 2 9 0 9 5 9 9 5 2 5 9 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3.  5. 39.  1. 13. 73.  0. 65.  1. 84.]\n",
      "Step 21700: val accuracy 0.2532\n",
      "Step 21800: training accuracy 0.2760\n",
      "    sample pred: [6 0 9 1 6 6 6 6 1 9 0 9 0 9 1 0 0 6 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [97. 27.  0.  0.  1. 10. 86.  6.  1. 48.]\n",
      "Step 21800: val accuracy 0.2642\n",
      "Step 21900: training accuracy 0.3730\n",
      "    sample pred: [7 9 9 1 5 4 4 4 2 9 0 9 7 9 1 0 2 7 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [50. 36. 50.  0. 46. 35.  0. 67.  4. 85.]\n",
      "Step 21900: val accuracy 0.3192\n",
      "Step 22000: training accuracy 0.2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample pred: [2 0 1 1 3 4 2 4 2 1 0 9 0 1 1 0 0 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [97. 38. 33.  3. 43.  0.  0. 36. 12.  7.]\n",
      "Step 22000: val accuracy 0.2668\n",
      "Step 22100: training accuracy 0.2910\n",
      "    sample pred: [7 0 9 0 6 6 6 6 2 9 0 9 0 9 9 0 0 6 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [92.  5.  3.  0.  4.  3. 77. 26. 37. 44.]\n",
      "Step 22100: val accuracy 0.2794\n",
      "Step 22200: training accuracy 0.2680\n",
      "    sample pred: [7 9 1 1 3 1 3 1 1 1 0 9 1 1 1 7 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 77. 36. 17.  0.  0. 43. 57.  2. 32.]\n",
      "Step 22200: val accuracy 0.2586\n",
      "Step 22300: training accuracy 0.2730\n",
      "    sample pred: [4 8 8 1 3 4 4 4 1 8 8 8 4 9 1 8 4 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 26.  0. 18. 73. 27. 18.  5. 92. 10.]\n",
      "Step 22300: val accuracy 0.2780\n",
      "Step 22400: training accuracy 0.2840\n",
      "    sample pred: [7 3 1 1 5 6 3 5 1 1 0 3 7 1 1 7 3 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 54.  0. 41.  0. 50. 33. 79. 14. 10.]\n",
      "Step 22400: val accuracy 0.2796\n",
      "Step 22500: training accuracy 0.2500\n",
      "    sample pred: [5 8 8 8 5 4 4 8 1 8 8 8 4 9 1 8 4 5 4 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 16.  0.  0. 70. 41. 19.  1. 93.  9.]\n",
      "Step 22500: val accuracy 0.2468\n",
      "Step 22600: training accuracy 0.2390\n",
      "    sample pred: [2 9 9 9 3 4 3 4 9 9 8 9 9 9 9 9 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   1.   8.  33.  59.   0.   0.  14.  16. 108.]\n",
      "Step 22600: val accuracy 0.2242\n",
      "Step 22700: training accuracy 0.3130\n",
      "    sample pred: [2 6 1 1 5 6 6 5 1 1 0 1 6 1 1 0 1 5 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [39. 62. 16.  1.  0. 45. 75. 44. 31.  0.]\n",
      "Step 22700: val accuracy 0.3102\n",
      "Step 22800: training accuracy 0.2470\n",
      "    sample pred: [2 9 1 1 3 4 2 4 1 9 0 9 1 9 1 2 1 2 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 70. 50.  2. 34.  1. 21.  3.  0. 63.]\n",
      "Step 22800: val accuracy 0.2458\n",
      "Step 22900: training accuracy 0.2080\n",
      "    sample pred: [2 2 1 1 5 2 2 5 2 1 0 2 2 9 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8. 39. 95.  1.  5. 21.  0. 23.  7.  9.]\n",
      "Step 22900: val accuracy 0.2006\n",
      "Step 23000: training accuracy 0.2970\n",
      "    sample pred: [2 0 1 1 8 8 2 8 2 1 8 8 2 1 1 0 2 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [44. 33. 58.  0. 21.  0. 14. 45. 82.  0.]\n",
      "Step 23000: val accuracy 0.2888\n",
      "Step 23100: training accuracy 0.2780\n",
      "    sample pred: [2 9 1 1 3 4 4 4 1 9 0 9 1 9 1 0 1 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [64. 60.  5.  3. 75.  6.  0.  3.  0. 62.]\n",
      "Step 23100: val accuracy 0.2702\n",
      "Step 23200: training accuracy 0.2520\n",
      "    sample pred: [7 3 8 5 3 4 3 3 3 8 8 3 3 9 8 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  1. 55. 63. 25.  7. 19. 79.  3.]\n",
      "Step 23200: val accuracy 0.2608\n",
      "Step 23300: training accuracy 0.2750\n",
      "    sample pred: [7 7 1 1 3 4 7 4 7 7 0 7 7 1 1 7 4 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 40.  1. 12. 46.  1.  0. 97. 72.  3.]\n",
      "Step 23300: val accuracy 0.2632\n",
      "Step 23400: training accuracy 0.2880\n",
      "    sample pred: [7 0 9 1 5 5 5 5 9 9 0 9 0 9 9 0 0 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [97. 17. 13.  0.  4. 49. 16. 18. 22. 52.]\n",
      "Step 23400: val accuracy 0.2716\n",
      "Step 23500: training accuracy 0.3130\n",
      "    sample pred: [7 3 9 5 3 5 3 5 3 3 0 3 3 9 9 0 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [58.  0. 18. 51. 18. 46. 12. 54. 37. 19.]\n",
      "Step 23500: val accuracy 0.3002\n",
      "Step 23600: training accuracy 0.3000\n",
      "    sample pred: [7 9 1 1 5 1 5 5 1 9 8 9 1 9 1 8 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 62. 22.  0.  0. 46. 24. 22. 75. 49.]\n",
      "Step 23600: val accuracy 0.3004\n",
      "Step 23700: training accuracy 0.2880\n",
      "    sample pred: [2 9 9 1 3 2 2 2 2 9 8 9 2 9 1 2 2 2 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 39. 85. 10.  3.  0. 27. 37.  1. 86.]\n",
      "Step 23700: val accuracy 0.2572\n",
      "Step 23800: training accuracy 0.3140\n",
      "    sample pred: [2 0 1 1 3 3 3 3 1 1 0 3 3 1 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [73. 43. 42. 58.  0. 13.  1. 24. 60.  0.]\n",
      "Step 23800: val accuracy 0.3030\n",
      "Step 23900: training accuracy 0.3130\n",
      "    sample pred: [4 0 9 1 3 4 3 3 1 9 0 9 3 9 1 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [76. 46.  0. 52. 48.  0.  2.  7.  1. 81.]\n",
      "Step 23900: val accuracy 0.2952\n",
      "Step 24000: training accuracy 0.3210\n",
      "    sample pred: [4 9 9 1 5 4 4 5 1 9 8 9 5 9 1 4 4 5 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 40.  0.  0. 70. 57. 27.  2. 49. 76.]\n",
      "Step 24000: val accuracy 0.3156\n",
      "Step 24100: training accuracy 0.2790\n",
      "    sample pred: [7 9 1 1 5 1 5 5 1 9 0 9 5 9 1 5 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6. 70.  0.  2.  9. 70. 23. 31.  0. 68.]\n",
      "Step 24100: val accuracy 0.2542\n",
      "Step 24200: training accuracy 0.2690\n",
      "    sample pred: [7 8 8 5 5 5 5 5 3 8 8 5 5 9 1 5 3 5 5 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 22.  0. 28. 10. 61.  0. 65. 80.  3.]\n",
      "Step 24200: val accuracy 0.2606\n",
      "Step 24300: training accuracy 0.2620\n",
      "    sample pred: [6 9 9 9 6 4 9 8 9 9 0 9 9 9 9 0 9 6 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 35.   0.   0.   0.  21.   3.  37.   3.  55. 108.]\n",
      "Step 24300: val accuracy 0.2408\n",
      "Step 24400: training accuracy 0.2050\n",
      "    sample pred: [7 1 1 1 1 1 4 1 1 1 0 1 1 1 1 0 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [21. 85.  3.  0. 44.  0.  3. 37.  4.  8.]\n",
      "Step 24400: val accuracy 0.2024\n",
      "Step 24500: training accuracy 0.2890\n",
      "    sample pred: [7 6 9 1 6 6 6 6 7 9 8 6 6 9 1 7 6 7 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 24.  2.  5.  4.  0. 85. 79. 64. 26.]\n",
      "Step 24500: val accuracy 0.2850\n",
      "Step 24600: training accuracy 0.1530\n",
      "    sample pred: [4 4 4 3 3 4 4 4 4 9 8 4 4 9 4 4 3 3 4 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  0.  0. 28. 86.  0.  3.  7. 21.  8.]\n",
      "Step 24600: val accuracy 0.1742\n",
      "Step 24700: training accuracy 0.2680\n",
      "    sample pred: [2 0 1 1 5 2 2 5 2 1 8 1 2 1 1 0 2 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 42. 80.  0.  0. 37.  0.  0. 49.  0.]\n",
      "Step 24700: val accuracy 0.2700\n",
      "Step 24800: training accuracy 0.2210\n",
      "    sample pred: [7 1 1 1 3 1 3 1 1 1 8 1 1 1 1 1 1 7 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 84.  0. 22. 44.  0. 17. 49.  0.  5.]\n",
      "Step 24800: val accuracy 0.2084\n",
      "Step 24900: training accuracy 0.2990\n",
      "    sample pred: [5 0 1 1 5 4 5 5 1 9 0 9 5 9 1 0 5 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [65. 41.  0.  0. 42. 71.  2.  0. 51. 27.]\n",
      "Step 24900: val accuracy 0.2984\n",
      "Step 25000: training accuracy 0.2730\n",
      "    sample pred: [7 9 9 8 8 8 8 8 9 9 8 9 9 9 9 8 8 7 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 20.  4.  0. 12.  3. 22. 46. 92. 74.]\n",
      "Step 25000: val accuracy 0.2466\n",
      "Step 25100: training accuracy 0.2880\n",
      "    sample pred: [2 9 9 1 3 1 2 1 1 9 0 9 2 9 1 0 1 2 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [54. 55. 74.  8.  1.  0.  0. 16.  0. 80.]\n",
      "Step 25100: val accuracy 0.2636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25200: training accuracy 0.2910\n",
      "    sample pred: [7 9 9 9 5 8 5 8 9 9 8 9 9 9 9 8 9 5 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  2.   3.   0.   0.  24.  30.   3.  52.  71. 106.]\n",
      "Step 25200: val accuracy 0.2582\n",
      "Step 25300: training accuracy 0.2400\n",
      "    sample pred: [7 5 1 5 5 4 5 5 2 9 0 5 5 9 1 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [12. 36.  6.  0. 29. 88.  7. 33.  0. 29.]\n",
      "Step 25300: val accuracy 0.2340\n",
      "Step 25400: training accuracy 0.2650\n",
      "    sample pred: [7 0 0 1 5 1 0 1 1 9 0 9 0 9 1 0 0 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [102.  34.   1.   0.   0.  12.  30.  56.   3.  27.]\n",
      "Step 25400: val accuracy 0.2456\n",
      "Step 25500: training accuracy 0.3680\n",
      "    sample pred: [2 9 9 1 3 4 3 3 2 9 0 9 3 9 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [35. 41. 28. 63. 35.  0. 30.  8. 70. 58.]\n",
      "Step 25500: val accuracy 0.3438\n",
      "Step 25600: training accuracy 0.3280\n",
      "    sample pred: [7 0 1 1 5 4 3 3 1 1 0 7 7 1 1 0 1 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [93. 52.  0. 21. 32. 40. 12. 76.  1.  1.]\n",
      "Step 25600: val accuracy 0.3012\n",
      "Step 25700: training accuracy 0.2780\n",
      "    sample pred: [6 6 1 1 6 6 6 6 2 1 8 6 6 1 1 0 2 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [29. 32. 40.  1.  0.  1. 87. 31. 53.  4.]\n",
      "Step 25700: val accuracy 0.2744\n",
      "Step 25800: training accuracy 0.2760\n",
      "    sample pred: [2 8 9 8 3 4 3 8 2 9 8 8 8 9 9 8 3 4 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6.  2. 16. 24. 40.  1. 28. 18. 94. 47.]\n",
      "Step 25800: val accuracy 0.2702\n",
      "Step 25900: training accuracy 0.3120\n",
      "    sample pred: [7 9 1 1 5 5 5 5 1 9 8 9 5 9 1 5 1 5 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 46.  0.  7.  7. 68. 16. 37. 51. 80.]\n",
      "Step 25900: val accuracy 0.3038\n",
      "Step 26000: training accuracy 0.3430\n",
      "    sample pred: [6 0 1 1 5 4 4 4 1 1 0 5 5 1 1 0 4 5 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [67. 34.  0.  0. 70. 47. 49. 10. 65.  1.]\n",
      "Step 26000: val accuracy 0.3224\n",
      "Step 26100: training accuracy 0.2940\n",
      "    sample pred: [6 6 1 1 6 4 4 4 2 9 8 9 6 9 1 4 4 4 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 45. 24.  7. 62.  4. 60.  0. 70. 22.]\n",
      "Step 26100: val accuracy 0.3054\n",
      "Step 26200: training accuracy 0.2820\n",
      "    sample pred: [2 3 1 1 3 2 2 3 2 9 8 3 2 9 1 2 2 2 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 37. 78. 38.  0.  0.  2. 39. 70. 14.]\n",
      "Step 26200: val accuracy 0.2820\n",
      "Step 26300: training accuracy 0.1430\n",
      "    sample pred: [7 7 7 7 7 7 7 7 7 7 0 7 7 7 7 7 7 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 17.   4.   0.   0.   1.   0.   0. 109.  12.   0.]\n",
      "Step 26300: val accuracy 0.1358\n",
      "Step 26400: training accuracy 0.2360\n",
      "    sample pred: [7 3 9 3 3 3 3 3 3 9 0 3 3 9 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [10. 22.  0. 87. 20.  0.  0. 45.  4. 48.]\n",
      "Step 26400: val accuracy 0.2282\n",
      "Step 26500: training accuracy 0.1880\n",
      "    sample pred: [5 5 1 5 5 5 5 5 1 1 8 5 5 1 1 5 5 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 48.  1.  0.  5. 87.  0. 15. 16. 16.]\n",
      "Step 26500: val accuracy 0.1984\n",
      "Step 26600: training accuracy 0.2810\n",
      "    sample pred: [7 9 1 1 3 1 3 3 1 1 8 9 1 1 1 1 1 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 63. 40. 47.  4.  1.  0. 37. 62. 27.]\n",
      "Step 26600: val accuracy 0.2772\n",
      "Step 26700: training accuracy 0.2780\n",
      "    sample pred: [7 9 9 5 5 4 4 4 9 9 0 9 4 9 9 4 4 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1.  3.  2. 25. 75. 30. 14. 60.  0. 68.]\n",
      "Step 26700: val accuracy 0.2488\n",
      "Step 26800: training accuracy 0.2770\n",
      "    sample pred: [2 0 9 1 3 2 2 3 2 9 0 9 2 9 1 0 2 2 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [88. 16. 72. 26.  0.  6.  4.  0.  0. 65.]\n",
      "Step 26800: val accuracy 0.2620\n",
      "Step 26900: training accuracy 0.2990\n",
      "    sample pred: [2 2 1 1 6 2 2 8 2 9 8 9 2 9 1 2 2 5 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 40. 78.  0.  0. 22. 35. 28. 78. 18.]\n",
      "Step 26900: val accuracy 0.2928\n",
      "Step 27000: training accuracy 0.2700\n",
      "    sample pred: [7 9 9 6 6 6 6 6 2 9 0 9 6 9 9 7 6 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [10.  5. 18.  7.  9.  0. 87. 75.  2. 57.]\n",
      "Step 27000: val accuracy 0.2492\n",
      "Step 27100: training accuracy 0.2950\n",
      "    sample pred: [2 2 1 1 6 4 2 4 2 9 8 9 2 9 1 2 2 2 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8. 46. 73.  1. 25.  0. 53.  9. 50. 30.]\n",
      "Step 27100: val accuracy 0.2994\n",
      "Step 27200: training accuracy 0.3650\n",
      "    sample pred: [6 0 9 5 5 6 5 5 9 9 0 9 5 9 1 0 5 5 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [57. 35.  0.  1.  0. 67. 63. 37. 24. 81.]\n",
      "Step 27200: val accuracy 0.3346\n",
      "Step 27300: training accuracy 0.3330\n",
      "    sample pred: [6 0 1 1 6 6 6 6 9 9 0 9 6 9 1 0 6 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [55. 43.  1.  0.  0. 13. 88. 21. 44. 68.]\n",
      "Step 27300: val accuracy 0.3108\n",
      "Step 27400: training accuracy 0.2870\n",
      "    sample pred: [6 3 1 1 3 3 3 3 3 9 8 9 3 9 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 42.  2. 85. 17.  0. 22.  0. 39. 57.]\n",
      "Step 27400: val accuracy 0.2846\n",
      "Step 27500: training accuracy 0.2800\n",
      "    sample pred: [2 8 1 1 6 6 6 8 2 9 8 9 6 9 1 8 2 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 32. 36.  4.  7.  0. 83.  0. 84. 33.]\n",
      "Step 27500: val accuracy 0.2822\n",
      "Step 27600: training accuracy 0.3360\n",
      "    sample pred: [7 0 8 8 3 4 3 3 2 9 8 3 3 9 1 0 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [42. 13.  7. 45. 40.  0. 38. 53. 89.  9.]\n",
      "Step 27600: val accuracy 0.3220\n",
      "Step 27700: training accuracy 0.2500\n",
      "    sample pred: [2 2 1 1 3 4 2 3 2 9 0 9 2 9 1 2 2 2 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31. 27. 80. 37. 30.  0.  0.  5. 14. 26.]\n",
      "Step 27700: val accuracy 0.2492\n",
      "Step 27800: training accuracy 0.2620\n",
      "    sample pred: [7 3 1 3 3 3 3 3 3 3 8 3 3 9 1 7 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 9. 20.  5. 72.  0. 15.  0. 74. 54. 13.]\n",
      "Step 27800: val accuracy 0.2684\n",
      "Step 27900: training accuracy 0.3390\n",
      "    sample pred: [7 0 9 5 5 4 5 5 9 9 0 9 5 9 9 0 2 5 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [65.  0. 42.  0. 32. 57.  1. 57.  1. 84.]\n",
      "Step 27900: val accuracy 0.3104\n",
      "Step 28000: training accuracy 0.2700\n",
      "    sample pred: [2 3 1 1 5 5 3 3 1 1 0 3 5 9 1 0 3 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [38. 58. 27. 48.  0. 57.  0. 11. 14. 17.]\n",
      "Step 28000: val accuracy 0.2538\n",
      "Step 28100: training accuracy 0.3590\n",
      "    sample pred: [7 0 1 1 6 1 2 8 2 9 0 9 1 9 1 0 1 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [51. 55. 28.  2.  6.  2. 42. 67. 68. 38.]\n",
      "Step 28100: val accuracy 0.3424\n",
      "Step 28200: training accuracy 0.2650\n",
      "    sample pred: [7 0 1 1 3 1 3 1 1 1 0 3 1 1 1 0 1 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31. 72.  7. 38.  0. 19.  8. 28. 62.  0.]\n",
      "Step 28200: val accuracy 0.2692\n",
      "Step 28300: training accuracy 0.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample pred: [6 8 9 8 3 8 3 8 3 9 8 9 3 9 1 8 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 19.  0. 49. 10. 17. 43. 11. 94. 31.]\n",
      "Step 28300: val accuracy 0.2578\n",
      "Step 28400: training accuracy 0.2390\n",
      "    sample pred: [2 4 1 1 6 4 4 4 2 1 0 5 4 1 1 4 2 4 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7. 49. 27.  2. 76. 18. 50.  4.  6.  0.]\n",
      "Step 28400: val accuracy 0.2414\n",
      "Step 28500: training accuracy 0.2860\n",
      "    sample pred: [7 0 1 1 3 4 3 3 1 9 0 3 0 9 1 0 3 3 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [98. 50.  1. 37. 41. 25.  0. 16.  0. 18.]\n",
      "Step 28500: val accuracy 0.2742\n",
      "Step 28600: training accuracy 0.2900\n",
      "    sample pred: [7 8 1 1 5 4 4 4 1 9 8 9 4 9 1 4 4 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 39.  0.  0. 85. 14. 11. 34. 77. 30.]\n",
      "Step 28600: val accuracy 0.2886\n",
      "Step 28700: training accuracy 0.3380\n",
      "    sample pred: [2 9 9 1 3 2 2 8 2 9 8 9 2 9 9 2 2 5 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 10. 76. 12.  8. 20. 27. 22. 68. 90.]\n",
      "Step 28700: val accuracy 0.3074\n",
      "Step 28800: training accuracy 0.3090\n",
      "    sample pred: [7 9 9 1 3 6 3 3 1 9 0 9 7 9 9 7 1 7 9 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [14. 43.  0. 20.  0. 32. 29. 91.  1. 79.]\n",
      "Step 28800: val accuracy 0.2814\n",
      "Step 28900: training accuracy 0.2040\n",
      "    sample pred: [5 4 4 5 5 4 4 4 4 9 0 5 5 9 9 5 4 4 5 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [24.  0.  0.  4. 80. 55.  7. 14.  0. 20.]\n",
      "Step 28900: val accuracy 0.1944\n",
      "Step 29000: training accuracy 0.2660\n",
      "    sample pred: [2 2 1 1 3 4 3 3 2 1 0 9 2 9 1 0 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [37. 41. 51. 45. 54.  0.  0.  5. 10. 23.]\n",
      "Step 29000: val accuracy 0.2708\n",
      "Step 29100: training accuracy 0.2290\n",
      "    sample pred: [2 3 1 1 3 3 3 3 2 1 8 3 3 1 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 9. 34. 24. 83.  1.  0.  3. 30. 45.  0.]\n",
      "Step 29100: val accuracy 0.2512\n",
      "Step 29200: training accuracy 0.2250\n",
      "    sample pred: [6 0 1 1 6 1 0 1 1 1 0 1 0 1 1 0 1 6 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [96. 59.  1.  2. 17.  0. 40.  3.  5.  2.]\n",
      "Step 29200: val accuracy 0.2260\n",
      "Step 29300: training accuracy 0.3120\n",
      "    sample pred: [7 0 7 8 5 2 2 8 2 7 0 7 2 9 9 0 2 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [64.  4. 58.  0.  3. 17. 14. 81. 58. 13.]\n",
      "Step 29300: val accuracy 0.2912\n",
      "Step 29400: training accuracy 0.1840\n",
      "    sample pred: [2 0 0 0 3 4 3 3 2 0 0 3 0 0 0 0 0 3 3 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [104.   0.  15.  32.   9.   4.  16.   4.   0.   0.]\n",
      "Step 29400: val accuracy 0.1718\n",
      "Step 29500: training accuracy 0.2890\n",
      "    sample pred: [6 0 1 1 6 6 6 6 1 1 0 9 0 1 1 0 0 6 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [95. 48.  0.  0.  1. 11. 70. 42. 17.  5.]\n",
      "Step 29500: val accuracy 0.2818\n",
      "Step 29600: training accuracy 0.3230\n",
      "    sample pred: [7 0 1 1 3 1 3 3 1 1 8 3 3 1 1 0 1 7 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [65. 52.  1. 51.  4.  0. 17. 76. 57.  0.]\n",
      "Step 29600: val accuracy 0.3146\n",
      "Step 29700: training accuracy 0.2360\n",
      "    sample pred: [5 5 1 1 5 5 5 5 2 1 8 3 5 1 1 5 1 5 5 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 46. 26. 21.  3. 71. 13. 22. 34.  0.]\n",
      "Step 29700: val accuracy 0.2558\n",
      "Step 29800: training accuracy 0.2720\n",
      "    sample pred: [4 9 1 1 5 4 4 1 1 9 0 9 1 9 1 0 1 4 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [54. 68.  0.  0. 50. 12.  8.  0.  7. 73.]\n",
      "Step 29800: val accuracy 0.2646\n",
      "Step 29900: training accuracy 0.3110\n",
      "    sample pred: [6 6 8 3 3 4 3 4 3 9 8 3 6 9 9 0 4 4 3 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [33.  5.  0. 27. 59.  9. 64. 30. 63. 21.]\n",
      "Step 29900: val accuracy 0.2986\n",
      "Step 30000: training accuracy 0.3090\n",
      "    sample pred: [2 9 9 5 5 6 3 5 2 9 8 9 5 9 9 5 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 2.  1. 21. 34.  0. 55. 27. 11. 72. 86.]\n",
      "Step 30000: val accuracy 0.2916\n",
      "Step 30100: training accuracy 0.4050\n",
      "    sample pred: [7 9 9 1 6 4 6 6 6 9 0 9 6 9 9 0 6 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [50. 23.  1. 11. 42.  0. 78. 63. 49. 88.]\n",
      "Step 30100: val accuracy 0.3502\n",
      "Step 30200: training accuracy 0.2900\n",
      "    sample pred: [5 9 1 1 5 5 3 3 1 9 8 9 3 9 1 5 3 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 47.  5. 49.  2. 58.  7. 14. 60. 47.]\n",
      "Step 30200: val accuracy 0.2772\n",
      "Step 30300: training accuracy 0.3280\n",
      "    sample pred: [7 4 1 1 6 4 6 4 1 1 0 9 7 1 1 7 4 7 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [31. 54.  0.  0. 55. 13. 57. 76. 29. 13.]\n",
      "Step 30300: val accuracy 0.3110\n",
      "Step 30400: training accuracy 0.2890\n",
      "    sample pred: [7 9 9 5 5 5 5 5 3 9 0 9 5 9 9 7 3 5 5 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6.  0. 26. 21.  0. 65. 13. 81.  0. 77.]\n",
      "Step 30400: val accuracy 0.2532\n",
      "Step 30500: training accuracy 0.3310\n",
      "    sample pred: [6 9 9 1 5 6 5 5 1 9 0 9 5 9 1 5 6 5 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [24. 37.  0.  0. 12. 72. 64. 52.  7. 63.]\n",
      "Step 30500: val accuracy 0.3078\n",
      "Step 30600: training accuracy 0.3190\n",
      "    sample pred: [2 9 9 1 4 4 4 4 2 9 0 9 4 9 1 0 4 4 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [40. 24.  2.  0. 78.  0. 12. 43. 26. 94.]\n",
      "Step 30600: val accuracy 0.2894\n",
      "Step 30700: training accuracy 0.3080\n",
      "    sample pred: [2 0 1 1 2 4 2 4 2 1 0 9 2 1 1 0 2 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [76. 63. 50.  0. 29.  0.  8. 59.  3. 20.]\n",
      "Step 30700: val accuracy 0.2982\n",
      "Step 30800: training accuracy 0.3500\n",
      "    sample pred: [6 0 1 1 6 4 6 6 2 1 0 1 6 1 1 0 2 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [62. 57. 31.  1. 36.  0. 76. 46. 41.  0.]\n",
      "Step 30800: val accuracy 0.3258\n",
      "Step 30900: training accuracy 0.3550\n",
      "    sample pred: [7 3 9 1 3 4 3 3 1 9 0 9 3 1 1 0 1 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [51. 59.  0. 51. 61.  0. 36. 29. 25. 43.]\n",
      "Step 30900: val accuracy 0.3370\n",
      "Step 31000: training accuracy 0.2390\n",
      "    sample pred: [2 3 1 1 3 2 3 3 2 1 8 3 2 1 1 2 2 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 50. 76. 55.  1.  0. 20.  7. 21.  9.]\n",
      "Step 31000: val accuracy 0.2428\n",
      "Step 31100: training accuracy 0.3410\n",
      "    sample pred: [7 9 9 1 3 6 3 3 9 9 8 9 3 9 9 7 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7. 21.  2. 49.  0.  0. 41. 66. 74. 81.]\n",
      "Step 31100: val accuracy 0.3196\n",
      "Step 31200: training accuracy 0.3240\n",
      "    sample pred: [7 8 1 1 6 4 6 4 2 1 8 7 6 1 1 7 1 7 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 44. 11.  4. 50.  0. 67. 65. 79.  0.]\n",
      "Step 31200: val accuracy 0.3284\n",
      "Step 31300: training accuracy 0.2760\n",
      "    sample pred: [5 0 0 1 5 6 5 5 2 9 0 5 0 9 1 0 0 5 5 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [98. 20.  1.  0. 20. 53. 45. 21.  0. 18.]\n",
      "Step 31300: val accuracy 0.2754\n",
      "Step 31400: training accuracy 0.2260\n",
      "    sample pred: [6 8 8 8 5 6 6 8 2 8 8 8 8 8 8 8 6 5 8 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 2.  0.  2.  0.  6. 33. 75. 15. 93.  0.]\n",
      "Step 31400: val accuracy 0.2350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31500: training accuracy 0.2880\n",
      "    sample pred: [5 9 9 5 5 5 5 5 9 9 0 9 5 9 9 0 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [39. 26.  0.  3.  3. 82.  1. 45.  5. 84.]\n",
      "Step 31500: val accuracy 0.2676\n",
      "Step 31600: training accuracy 0.3500\n",
      "    sample pred: [7 9 9 5 5 4 5 5 9 9 0 9 7 9 9 7 3 7 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [27.  2.  0. 12. 22. 49. 35. 83. 34. 86.]\n",
      "Step 31600: val accuracy 0.3236\n",
      "Step 31700: training accuracy 0.1990\n",
      "    sample pred: [6 6 9 1 6 6 6 6 3 9 8 9 6 9 1 6 6 6 3 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 37.  0. 11.  0.  1. 92.  0. 16. 42.]\n",
      "Step 31700: val accuracy 0.2040\n",
      "Step 31800: training accuracy 0.2640\n",
      "    sample pred: [2 4 9 1 5 4 4 4 2 9 0 9 4 9 1 4 4 5 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 52.  9.  0. 68. 45. 44.  2.  0. 40.]\n",
      "Step 31800: val accuracy 0.2708\n",
      "Step 31900: training accuracy 0.2760\n",
      "    sample pred: [7 2 7 1 3 4 3 3 2 7 0 3 7 1 1 7 3 7 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 33. 45. 38. 12.  8. 42. 86.  9.  0.]\n",
      "Step 31900: val accuracy 0.2732\n",
      "Step 32000: training accuracy 0.3080\n",
      "    sample pred: [5 9 9 1 5 1 5 5 1 9 8 9 5 9 1 5 1 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 40.  0.  6.  0. 76.  5. 46. 76. 58.]\n",
      "Step 32000: val accuracy 0.2842\n",
      "Step 32100: training accuracy 0.3000\n",
      "    sample pred: [5 5 1 1 5 4 5 4 1 9 8 5 5 1 1 0 1 5 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [36. 58.  0.  0. 68. 59.  0. 18. 36. 25.]\n",
      "Step 32100: val accuracy 0.2972\n",
      "Step 32200: training accuracy 0.3230\n",
      "    sample pred: [6 9 9 1 3 4 3 4 9 9 8 9 3 9 1 4 4 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8. 35.  0. 36. 64.  0. 21.  7. 63. 89.]\n",
      "Step 32200: val accuracy 0.3050\n",
      "Step 32300: training accuracy 0.1780\n",
      "    sample pred: [2 2 1 1 2 2 2 2 2 1 0 1 2 1 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 58. 92.  1.  0.  1. 12. 13.  0.  0.]\n",
      "Step 32300: val accuracy 0.1798\n",
      "Step 32400: training accuracy 0.3120\n",
      "    sample pred: [7 9 9 1 5 4 4 5 9 9 8 9 4 9 9 4 4 5 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 28.  0.  0. 77. 43. 10. 25. 34. 92.]\n",
      "Step 32400: val accuracy 0.2928\n",
      "Step 32500: training accuracy 0.3010\n",
      "    sample pred: [5 5 9 5 5 5 5 5 9 9 8 5 5 9 1 5 3 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 39. 11. 11. 27. 72.  8. 49. 22. 62.]\n",
      "Step 32500: val accuracy 0.2762\n",
      "Step 32600: training accuracy 0.3030\n",
      "    sample pred: [2 9 9 9 5 4 2 4 9 9 8 9 9 9 9 9 2 7 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   5.  51.   3.  21.   3.  26.  44.  43. 107.]\n",
      "Step 32600: val accuracy 0.2772\n",
      "Step 32700: training accuracy 0.2590\n",
      "    sample pred: [7 7 7 1 3 4 4 4 7 7 8 7 7 9 1 7 4 7 7 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  4.  19.   1.  10.  55.   0.  25. 100.  29.  16.]\n",
      "Step 32700: val accuracy 0.2524\n",
      "Step 32800: training accuracy 0.3140\n",
      "    sample pred: [7 9 9 1 5 4 7 5 9 9 8 9 7 9 1 7 1 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7. 36.  0.  0. 11. 33.  7. 96. 68. 56.]\n",
      "Step 32800: val accuracy 0.2800\n",
      "Step 32900: training accuracy 0.3320\n",
      "    sample pred: [6 8 9 1 6 6 6 8 1 9 8 9 6 9 1 8 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 46.  0. 17.  0.  9. 81. 40. 86. 53.]\n",
      "Step 32900: val accuracy 0.3062\n",
      "Step 33000: training accuracy 0.2760\n",
      "    sample pred: [2 0 9 3 3 3 3 3 3 9 0 9 3 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [94. 11. 17. 64.  1.  3. 12.  3.  7. 64.]\n",
      "Step 33000: val accuracy 0.2492\n",
      "Step 33100: training accuracy 0.2440\n",
      "    sample pred: [6 9 9 5 5 6 5 5 9 9 8 9 6 9 9 5 6 5 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  2.  0.  0.  1. 58. 71. 17.  3. 92.]\n",
      "Step 33100: val accuracy 0.2380\n",
      "Step 33200: training accuracy 0.3190\n",
      "    sample pred: [2 9 9 9 3 6 3 3 9 9 0 9 3 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [64.  2. 32. 54.  0.  0. 35. 35.  1. 96.]\n",
      "Step 33200: val accuracy 0.2894\n",
      "Step 33300: training accuracy 0.2170\n",
      "    sample pred: [5 0 1 1 5 1 0 1 1 9 0 9 0 1 1 0 1 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [100.  55.  13.   0.   0.  14.   7.   7.   0.  21.]\n",
      "Step 33300: val accuracy 0.2022\n",
      "Step 33400: training accuracy 0.2960\n",
      "    sample pred: [7 3 7 3 3 4 3 3 3 7 0 7 3 3 1 0 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [57.  4. 13. 64. 26.  0. 44. 78. 10.  0.]\n",
      "Step 33400: val accuracy 0.2804\n",
      "Step 33500: training accuracy 0.2690\n",
      "    sample pred: [5 0 9 5 5 4 5 5 3 9 0 5 5 9 1 0 4 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [73. 10.  0.  8. 26. 81.  1. 29. 12. 29.]\n",
      "Step 33500: val accuracy 0.2622\n",
      "Step 33600: training accuracy 0.2850\n",
      "    sample pred: [5 5 8 5 5 4 5 5 5 8 8 5 5 5 8 0 0 5 5 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [48.  2.  0.  0. 27. 65. 32. 25. 86.  0.]\n",
      "Step 33600: val accuracy 0.2840\n",
      "Step 33700: training accuracy 0.3030\n",
      "    sample pred: [6 0 9 5 5 6 6 6 6 9 0 9 6 9 9 0 0 5 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [86.  3.  2.  0.  8. 26. 80. 20. 51. 27.]\n",
      "Step 33700: val accuracy 0.2904\n",
      "Step 33800: training accuracy 0.2650\n",
      "    sample pred: [7 8 1 1 5 8 7 8 1 7 8 8 7 9 1 7 1 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 7. 42.  0.  0.  0. 37.  0. 87. 81. 11.]\n",
      "Step 33800: val accuracy 0.2668\n",
      "Step 33900: training accuracy 0.2160\n",
      "    sample pred: [2 1 1 1 3 1 2 1 1 1 8 1 1 1 1 2 1 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 77. 65. 15. 11.  2. 31.  0.  4. 11.]\n",
      "Step 33900: val accuracy 0.2170\n",
      "Step 34000: training accuracy 0.2360\n",
      "    sample pred: [2 2 1 1 5 2 2 3 2 9 0 9 2 9 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [19. 29. 92. 11.  0. 17. 10.  0. 24. 34.]\n",
      "Step 34000: val accuracy 0.2190\n",
      "Step 34100: training accuracy 0.2520\n",
      "    sample pred: [2 5 1 1 5 1 5 5 1 1 8 9 5 1 1 5 1 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 63. 35.  0.  1. 72. 20.  0. 48. 13.]\n",
      "Step 34100: val accuracy 0.2636\n",
      "Step 34200: training accuracy 0.2980\n",
      "    sample pred: [7 9 9 9 3 6 3 3 9 9 0 9 9 9 9 7 9 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 21.   0.   5.  18.   5.   8.  58.  68.   9. 106.]\n",
      "Step 34200: val accuracy 0.2688\n",
      "Step 34300: training accuracy 0.3370\n",
      "    sample pred: [2 0 1 1 3 2 3 3 2 9 0 9 3 9 1 0 2 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [75. 45. 55. 59. 22.  4.  1.  0. 41. 35.]\n",
      "Step 34300: val accuracy 0.3154\n",
      "Step 34400: training accuracy 0.3090\n",
      "    sample pred: [2 9 9 1 3 4 4 4 9 9 0 9 4 9 1 4 4 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [18. 48.  2. 15. 76.  0. 27.  0. 53. 70.]\n",
      "Step 34400: val accuracy 0.2990\n",
      "Step 34500: training accuracy 0.3400\n",
      "    sample pred: [7 3 9 1 3 4 3 3 9 9 8 9 3 9 9 3 3 7 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 4. 41.  0. 58. 37.  0. 27. 70. 15. 88.]\n",
      "Step 34500: val accuracy 0.3174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 34600: training accuracy 0.2740\n",
      "    sample pred: [6 6 1 1 6 6 6 6 3 1 0 6 6 9 1 0 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [63. 52.  1. 16. 22.  0. 89. 11.  0. 20.]\n",
      "Step 34600: val accuracy 0.2678\n",
      "Step 34700: training accuracy 0.3030\n",
      "    sample pred: [5 5 1 1 3 4 3 3 3 1 8 3 3 1 1 0 3 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 46. 14. 54. 54. 25.  0.  1. 79.  7.]\n",
      "Step 34700: val accuracy 0.2988\n",
      "Step 34800: training accuracy 0.2970\n",
      "    sample pred: [2 3 9 1 3 2 3 5 2 1 0 3 3 1 1 0 2 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [77. 41. 58. 48.  0. 23.  0. 27.  5. 18.]\n",
      "Step 34800: val accuracy 0.2984\n",
      "Step 34900: training accuracy 0.3060\n",
      "    sample pred: [7 8 9 1 4 4 4 4 2 9 8 9 7 9 1 7 4 7 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 42.  3.  0. 71.  0.  0. 66. 80. 44.]\n",
      "Step 34900: val accuracy 0.2958\n",
      "Step 35000: training accuracy 0.2970\n",
      "    sample pred: [7 8 9 8 3 8 7 8 2 9 8 9 8 9 9 8 2 7 9 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 18. 33.  7.  0.  1. 17. 69. 92. 60.]\n",
      "Step 35000: val accuracy 0.2638\n",
      "Step 35100: training accuracy 0.2960\n",
      "    sample pred: [7 9 9 3 3 4 3 4 3 9 0 9 7 9 9 7 3 7 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 2.  5.  1. 20. 38.  0. 61. 89.  1. 79.]\n",
      "Step 35100: val accuracy 0.2562\n",
      "Step 35200: training accuracy 0.3270\n",
      "    sample pred: [2 9 9 1 3 6 3 3 9 9 8 9 9 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 33.  32.  43.  36.   0.  24.  28.   6.  23. 102.]\n",
      "Step 35200: val accuracy 0.3058\n",
      "Step 35300: training accuracy 0.3350\n",
      "    sample pred: [7 2 9 1 6 2 2 3 2 9 8 9 7 9 1 2 2 7 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 34. 73.  6.  0.  3. 41. 83. 31. 61.]\n",
      "Step 35300: val accuracy 0.3018\n",
      "Step 35400: training accuracy 0.3660\n",
      "    sample pred: [7 0 0 1 6 4 4 4 2 9 0 9 7 9 1 0 4 7 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [83. 25. 12.  4. 53.  0. 49. 71. 44. 25.]\n",
      "Step 35400: val accuracy 0.3426\n",
      "Step 35500: training accuracy 0.2770\n",
      "    sample pred: [2 5 9 1 5 4 5 5 2 9 0 9 5 9 1 0 2 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [37. 37. 59.  0.  6. 70.  0.  0. 11. 57.]\n",
      "Step 35500: val accuracy 0.2678\n",
      "Step 35600: training accuracy 0.2770\n",
      "    sample pred: [2 9 9 9 3 4 3 3 9 9 0 9 9 9 9 0 0 3 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [75.  2.  3. 28. 29.  1. 38.  0.  5. 96.]\n",
      "Step 35600: val accuracy 0.2556\n",
      "Step 35700: training accuracy 0.3470\n",
      "    sample pred: [7 3 1 1 3 4 3 3 3 1 0 3 7 1 1 0 3 7 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 59. 30. 56. 13.  2. 37. 80.  6.  4.]\n",
      "Step 35700: val accuracy 0.3274\n",
      "Step 35800: training accuracy 0.1610\n",
      "    sample pred: [4 4 4 1 4 4 4 4 2 1 0 4 4 1 1 0 4 4 4 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [57. 11.  1.  0. 88.  0.  0.  0.  3.  1.]\n",
      "Step 35800: val accuracy 0.1718\n",
      "Step 35900: training accuracy 0.2380\n",
      "    sample pred: [2 2 9 5 5 2 2 5 2 9 0 5 2 9 1 2 2 5 5 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [10. 26. 81.  2.  9. 56. 34.  0.  0. 20.]\n",
      "Step 35900: val accuracy 0.2342\n",
      "Step 36000: training accuracy 0.2880\n",
      "    sample pred: [7 7 1 1 7 4 7 8 1 9 0 9 7 1 1 7 1 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 24.  57.  19.   0.   9.   0.   1. 100.  56.  22.]\n",
      "Step 36000: val accuracy 0.2688\n",
      "Step 36100: training accuracy 0.2190\n",
      "    sample pred: [5 5 1 5 5 5 5 5 2 9 0 5 5 9 1 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [19. 20. 15.  0.  0. 90.  0. 14. 37. 24.]\n",
      "Step 36100: val accuracy 0.2262\n",
      "Step 36200: training accuracy 0.2240\n",
      "    sample pred: [7 7 1 1 5 1 7 5 1 1 0 7 7 1 1 7 1 7 1 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 14.  52.   0.   0.   0.  25.   0. 101.  32.   0.]\n",
      "Step 36200: val accuracy 0.2268\n",
      "Step 36300: training accuracy 0.2490\n",
      "    sample pred: [5 0 0 1 3 5 3 5 1 9 0 9 0 9 1 0 0 5 1 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [101.  26.   5.  31.   0.  41.  28.   0.   2.  15.]\n",
      "Step 36300: val accuracy 0.2322\n",
      "Step 36400: training accuracy 0.3550\n",
      "    sample pred: [2 0 9 1 3 2 3 5 2 9 0 9 2 9 1 0 2 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [62. 49. 70. 17.  0. 26.  4. 18. 48. 61.]\n",
      "Step 36400: val accuracy 0.3252\n",
      "Step 36500: training accuracy 0.2850\n",
      "    sample pred: [7 7 1 1 3 6 3 5 2 1 8 1 7 1 1 7 2 7 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 56. 50.  9.  0. 41. 41. 87.  1.  0.]\n",
      "Step 36500: val accuracy 0.2740\n",
      "Step 36600: training accuracy 0.2360\n",
      "    sample pred: [6 9 9 3 3 6 3 3 9 9 0 9 3 9 9 3 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 8.  0.  0. 68. 16.  5. 45.  4.  1. 89.]\n",
      "Step 36600: val accuracy 0.2322\n",
      "Step 36700: training accuracy 0.2600\n",
      "    sample pred: [2 2 1 1 3 2 3 3 2 1 0 3 2 1 1 2 2 3 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 47. 79. 23.  2. 15. 43.  0. 46.  0.]\n",
      "Step 36700: val accuracy 0.2756\n",
      "Step 36800: training accuracy 0.2390\n",
      "    sample pred: [2 0 9 5 5 5 5 5 9 9 0 9 0 9 9 0 0 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [101.   2.   7.   6.   3.  47.  24.   0.   0.  49.]\n",
      "Step 36800: val accuracy 0.2168\n",
      "Step 36900: training accuracy 0.2650\n",
      "    sample pred: [7 5 1 1 5 4 5 5 1 1 8 5 5 1 1 5 3 5 5 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 43.  5. 16. 20. 76. 12. 54. 36.  3.]\n",
      "Step 36900: val accuracy 0.2684\n",
      "Step 37000: training accuracy 0.2840\n",
      "    sample pred: [2 4 1 1 5 4 4 5 1 1 8 9 5 1 1 4 4 5 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [11. 51.  2.  0. 70. 55. 14.  7. 58. 16.]\n",
      "Step 37000: val accuracy 0.2936\n",
      "Step 37100: training accuracy 0.2850\n",
      "    sample pred: [6 9 9 8 3 8 3 8 9 9 0 9 9 9 1 0 3 5 9 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [23. 17.  0. 19.  0. 23. 36.  7. 91. 69.]\n",
      "Step 37100: val accuracy 0.2696\n",
      "Step 37200: training accuracy 0.2810\n",
      "    sample pred: [7 9 9 1 3 4 3 3 2 9 0 9 4 9 1 4 4 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 3. 40.  3. 43. 71.  0. 22. 14.  0. 85.]\n",
      "Step 37200: val accuracy 0.2582\n",
      "Step 37300: training accuracy 0.3190\n",
      "    sample pred: [7 0 1 1 6 6 6 6 1 1 0 6 6 1 1 0 6 7 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [90. 44.  2.  6. 18.  0. 83. 62. 13.  1.]\n",
      "Step 37300: val accuracy 0.3012\n",
      "Step 37400: training accuracy 0.3330\n",
      "    sample pred: [7 9 1 1 6 1 7 6 2 9 0 9 7 9 1 7 1 7 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [21. 65. 15.  0.  1. 17. 58. 91. 28. 37.]\n",
      "Step 37400: val accuracy 0.3082\n",
      "Step 37500: training accuracy 0.3410\n",
      "    sample pred: [7 3 9 5 3 5 3 3 2 9 0 3 3 9 1 0 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 11. 23. 52.  0. 35. 23. 58. 60. 19.]\n",
      "Step 37500: val accuracy 0.3266\n",
      "Step 37600: training accuracy 0.3020\n",
      "    sample pred: [5 5 9 1 5 6 5 5 1 1 8 5 5 1 1 0 1 5 1 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [33. 50.  6.  0.  2. 79. 39. 23. 48. 22.]\n",
      "Step 37600: val accuracy 0.3134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37700: training accuracy 0.2210\n",
      "    sample pred: [4 9 9 1 4 4 4 4 1 9 8 9 1 9 1 4 1 4 9 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 62.  0.  0. 72.  0.  0.  4.  0. 83.]\n",
      "Step 37700: val accuracy 0.2076\n",
      "Step 37800: training accuracy 0.2990\n",
      "    sample pred: [2 9 9 1 5 5 3 3 2 9 8 9 3 9 1 2 3 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 52. 45. 38. 12. 54. 26.  0. 11. 61.]\n",
      "Step 37800: val accuracy 0.2862\n",
      "Step 37900: training accuracy 0.2860\n",
      "    sample pred: [2 9 9 9 3 3 3 3 2 9 8 9 9 9 9 9 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  6.   0.  52.  42.   2.  30.  10.  22.  16. 106.]\n",
      "Step 37900: val accuracy 0.2606\n",
      "Step 38000: training accuracy 0.2870\n",
      "    sample pred: [2 9 9 1 6 6 2 6 2 9 8 9 2 9 9 2 2 2 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0.  9. 69.  0. 12.  6. 66.  3. 29. 93.]\n",
      "Step 38000: val accuracy 0.2680\n",
      "Step 38100: training accuracy 0.2240\n",
      "    sample pred: [5 0 0 5 5 5 5 5 5 9 0 5 5 9 1 0 0 5 5 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [92. 16.  1.  7.  0. 81.  1.  3.  1. 22.]\n",
      "Step 38100: val accuracy 0.2080\n",
      "Step 38200: training accuracy 0.3010\n",
      "    sample pred: [6 9 9 1 3 6 3 3 9 9 8 9 6 9 1 6 3 6 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 55.  3. 36.  0.  0. 75. 14. 49. 69.]\n",
      "Step 38200: val accuracy 0.2800\n",
      "Step 38300: training accuracy 0.2840\n",
      "    sample pred: [2 9 9 1 2 4 2 2 2 9 8 9 2 9 1 2 2 2 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 31. 86.  1. 27.  0.  8.  0. 44. 87.]\n",
      "Step 38300: val accuracy 0.2552\n",
      "Step 38400: training accuracy 0.2630\n",
      "    sample pred: [6 8 1 1 6 1 6 8 1 1 8 1 1 1 1 8 1 6 1 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1. 63.  0.  1.  0.  7. 75. 38. 78.  0.]\n",
      "Step 38400: val accuracy 0.2728\n",
      "Step 38500: training accuracy 0.2410\n",
      "    sample pred: [7 0 0 0 3 4 3 3 7 7 0 7 0 0 0 0 0 7 7 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [99. 11.  0. 14. 11.  0. 28. 72.  6.  0.]\n",
      "Step 38500: val accuracy 0.2214\n",
      "Step 38600: training accuracy 0.2470\n",
      "    sample pred: [4 9 9 1 5 4 4 4 1 9 0 9 4 9 1 4 4 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [20. 54.  0.  1. 86.  6. 13.  2. 19. 46.]\n",
      "Step 38600: val accuracy 0.2424\n",
      "Step 38700: training accuracy 0.3100\n",
      "    sample pred: [7 9 9 9 3 3 3 3 9 9 0 9 9 9 9 0 3 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [61. 10.  0. 54.  2.  0. 21. 56.  8. 98.]\n",
      "Step 38700: val accuracy 0.2812\n",
      "Step 38800: training accuracy 0.3890\n",
      "    sample pred: [7 9 9 1 3 2 6 6 2 9 8 9 7 9 1 0 2 7 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [44. 30. 36. 12.  0.  2. 62. 90. 61. 52.]\n",
      "Step 38800: val accuracy 0.3482\n",
      "Step 38900: training accuracy 0.3150\n",
      "    sample pred: [7 3 9 5 3 5 3 5 3 9 8 3 3 9 1 5 3 5 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 14.  3. 49.  0. 55. 15. 71. 48. 60.]\n",
      "Step 38900: val accuracy 0.2902\n",
      "Step 39000: training accuracy 0.2670\n",
      "    sample pred: [7 3 9 3 3 4 3 3 3 9 8 3 3 9 3 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 1.  0.  0. 69. 53. 23.  3. 30. 70. 18.]\n",
      "Step 39000: val accuracy 0.2542\n",
      "Step 39100: training accuracy 0.2830\n",
      "    sample pred: [7 4 9 1 3 4 3 4 9 9 0 9 4 9 1 4 4 3 9 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [13. 23.  0. 39. 76.  0. 25. 18. 16. 73.]\n",
      "Step 39100: val accuracy 0.2754\n",
      "Step 39200: training accuracy 0.2270\n",
      "    sample pred: [2 3 1 1 3 3 3 3 3 1 8 3 3 1 1 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 6. 34. 13. 84.  4.  4.  1.  7. 74.  0.]\n",
      "Step 39200: val accuracy 0.2338\n",
      "Step 39300: training accuracy 0.2710\n",
      "    sample pred: [7 5 1 1 5 1 6 1 1 1 8 1 1 1 1 1 1 7 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 75.  0.  0.  0. 33. 57. 57. 40.  9.]\n",
      "Step 39300: val accuracy 0.2606\n",
      "Step 39400: training accuracy 0.2640\n",
      "    sample pred: [5 5 1 1 3 4 3 5 1 1 8 3 5 1 1 5 1 5 1 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 5. 64.  0. 49. 30. 55.  8. 11. 24. 18.]\n",
      "Step 39400: val accuracy 0.2546\n",
      "Step 39500: training accuracy 0.3290\n",
      "    sample pred: [2 0 9 1 5 4 2 4 2 9 0 9 2 9 1 0 2 5 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [66. 36. 56.  2. 46. 32.  0.  3. 59. 29.]\n",
      "Step 39500: val accuracy 0.3162\n",
      "Step 39600: training accuracy 0.3020\n",
      "    sample pred: [2 9 9 1 3 1 2 8 9 9 8 9 2 9 1 2 2 5 9 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 45. 68.  8.  2. 21.  7.  0. 55. 96.]\n",
      "Step 39600: val accuracy 0.2782\n",
      "Step 39700: training accuracy 0.2640\n",
      "    sample pred: [7 8 8 1 3 4 4 8 3 9 8 8 8 9 1 0 4 4 1 4]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [20. 25.  0. 20. 73.  0.  3. 16. 92. 15.]\n",
      "Step 39700: val accuracy 0.2612\n",
      "Step 39800: training accuracy 0.2610\n",
      "    sample pred: [2 9 1 1 3 1 3 1 1 1 8 9 1 9 1 1 1 5 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 76. 36. 16. 27. 25.  0.  2. 33. 46.]\n",
      "Step 39800: val accuracy 0.2548\n",
      "Step 39900: training accuracy 0.3400\n",
      "    sample pred: [7 9 9 1 3 6 3 3 3 9 0 9 6 9 1 0 3 3 9 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [60. 41.  0. 31.  0.  0. 70. 47.  2. 89.]\n",
      "Step 39900: val accuracy 0.3088\n",
      "Step 40000: training accuracy 0.2350\n",
      "    sample pred: [2 2 1 1 6 2 2 6 2 1 8 2 2 1 1 2 2 2 1 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 0. 48. 92.  5.  5.  1. 36. 38.  1.  9.]\n",
      "Step 40000: val accuracy 0.2168\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    pkeep = tf.placeholder(tf.float32, name='pkeep')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits(x, model_type, pkeep)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        if opt_method == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "        elif opt_method == 'rms':\n",
    "            opt = tf.train.RMSPropOptimizer(.001)\n",
    "        elif opt_method == 'adam':\n",
    "            opt = tf.train.AdamOptimizer(1e-4)\n",
    "        train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        # create summary for logits\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        # create summary for input image\n",
    "        tf.summary.image('input', tf.reshape(x, [-1, 32, 32, 3]))\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for i in range(40001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(n-n_val)).astype(int)\n",
    "            X_batch = X_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_onehot[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%100 == 0:\n",
    "                X_batch = X_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_onehot[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "                # further diagnostics\n",
    "                perf_eval(train_logits, y_batch)\n",
    "                \n",
    "            if i%100 == 0:\n",
    "                X_batch = X_val.reshape([n_val,-1])\n",
    "                y_batch = y_onehot_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
