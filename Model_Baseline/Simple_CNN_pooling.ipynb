{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hFX9GoVeGftw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "af197160-4f27-48fb-cc01-89a7d68c25a7"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 110377 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lBn9W9ttGlBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f593b7c7-990c-4f60-eadc-7b2f5263550c"
      },
      "cell_type": "code",
      "source": [
        "!mkdir drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls /content/drive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive’: File exists\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n",
            "'Colab Notebooks'  'Getting started'   logs   model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vYODqNuZGlED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "\n",
        "def _print_download_progress(count, block_size, total_size):\n",
        "    \"\"\"\n",
        "    Function used for printing the download progress.\n",
        "    Used as a call-back function in maybe_download_and_extract().\n",
        "    \"\"\"\n",
        "\n",
        "    # Percentage completion.\n",
        "    pct_complete = float(count * block_size) / total_size\n",
        "\n",
        "    # Limit it because rounding errors may cause it to exceed 100%.\n",
        "    pct_complete = min(1.0, pct_complete)\n",
        "\n",
        "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
        "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
        "\n",
        "    # Print it.\n",
        "    sys.stdout.write(msg)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def _maybe_download_and_extract(url, download_dir):\n",
        "    \"\"\"\n",
        "    Download and extract the data if it doesn't already exist.\n",
        "    Assumes the url is a tar-ball file.\n",
        "    :param url:\n",
        "        Internet URL for the tar-file to download.\n",
        "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    :param download_dir:\n",
        "        Directory where the downloaded file is saved.\n",
        "        Example: \"data/CIFAR-10/\"\n",
        "    :return:\n",
        "        Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filename for saving the file downloaded from the internet.\n",
        "    # Use the filename from the URL and add it to the download_dir.\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists.\n",
        "    # If it exists then we assume it has also been extracted,\n",
        "    # otherwise we need to download and extract it now.\n",
        "    if not os.path.exists(file_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=file_path,\n",
        "                                                  reporthook=_print_download_progress)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            # Unpack the zip-file.\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            # Unpack the tar-ball.\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cDs3g3v-GlF9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def one_hot_encoded(class_numbers, num_classes=None):\n",
        "    \"\"\"\n",
        "    Generate the One-Hot encoded class-labels from an array of integers.\n",
        "    For example, if class_number=2 and num_classes=4 then\n",
        "    the one-hot encoded label is the float array: [0. 0. 1. 0.]\n",
        "    :param class_numbers:\n",
        "        Array of integers with class-numbers.\n",
        "        Assume the integers are from zero to num_classes-1 inclusive.\n",
        "    :param num_classes:\n",
        "        Number of classes. If None then use max(class_numbers)+1.\n",
        "    :return:\n",
        "        2-dim array of shape: [len(class_numbers), num_classes]\n",
        "    \"\"\"\n",
        "\n",
        "    # Find the number of classes if None is provided.\n",
        "    # Assumes the lowest class-number is zero.\n",
        "    if num_classes is None:\n",
        "        num_classes = np.max(class_numbers) + 1\n",
        "\n",
        "    return np.eye(num_classes, dtype=float)[class_numbers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijE9syB9GlH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "########################################################################\n",
        "\n",
        "# Directory where you want to download and save the data-set.\n",
        "# Set this before you start calling any of the functions below.\n",
        "data_path = \"data/CIFAR-10/\"\n",
        "\n",
        "# URL for the data-set on the internet.\n",
        "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "\n",
        "########################################################################\n",
        "# Various constants for the size of the images.\n",
        "# Use these constants in your own program.\n",
        "\n",
        "# Width and height of each image.\n",
        "img_size = 32\n",
        "\n",
        "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
        "num_channels = 3\n",
        "\n",
        "# Length of an image when flattened to a 1-dim array.\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "\n",
        "# Number of classes.\n",
        "num_classes = 10\n",
        "\n",
        "########################################################################\n",
        "# Various constants used to allocate arrays of the correct size.\n",
        "\n",
        "# Number of files for the training-set.\n",
        "_num_files_train = 5\n",
        "\n",
        "# Number of images for each batch-file in the training-set.\n",
        "_images_per_file = 10000\n",
        "\n",
        "# Total number of images in the training-set.\n",
        "# This is used to pre-allocate arrays for efficiency.\n",
        "_num_images_train = _num_files_train * _images_per_file\n",
        "\n",
        "########################################################################\n",
        "# Private functions for downloading, unpacking and loading data-files.\n",
        "\n",
        "\n",
        "def _get_file_path(filename=\"\"):\n",
        "    \"\"\"\n",
        "    Return the full path of a data-file for the data-set.\n",
        "    If filename==\"\" then return the directory of the files.\n",
        "    \"\"\"\n",
        "\n",
        "    return os.path.join(data_path, \"cifar-10-batches-py/\", filename)\n",
        "\n",
        "\n",
        "def _unpickle(filename):\n",
        "    \"\"\"\n",
        "    Unpickle the given file and return the data.\n",
        "    Note that the appropriate dir-name is prepended the filename.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create full path for the file.\n",
        "    file_path = _get_file_path(filename)\n",
        "\n",
        "    print(\"Loading data: \" + file_path)\n",
        "\n",
        "    with open(file_path, mode='rb') as file:\n",
        "        # In Python 3.X it is important to set the encoding,\n",
        "        # otherwise an exception is raised here.\n",
        "        data = pickle.load(file, encoding='bytes')\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def _convert_images(raw):\n",
        "    \"\"\"\n",
        "    Convert images from the CIFAR-10 format and\n",
        "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
        "    where the pixels are floats between 0.0 and 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the raw images from the data-files to floating-points.\n",
        "    raw_float = np.array(raw, dtype=float) / 255.0\n",
        "\n",
        "    # Reshape the array to 4-dimensions.\n",
        "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
        "\n",
        "    # Reorder the indices of the array.\n",
        "    images = images.transpose([0, 2, 3, 1])\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def _load_data(filename):\n",
        "    \"\"\"\n",
        "    Load a pickled data-file from the CIFAR-10 data-set\n",
        "    and return the converted images (see above) and the class-number\n",
        "    for each image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the pickled data-file.\n",
        "    data = _unpickle(filename)\n",
        "\n",
        "    # Get the raw images.\n",
        "    raw_images = data[b'data']\n",
        "\n",
        "    # Get the class-numbers for each image. Convert to numpy-array.\n",
        "    cls = np.array(data[b'labels'])\n",
        "\n",
        "    # Convert the images.\n",
        "    images = _convert_images(raw_images)\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "\n",
        "########################################################################\n",
        "# Public functions that you may call to download the data-set from\n",
        "# the internet and load the data into memory.\n",
        "\n",
        "\n",
        "def maybe_download_and_extract():\n",
        "    \"\"\"\n",
        "    Download and extract the CIFAR-10 data-set if it doesn't already exist\n",
        "    in data_path (set this variable first to the desired path).\n",
        "    \"\"\"\n",
        "\n",
        "    _maybe_download_and_extract(url=data_url, download_dir=data_path)\n",
        "\n",
        "\n",
        "def load_class_names():\n",
        "    \"\"\"\n",
        "    Load the names for the classes in the CIFAR-10 data-set.\n",
        "    Returns a list with the names. Example: names[3] is the name\n",
        "    associated with class-number 3.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the class-names from the pickled file.\n",
        "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
        "\n",
        "    # Convert from binary strings.\n",
        "    names = [x.decode('utf-8') for x in raw]\n",
        "\n",
        "    return names\n",
        "\n",
        "\n",
        "def load_training_data():\n",
        "    \"\"\"\n",
        "    Load all the training-data for the CIFAR-10 data-set.\n",
        "    The data-set is split into 5 data-files which are merged here.\n",
        "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
        "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
        "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
        "\n",
        "    # Begin-index for the current batch.\n",
        "    begin = 0\n",
        "\n",
        "    # For each data-file.\n",
        "    for i in range(_num_files_train):\n",
        "        # Load the images and class-numbers from the data-file.\n",
        "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
        "\n",
        "        # Number of images in this batch.\n",
        "        num_images = len(images_batch)\n",
        "\n",
        "        # End-index for the current batch.\n",
        "        end = begin + num_images\n",
        "\n",
        "        # Store the images into the array.\n",
        "        images[begin:end, :] = images_batch\n",
        "\n",
        "        # Store the class-numbers into the array.\n",
        "        cls[begin:end] = cls_batch\n",
        "\n",
        "        # The begin-index for the next batch is the current end-index.\n",
        "        begin = end\n",
        "\n",
        "    return images, one_hot_encoded(class_numbers=cls, num_classes=num_classes)\n",
        "\n",
        "\n",
        "def load_test_data():\n",
        "    \"\"\"\n",
        "    Load all the test-data for the CIFAR-10 data-set.\n",
        "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
        "    \"\"\"\n",
        "\n",
        "    images, cls = _load_data(filename=\"test_batch\")\n",
        "\n",
        "    return images, one_hot_encoded(class_numbers=cls, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVunDeczGlJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _random_crop(batch, crop_shape, padding=None):\n",
        "        oshape = np.shape(batch[0])\n",
        "        \n",
        "        if padding:\n",
        "            oshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n",
        "        new_batch = []\n",
        "        npad = ((padding, padding), (padding, padding), (0, 0))\n",
        "        for i in range(len(batch)):\n",
        "            new_batch.append(batch[i])\n",
        "            if padding:\n",
        "                new_batch[i] = np.lib.pad(batch[i], pad_width=npad, mode=\"constant\", constant_values=0)\n",
        "            nh = random.randint(0, oshape[0] - crop_shape[0])\n",
        "            nw = random.randint(0, oshape[1] - crop_shape[1])\n",
        "            new_batch[i] = new_batch[i][nh:nh + crop_shape[0], nw:nw + crop_shape[1]]\n",
        "        return new_batch\n",
        "\n",
        "\n",
        "def _random_flip_leftright(batch):\n",
        "        for i in range(len(batch)):\n",
        "            if bool(random.getrandbits(1)):\n",
        "                batch[i] = np.fliplr(batch[i])\n",
        "        return batch\n",
        "\n",
        "\n",
        "def data_augmentation(batch, crop_shape, size):\n",
        "    batch = _random_flip_leftright(batch)\n",
        "    batch = _random_crop(batch, [size,size], crop_shape)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3V4nBayhG39q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40953
        },
        "outputId": "72fbf90c-68b1-495b-d96c-8fe243eb8d7e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "epochs = 400\n",
        "batch_size = 100\n",
        "num_filters = 32\n",
        "window_size = 3\n",
        "learning_rate = 0.001\n",
        "crop_shape = 4\n",
        "log_save_path = \"/content/drive/logs/\"\n",
        "model_save_path = \"/content/drive/model/\"\n",
        "\n",
        "maybe_download_and_extract()\n",
        "X_train, y_train = load_training_data()\n",
        "X_test, y_test = load_test_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# z-score\n",
        "X_train = (X_train - np.mean(X_train, axis=(0, 1, 2, 3))) / np.std(X_train,axis=(0,1,2,3))\n",
        "X_test = (X_test - np.mean(X_test, axis=(0, 1, 2, 3))) / np.std(X_test,axis=(0,1,2,3))\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, img_size, img_size, num_channels])\n",
        "y = tf.placeholder(tf.float32, [None, num_classes])\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv1 = tf.get_variable(\"W_conv1\", [window_size, window_size, num_channels, num_filters])\n",
        "b_conv1 = tf.get_variable(\"b_conv1\", [num_filters])\n",
        "h_conv1 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(x, W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv1)))\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv2 = tf.get_variable(\"W_conv2\", [window_size, window_size, num_filters, num_filters])\n",
        "b_conv2 = tf.get_variable(\"b_conv2\", [num_filters])\n",
        "h_conv2 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(h_conv1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv2)))\n",
        "\n",
        "# max pooling layer\n",
        "h_pool1 = tf.nn.max_pool(h_conv2, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "# dropout layer\n",
        "dropout1 = tf.nn.dropout(h_pool1, 0.8)\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv3 = tf.get_variable(\"W_conv3\", [window_size, window_size, num_filters, num_filters * 2])\n",
        "b_conv3 = tf.get_variable(\"b_conv3\", [num_filters * 2])\n",
        "h_conv3 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(dropout1, W_conv3, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv3)))\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv4 = tf.get_variable(\"W_conv4\", [window_size, window_size, num_filters * 2, num_filters * 2])\n",
        "b_conv4 = tf.get_variable(\"b_conv4\", [num_filters * 2])\n",
        "h_conv4 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv4)))\n",
        "\n",
        "# max pooling layer\n",
        "h_pool2 = tf.nn.max_pool(h_conv4, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "# dropout layer\n",
        "dropout2 = tf.nn.dropout(h_pool2, 0.7)\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv5 = tf.get_variable(\"W_conv5\", [window_size, window_size, num_filters * 2, num_filters * 3])\n",
        "b_conv5 = tf.get_variable(\"b_conv5\", [num_filters * 3])\n",
        "h_conv5 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(dropout2, W_conv5, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv5)))\n",
        "\n",
        "# 2D convolution layer\n",
        "W_conv6 = tf.get_variable(\"W_conv6\", [window_size, window_size, num_filters * 3, num_filters * 3])\n",
        "b_conv6 = tf.get_variable(\"b_conv6\", [num_filters * 3])\n",
        "h_conv6 = tf.contrib.layers.batch_norm(tf.nn.relu(tf.add(tf.nn.conv2d(h_conv5, W_conv6, strides=[1, 1, 1, 1], padding=\"SAME\"), b_conv6)))\n",
        "\n",
        "# max pooling layer\n",
        "h_pool3 = tf.nn.max_pool(h_conv6, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "# dropout layer\n",
        "dropout3 = tf.nn.dropout(h_pool3, 0.6)\n",
        "\n",
        "# reshape layer\n",
        "dim = dropout3.get_shape()[1].value ** 2 * dropout3.get_shape()[3].value\n",
        "reshape = tf.reshape(dropout3, [-1, dim])\n",
        "\n",
        "# output layer\n",
        "W_conv14 = tf.get_variable(\"W_conv14\", [dim, num_classes])\n",
        "b_conv14 = tf.get_variable(\"b_conv14\", [num_classes])\n",
        "output = tf.add(tf.matmul(reshape, W_conv14), b_conv14)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_sum(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    summary_writer = tf.summary.FileWriter(log_save_path,sess.graph)\n",
        "    total_batch = int(X_train.shape[0] / batch_size)\n",
        "    total_batch_test = int(X_test.shape[0] / batch_size)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        print(\"epoch %d/%d:\" % (i + 1, epochs))\n",
        "        \n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        for batch in range(total_batch):\n",
        "            batch_x = X_train[batch * batch_size: (batch + 1) * batch_size, :]\n",
        "            batch_y = y_train[batch * batch_size: (batch + 1) * batch_size, :]\n",
        "            \n",
        "            batch_x = data_augmentation(batch_x, crop_shape, img_size)\n",
        "            \n",
        "            _, batch_loss, batch_acc = sess.run([optimizer, loss, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "            \n",
        "            train_loss += batch_loss\n",
        "            train_acc += batch_acc\n",
        "        \n",
        "            if batch == total_batch - 1:\n",
        "                train_loss /= total_batch\n",
        "                train_acc /= total_batch\n",
        "                train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"train_loss\", simple_value=train_loss), tf.Summary.Value(tag=\"train_accuracy\", simple_value=train_acc)])\n",
        "\n",
        "                test_loss = 0\n",
        "                test_acc = 0\n",
        "                for test_batch in range(total_batch_test):\n",
        "                    batch_x_test = X_test[test_batch * batch_size: (test_batch + 1) * batch_size, :]\n",
        "                    batch_y_test = y_test[test_batch * batch_size: (test_batch + 1) * batch_size, :]\n",
        "                    batch_loss_test, batch_acc_test = sess.run([loss, accuracy], feed_dict={x: batch_x_test, y: batch_y_test})\n",
        "                    \n",
        "                    test_loss += batch_loss_test\n",
        "                    test_acc += batch_acc_test\n",
        "\n",
        "                test_loss /= total_batch_test\n",
        "                test_acc /= total_batch_test\n",
        "                test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"test_loss\", simple_value=test_loss), tf.Summary.Value(tag=\"test_accuracy\", simple_value=test_acc)])\n",
        "                \n",
        "                summary_writer.add_summary(train_summary, i)\n",
        "                summary_writer.add_summary(test_summary, i)\n",
        "                summary_writer.flush()\n",
        "                print(\"iteration: %d/%d, train_loss: %.4f, train_accuracy: %.4f, test_loss: %.4f, test_accuracy: %.4f\" % (batch + 1, total_batch, train_loss, train_acc, test_loss, test_acc))\n",
        "            elif (batch + 1) % 100 == 0:\n",
        "                print(\"iteration: %d/%d, train_loss: %.4f, train_accuracy: %.4f\" % (batch + 1, total_batch, train_loss / (batch + 1), train_acc / (batch + 1)))\n",
        "    save_path = saver.save(sess, model_save_path)\n",
        "    print(\"Model saved in file: %s\" % save_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has apparently already been downloaded and unpacked.\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
            "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n",
            "epoch 1/400:\n",
            "iteration: 100/500, train_loss: 2.6706, train_accuracy: 26.5900\n",
            "iteration: 200/500, train_loss: 2.3380, train_accuracy: 30.9600\n",
            "iteration: 300/500, train_loss: 2.1410, train_accuracy: 34.4200\n",
            "iteration: 400/500, train_loss: 2.0447, train_accuracy: 36.8300\n",
            "iteration: 500/500, train_loss: 1.9524, train_accuracy: 39.0620, test_loss: 1.4795, test_accuracy: 52.6300\n",
            "epoch 2/400:\n",
            "iteration: 100/500, train_loss: 1.5024, train_accuracy: 49.8400\n",
            "iteration: 200/500, train_loss: 1.4936, train_accuracy: 51.1100\n",
            "iteration: 300/500, train_loss: 1.4648, train_accuracy: 52.3033\n",
            "iteration: 400/500, train_loss: 1.4641, train_accuracy: 52.8075\n",
            "iteration: 500/500, train_loss: 1.4420, train_accuracy: 53.4920, test_loss: 1.2602, test_accuracy: 60.3500\n",
            "epoch 3/400:\n",
            "iteration: 100/500, train_loss: 1.2844, train_accuracy: 58.0800\n",
            "iteration: 200/500, train_loss: 1.2970, train_accuracy: 58.1250\n",
            "iteration: 300/500, train_loss: 1.2823, train_accuracy: 58.8167\n",
            "iteration: 400/500, train_loss: 1.2747, train_accuracy: 59.0425\n",
            "iteration: 500/500, train_loss: 1.2635, train_accuracy: 59.5600, test_loss: 1.1992, test_accuracy: 63.7800\n",
            "epoch 4/400:\n",
            "iteration: 100/500, train_loss: 1.1584, train_accuracy: 63.0300\n",
            "iteration: 200/500, train_loss: 1.1862, train_accuracy: 62.5850\n",
            "iteration: 300/500, train_loss: 1.1547, train_accuracy: 63.1633\n",
            "iteration: 400/500, train_loss: 1.1563, train_accuracy: 63.3800\n",
            "iteration: 500/500, train_loss: 1.1415, train_accuracy: 63.7620, test_loss: 0.9984, test_accuracy: 67.9500\n",
            "epoch 5/400:\n",
            "iteration: 100/500, train_loss: 1.0522, train_accuracy: 66.4900\n",
            "iteration: 200/500, train_loss: 1.0627, train_accuracy: 65.8100\n",
            "iteration: 300/500, train_loss: 1.0483, train_accuracy: 66.1300\n",
            "iteration: 400/500, train_loss: 1.0417, train_accuracy: 66.3800\n",
            "iteration: 500/500, train_loss: 1.0347, train_accuracy: 66.7040, test_loss: 0.9447, test_accuracy: 69.5900\n",
            "epoch 6/400:\n",
            "iteration: 100/500, train_loss: 0.9531, train_accuracy: 68.3600\n",
            "iteration: 200/500, train_loss: 0.9831, train_accuracy: 68.0800\n",
            "iteration: 300/500, train_loss: 0.9687, train_accuracy: 68.4367\n",
            "iteration: 400/500, train_loss: 0.9656, train_accuracy: 68.5275\n",
            "iteration: 500/500, train_loss: 0.9526, train_accuracy: 68.7780, test_loss: 0.8540, test_accuracy: 71.1700\n",
            "epoch 7/400:\n",
            "iteration: 100/500, train_loss: 0.8910, train_accuracy: 70.2900\n",
            "iteration: 200/500, train_loss: 0.8972, train_accuracy: 70.0050\n",
            "iteration: 300/500, train_loss: 0.8793, train_accuracy: 70.4133\n",
            "iteration: 400/500, train_loss: 0.8691, train_accuracy: 70.6375\n",
            "iteration: 500/500, train_loss: 0.8599, train_accuracy: 70.9280, test_loss: 0.8061, test_accuracy: 72.6900\n",
            "epoch 8/400:\n",
            "iteration: 100/500, train_loss: 0.8060, train_accuracy: 72.6300\n",
            "iteration: 200/500, train_loss: 0.8084, train_accuracy: 72.4350\n",
            "iteration: 300/500, train_loss: 0.8024, train_accuracy: 72.5800\n",
            "iteration: 400/500, train_loss: 0.8008, train_accuracy: 72.6825\n",
            "iteration: 500/500, train_loss: 0.7922, train_accuracy: 73.0020, test_loss: 0.7549, test_accuracy: 74.2600\n",
            "epoch 9/400:\n",
            "iteration: 100/500, train_loss: 0.7570, train_accuracy: 74.1800\n",
            "iteration: 200/500, train_loss: 0.7624, train_accuracy: 74.3300\n",
            "iteration: 300/500, train_loss: 0.7539, train_accuracy: 74.4667\n",
            "iteration: 400/500, train_loss: 0.7597, train_accuracy: 74.2875\n",
            "iteration: 500/500, train_loss: 0.7549, train_accuracy: 74.4400, test_loss: 0.7295, test_accuracy: 75.2500\n",
            "epoch 10/400:\n",
            "iteration: 100/500, train_loss: 0.7323, train_accuracy: 75.1200\n",
            "iteration: 200/500, train_loss: 0.7434, train_accuracy: 74.6900\n",
            "iteration: 300/500, train_loss: 0.7373, train_accuracy: 74.7800\n",
            "iteration: 400/500, train_loss: 0.7409, train_accuracy: 74.7975\n",
            "iteration: 500/500, train_loss: 0.7345, train_accuracy: 75.0300, test_loss: 0.7213, test_accuracy: 75.8700\n",
            "epoch 11/400:\n",
            "iteration: 100/500, train_loss: 0.7000, train_accuracy: 76.1000\n",
            "iteration: 200/500, train_loss: 0.7091, train_accuracy: 75.9550\n",
            "iteration: 300/500, train_loss: 0.7015, train_accuracy: 76.2400\n",
            "iteration: 400/500, train_loss: 0.7000, train_accuracy: 76.3275\n",
            "iteration: 500/500, train_loss: 0.6983, train_accuracy: 76.4040, test_loss: 0.7254, test_accuracy: 77.1800\n",
            "epoch 12/400:\n",
            "iteration: 100/500, train_loss: 0.6792, train_accuracy: 76.7200\n",
            "iteration: 200/500, train_loss: 0.6944, train_accuracy: 76.7750\n",
            "iteration: 300/500, train_loss: 0.6837, train_accuracy: 76.9300\n",
            "iteration: 400/500, train_loss: 0.6830, train_accuracy: 76.9000\n",
            "iteration: 500/500, train_loss: 0.6754, train_accuracy: 77.1100, test_loss: 0.6557, test_accuracy: 77.8200\n",
            "epoch 13/400:\n",
            "iteration: 100/500, train_loss: 0.6456, train_accuracy: 77.8700\n",
            "iteration: 200/500, train_loss: 0.6555, train_accuracy: 77.7300\n",
            "iteration: 300/500, train_loss: 0.6615, train_accuracy: 77.5633\n",
            "iteration: 400/500, train_loss: 0.6681, train_accuracy: 77.4150\n",
            "iteration: 500/500, train_loss: 0.6580, train_accuracy: 77.6420, test_loss: 0.6531, test_accuracy: 77.8300\n",
            "epoch 14/400:\n",
            "iteration: 100/500, train_loss: 0.6380, train_accuracy: 78.1800\n",
            "iteration: 200/500, train_loss: 0.6606, train_accuracy: 77.7850\n",
            "iteration: 300/500, train_loss: 0.6540, train_accuracy: 78.0033\n",
            "iteration: 400/500, train_loss: 0.6599, train_accuracy: 77.8550\n",
            "iteration: 500/500, train_loss: 0.6562, train_accuracy: 77.9340, test_loss: 0.6592, test_accuracy: 78.7000\n",
            "epoch 15/400:\n",
            "iteration: 100/500, train_loss: 0.6485, train_accuracy: 78.2300\n",
            "iteration: 200/500, train_loss: 0.6428, train_accuracy: 78.3100\n",
            "iteration: 300/500, train_loss: 0.6369, train_accuracy: 78.5467\n",
            "iteration: 400/500, train_loss: 0.6404, train_accuracy: 78.4600\n",
            "iteration: 500/500, train_loss: 0.6347, train_accuracy: 78.5660, test_loss: 0.6397, test_accuracy: 78.2700\n",
            "epoch 16/400:\n",
            "iteration: 100/500, train_loss: 0.5979, train_accuracy: 79.9200\n",
            "iteration: 200/500, train_loss: 0.6121, train_accuracy: 79.4400\n",
            "iteration: 300/500, train_loss: 0.6107, train_accuracy: 79.2800\n",
            "iteration: 400/500, train_loss: 0.6155, train_accuracy: 79.1025\n",
            "iteration: 500/500, train_loss: 0.6111, train_accuracy: 79.2640, test_loss: 0.6201, test_accuracy: 79.4700\n",
            "epoch 17/400:\n",
            "iteration: 100/500, train_loss: 0.6581, train_accuracy: 78.3100\n",
            "iteration: 200/500, train_loss: 0.6440, train_accuracy: 78.4100\n",
            "iteration: 300/500, train_loss: 0.6204, train_accuracy: 79.0267\n",
            "iteration: 400/500, train_loss: 0.6179, train_accuracy: 79.0100\n",
            "iteration: 500/500, train_loss: 0.6068, train_accuracy: 79.3220, test_loss: 0.6190, test_accuracy: 79.3800\n",
            "epoch 18/400:\n",
            "iteration: 100/500, train_loss: 0.5838, train_accuracy: 80.0700\n",
            "iteration: 200/500, train_loss: 0.5839, train_accuracy: 79.9050\n",
            "iteration: 300/500, train_loss: 0.5717, train_accuracy: 80.2300\n",
            "iteration: 400/500, train_loss: 0.5788, train_accuracy: 80.0475\n",
            "iteration: 500/500, train_loss: 0.5753, train_accuracy: 80.2200, test_loss: 0.5921, test_accuracy: 80.0000\n",
            "epoch 19/400:\n",
            "iteration: 100/500, train_loss: 0.6141, train_accuracy: 79.3300\n",
            "iteration: 200/500, train_loss: 0.6093, train_accuracy: 79.5400\n",
            "iteration: 300/500, train_loss: 0.6037, train_accuracy: 79.6067\n",
            "iteration: 400/500, train_loss: 0.6134, train_accuracy: 79.4500\n",
            "iteration: 500/500, train_loss: 0.6178, train_accuracy: 79.4180, test_loss: 0.6530, test_accuracy: 78.5000\n",
            "epoch 20/400:\n",
            "iteration: 100/500, train_loss: 0.6051, train_accuracy: 79.6500\n",
            "iteration: 200/500, train_loss: 0.6076, train_accuracy: 79.7250\n",
            "iteration: 300/500, train_loss: 0.6014, train_accuracy: 79.8633\n",
            "iteration: 400/500, train_loss: 0.5971, train_accuracy: 79.8650\n",
            "iteration: 500/500, train_loss: 0.5949, train_accuracy: 80.0040, test_loss: 0.6870, test_accuracy: 77.7700\n",
            "epoch 21/400:\n",
            "iteration: 100/500, train_loss: 0.5775, train_accuracy: 80.4500\n",
            "iteration: 200/500, train_loss: 0.5649, train_accuracy: 80.8150\n",
            "iteration: 300/500, train_loss: 0.5573, train_accuracy: 81.0167\n",
            "iteration: 400/500, train_loss: 0.5556, train_accuracy: 81.0025\n",
            "iteration: 500/500, train_loss: 0.5523, train_accuracy: 81.1840, test_loss: 0.5806, test_accuracy: 80.6700\n",
            "epoch 22/400:\n",
            "iteration: 100/500, train_loss: 0.5343, train_accuracy: 81.5400\n",
            "iteration: 200/500, train_loss: 0.5404, train_accuracy: 81.6550\n",
            "iteration: 300/500, train_loss: 0.5352, train_accuracy: 81.8933\n",
            "iteration: 400/500, train_loss: 0.5407, train_accuracy: 81.6375\n",
            "iteration: 500/500, train_loss: 0.5422, train_accuracy: 81.5960, test_loss: 0.6331, test_accuracy: 80.2900\n",
            "epoch 23/400:\n",
            "iteration: 100/500, train_loss: 0.5509, train_accuracy: 81.3400\n",
            "iteration: 200/500, train_loss: 0.5510, train_accuracy: 81.3200\n",
            "iteration: 300/500, train_loss: 0.5404, train_accuracy: 81.5767\n",
            "iteration: 400/500, train_loss: 0.5467, train_accuracy: 81.3225\n",
            "iteration: 500/500, train_loss: 0.5495, train_accuracy: 81.3380, test_loss: 0.6109, test_accuracy: 79.8400\n",
            "epoch 24/400:\n",
            "iteration: 100/500, train_loss: 0.5561, train_accuracy: 81.9300\n",
            "iteration: 200/500, train_loss: 0.5477, train_accuracy: 81.7900\n",
            "iteration: 300/500, train_loss: 0.5421, train_accuracy: 81.8500\n",
            "iteration: 400/500, train_loss: 0.5628, train_accuracy: 81.3400\n",
            "iteration: 500/500, train_loss: 0.5550, train_accuracy: 81.5480, test_loss: 0.6072, test_accuracy: 80.2000\n",
            "epoch 25/400:\n",
            "iteration: 100/500, train_loss: 0.5713, train_accuracy: 81.1800\n",
            "iteration: 200/500, train_loss: 0.5615, train_accuracy: 81.1300\n",
            "iteration: 300/500, train_loss: 0.5498, train_accuracy: 81.4333\n",
            "iteration: 400/500, train_loss: 0.5507, train_accuracy: 81.3775\n",
            "iteration: 500/500, train_loss: 0.5402, train_accuracy: 81.6680, test_loss: 0.5581, test_accuracy: 81.5000\n",
            "epoch 26/400:\n",
            "iteration: 100/500, train_loss: 0.5327, train_accuracy: 82.0800\n",
            "iteration: 200/500, train_loss: 0.5568, train_accuracy: 81.5550\n",
            "iteration: 300/500, train_loss: 0.5420, train_accuracy: 81.7600\n",
            "iteration: 400/500, train_loss: 0.5381, train_accuracy: 81.8000\n",
            "iteration: 500/500, train_loss: 0.5303, train_accuracy: 82.0360, test_loss: 0.5718, test_accuracy: 81.1600\n",
            "epoch 27/400:\n",
            "iteration: 100/500, train_loss: 0.5247, train_accuracy: 82.3900\n",
            "iteration: 200/500, train_loss: 0.5178, train_accuracy: 82.3000\n",
            "iteration: 300/500, train_loss: 0.5296, train_accuracy: 81.9633\n",
            "iteration: 400/500, train_loss: 0.5280, train_accuracy: 82.0150\n",
            "iteration: 500/500, train_loss: 0.5219, train_accuracy: 82.3060, test_loss: 0.5403, test_accuracy: 81.9200\n",
            "epoch 28/400:\n",
            "iteration: 100/500, train_loss: 0.5485, train_accuracy: 81.4100\n",
            "iteration: 200/500, train_loss: 0.5450, train_accuracy: 81.6150\n",
            "iteration: 300/500, train_loss: 0.5311, train_accuracy: 82.0200\n",
            "iteration: 400/500, train_loss: 0.5299, train_accuracy: 82.0900\n",
            "iteration: 500/500, train_loss: 0.5282, train_accuracy: 82.1600, test_loss: 0.5616, test_accuracy: 81.2400\n",
            "epoch 29/400:\n",
            "iteration: 100/500, train_loss: 0.5179, train_accuracy: 82.9200\n",
            "iteration: 200/500, train_loss: 0.5077, train_accuracy: 82.9250\n",
            "iteration: 300/500, train_loss: 0.4977, train_accuracy: 83.2700\n",
            "iteration: 400/500, train_loss: 0.5000, train_accuracy: 83.0850\n",
            "iteration: 500/500, train_loss: 0.5057, train_accuracy: 83.0160, test_loss: 0.5930, test_accuracy: 80.9300\n",
            "epoch 30/400:\n",
            "iteration: 100/500, train_loss: 0.5591, train_accuracy: 81.9200\n",
            "iteration: 200/500, train_loss: 0.5448, train_accuracy: 81.8650\n",
            "iteration: 300/500, train_loss: 0.5402, train_accuracy: 81.9267\n",
            "iteration: 400/500, train_loss: 0.5362, train_accuracy: 81.9675\n",
            "iteration: 500/500, train_loss: 0.5346, train_accuracy: 82.1500, test_loss: 0.6086, test_accuracy: 81.3200\n",
            "epoch 31/400:\n",
            "iteration: 100/500, train_loss: 0.5294, train_accuracy: 81.9900\n",
            "iteration: 200/500, train_loss: 0.5348, train_accuracy: 82.0250\n",
            "iteration: 300/500, train_loss: 0.5236, train_accuracy: 82.2433\n",
            "iteration: 400/500, train_loss: 0.5171, train_accuracy: 82.4450\n",
            "iteration: 500/500, train_loss: 0.5114, train_accuracy: 82.6380, test_loss: 0.7837, test_accuracy: 78.0700\n",
            "epoch 32/400:\n",
            "iteration: 100/500, train_loss: 0.5608, train_accuracy: 81.0400\n",
            "iteration: 200/500, train_loss: 0.5327, train_accuracy: 81.7000\n",
            "iteration: 300/500, train_loss: 0.5180, train_accuracy: 82.1033\n",
            "iteration: 400/500, train_loss: 0.5151, train_accuracy: 82.3225\n",
            "iteration: 500/500, train_loss: 0.5129, train_accuracy: 82.4940, test_loss: 0.5663, test_accuracy: 81.5300\n",
            "epoch 33/400:\n",
            "iteration: 100/500, train_loss: 0.5558, train_accuracy: 81.8800\n",
            "iteration: 200/500, train_loss: 0.5890, train_accuracy: 81.1650\n",
            "iteration: 300/500, train_loss: 0.6418, train_accuracy: 79.8733\n",
            "iteration: 400/500, train_loss: 0.6260, train_accuracy: 80.0125\n",
            "iteration: 500/500, train_loss: 0.6039, train_accuracy: 80.5200, test_loss: 0.5959, test_accuracy: 81.0100\n",
            "epoch 34/400:\n",
            "iteration: 100/500, train_loss: 0.5304, train_accuracy: 82.6800\n",
            "iteration: 200/500, train_loss: 0.5182, train_accuracy: 82.6000\n",
            "iteration: 300/500, train_loss: 0.5066, train_accuracy: 82.7533\n",
            "iteration: 400/500, train_loss: 0.5002, train_accuracy: 82.8775\n",
            "iteration: 500/500, train_loss: 0.4924, train_accuracy: 83.1580, test_loss: 0.5469, test_accuracy: 82.0100\n",
            "epoch 35/400:\n",
            "iteration: 100/500, train_loss: 0.4704, train_accuracy: 84.1000\n",
            "iteration: 200/500, train_loss: 0.4814, train_accuracy: 83.8200\n",
            "iteration: 300/500, train_loss: 0.4765, train_accuracy: 83.8200\n",
            "iteration: 400/500, train_loss: 0.4801, train_accuracy: 83.6925\n",
            "iteration: 500/500, train_loss: 0.4814, train_accuracy: 83.6860, test_loss: 0.5748, test_accuracy: 81.7100\n",
            "epoch 36/400:\n",
            "iteration: 100/500, train_loss: 0.4696, train_accuracy: 83.8600\n",
            "iteration: 200/500, train_loss: 0.4801, train_accuracy: 83.6650\n",
            "iteration: 300/500, train_loss: 0.4758, train_accuracy: 83.8033\n",
            "iteration: 400/500, train_loss: 0.4781, train_accuracy: 83.6875\n",
            "iteration: 500/500, train_loss: 0.4764, train_accuracy: 83.7200, test_loss: 0.5344, test_accuracy: 82.3900\n",
            "epoch 37/400:\n",
            "iteration: 100/500, train_loss: 0.4647, train_accuracy: 83.9200\n",
            "iteration: 200/500, train_loss: 0.4663, train_accuracy: 83.7350\n",
            "iteration: 300/500, train_loss: 0.4610, train_accuracy: 83.8767\n",
            "iteration: 400/500, train_loss: 0.4614, train_accuracy: 84.0275\n",
            "iteration: 500/500, train_loss: 0.4557, train_accuracy: 84.2520, test_loss: 0.5345, test_accuracy: 82.5700\n",
            "epoch 38/400:\n",
            "iteration: 100/500, train_loss: 0.4418, train_accuracy: 84.8200\n",
            "iteration: 200/500, train_loss: 0.4527, train_accuracy: 84.5150\n",
            "iteration: 300/500, train_loss: 0.4550, train_accuracy: 84.4400\n",
            "iteration: 400/500, train_loss: 0.4553, train_accuracy: 84.3775\n",
            "iteration: 500/500, train_loss: 0.4566, train_accuracy: 84.4140, test_loss: 0.5592, test_accuracy: 82.6200\n",
            "epoch 39/400:\n",
            "iteration: 100/500, train_loss: 0.5078, train_accuracy: 83.3900\n",
            "iteration: 200/500, train_loss: 0.4778, train_accuracy: 84.0000\n",
            "iteration: 300/500, train_loss: 0.4760, train_accuracy: 83.9367\n",
            "iteration: 400/500, train_loss: 0.4835, train_accuracy: 83.7575\n",
            "iteration: 500/500, train_loss: 0.4935, train_accuracy: 83.6780, test_loss: 0.5801, test_accuracy: 81.0100\n",
            "epoch 40/400:\n",
            "iteration: 100/500, train_loss: 0.4793, train_accuracy: 83.5600\n",
            "iteration: 200/500, train_loss: 0.4815, train_accuracy: 83.4150\n",
            "iteration: 300/500, train_loss: 0.4725, train_accuracy: 83.6367\n",
            "iteration: 400/500, train_loss: 0.4696, train_accuracy: 83.8400\n",
            "iteration: 500/500, train_loss: 0.4657, train_accuracy: 83.9460, test_loss: 0.5330, test_accuracy: 81.9700\n",
            "epoch 41/400:\n",
            "iteration: 100/500, train_loss: 0.4483, train_accuracy: 84.2900\n",
            "iteration: 200/500, train_loss: 0.4578, train_accuracy: 84.3150\n",
            "iteration: 300/500, train_loss: 0.4542, train_accuracy: 84.3333\n",
            "iteration: 400/500, train_loss: 0.4553, train_accuracy: 84.3825\n",
            "iteration: 500/500, train_loss: 0.4558, train_accuracy: 84.3720, test_loss: 0.5279, test_accuracy: 82.1800\n",
            "epoch 42/400:\n",
            "iteration: 100/500, train_loss: 0.4615, train_accuracy: 84.0500\n",
            "iteration: 200/500, train_loss: 0.4684, train_accuracy: 84.1150\n",
            "iteration: 300/500, train_loss: 0.4605, train_accuracy: 84.3133\n",
            "iteration: 400/500, train_loss: 0.4694, train_accuracy: 84.0675\n",
            "iteration: 500/500, train_loss: 0.4699, train_accuracy: 84.0540, test_loss: 0.5836, test_accuracy: 81.9500\n",
            "epoch 43/400:\n",
            "iteration: 100/500, train_loss: 0.4649, train_accuracy: 83.7000\n",
            "iteration: 200/500, train_loss: 0.4661, train_accuracy: 83.8500\n",
            "iteration: 300/500, train_loss: 0.4533, train_accuracy: 84.2733\n",
            "iteration: 400/500, train_loss: 0.4608, train_accuracy: 84.1825\n",
            "iteration: 500/500, train_loss: 0.4592, train_accuracy: 84.2400, test_loss: 0.5290, test_accuracy: 82.6000\n",
            "epoch 44/400:\n",
            "iteration: 100/500, train_loss: 0.4465, train_accuracy: 84.4600\n",
            "iteration: 200/500, train_loss: 0.4521, train_accuracy: 84.4850\n",
            "iteration: 300/500, train_loss: 0.4432, train_accuracy: 84.7133\n",
            "iteration: 400/500, train_loss: 0.4485, train_accuracy: 84.6100\n",
            "iteration: 500/500, train_loss: 0.4460, train_accuracy: 84.6760, test_loss: 0.5232, test_accuracy: 82.8100\n",
            "epoch 45/400:\n",
            "iteration: 100/500, train_loss: 0.4385, train_accuracy: 85.0900\n",
            "iteration: 200/500, train_loss: 0.4455, train_accuracy: 84.9100\n",
            "iteration: 300/500, train_loss: 0.4587, train_accuracy: 84.4433\n",
            "iteration: 400/500, train_loss: 0.4609, train_accuracy: 84.2625\n",
            "iteration: 500/500, train_loss: 0.4674, train_accuracy: 84.2900, test_loss: 0.5638, test_accuracy: 81.7500\n",
            "epoch 46/400:\n",
            "iteration: 100/500, train_loss: 0.4344, train_accuracy: 84.8800\n",
            "iteration: 200/500, train_loss: 0.4500, train_accuracy: 84.7050\n",
            "iteration: 300/500, train_loss: 0.4517, train_accuracy: 84.6567\n",
            "iteration: 400/500, train_loss: 0.4543, train_accuracy: 84.5300\n",
            "iteration: 500/500, train_loss: 0.4470, train_accuracy: 84.6820, test_loss: 0.5392, test_accuracy: 82.5700\n",
            "epoch 47/400:\n",
            "iteration: 100/500, train_loss: 0.4162, train_accuracy: 85.3200\n",
            "iteration: 200/500, train_loss: 0.4267, train_accuracy: 85.1400\n",
            "iteration: 300/500, train_loss: 0.4294, train_accuracy: 85.0300\n",
            "iteration: 400/500, train_loss: 0.4335, train_accuracy: 84.9425\n",
            "iteration: 500/500, train_loss: 0.4300, train_accuracy: 85.1540, test_loss: 0.5676, test_accuracy: 83.3400\n",
            "epoch 48/400:\n",
            "iteration: 100/500, train_loss: 0.4333, train_accuracy: 85.4800\n",
            "iteration: 200/500, train_loss: 0.4289, train_accuracy: 85.3650\n",
            "iteration: 300/500, train_loss: 0.4259, train_accuracy: 85.4700\n",
            "iteration: 400/500, train_loss: 0.4328, train_accuracy: 85.2550\n",
            "iteration: 500/500, train_loss: 0.4342, train_accuracy: 85.2960, test_loss: 0.5507, test_accuracy: 83.1900\n",
            "epoch 49/400:\n",
            "iteration: 100/500, train_loss: 0.4513, train_accuracy: 84.4200\n",
            "iteration: 200/500, train_loss: 0.4503, train_accuracy: 84.6200\n",
            "iteration: 300/500, train_loss: 0.4442, train_accuracy: 84.9000\n",
            "iteration: 400/500, train_loss: 0.4584, train_accuracy: 84.6600\n",
            "iteration: 500/500, train_loss: 0.4526, train_accuracy: 84.7740, test_loss: 0.5550, test_accuracy: 82.6300\n",
            "epoch 50/400:\n",
            "iteration: 100/500, train_loss: 0.4255, train_accuracy: 85.2800\n",
            "iteration: 200/500, train_loss: 0.4500, train_accuracy: 85.0100\n",
            "iteration: 300/500, train_loss: 0.4385, train_accuracy: 85.2733\n",
            "iteration: 400/500, train_loss: 0.4403, train_accuracy: 85.1275\n",
            "iteration: 500/500, train_loss: 0.4464, train_accuracy: 84.9960, test_loss: 0.5546, test_accuracy: 82.1200\n",
            "epoch 51/400:\n",
            "iteration: 100/500, train_loss: 0.4412, train_accuracy: 84.8200\n",
            "iteration: 200/500, train_loss: 0.4445, train_accuracy: 84.8250\n",
            "iteration: 300/500, train_loss: 0.4367, train_accuracy: 84.9800\n",
            "iteration: 400/500, train_loss: 0.4325, train_accuracy: 84.9750\n",
            "iteration: 500/500, train_loss: 0.4243, train_accuracy: 85.2600, test_loss: 0.5075, test_accuracy: 83.4200\n",
            "epoch 52/400:\n",
            "iteration: 100/500, train_loss: 0.4065, train_accuracy: 85.9400\n",
            "iteration: 200/500, train_loss: 0.4317, train_accuracy: 85.2850\n",
            "iteration: 300/500, train_loss: 0.4297, train_accuracy: 85.2767\n",
            "iteration: 400/500, train_loss: 0.4317, train_accuracy: 85.1275\n",
            "iteration: 500/500, train_loss: 0.4271, train_accuracy: 85.1980, test_loss: 0.5047, test_accuracy: 83.5100\n",
            "epoch 53/400:\n",
            "iteration: 100/500, train_loss: 0.4028, train_accuracy: 86.3700\n",
            "iteration: 200/500, train_loss: 0.4107, train_accuracy: 86.0950\n",
            "iteration: 300/500, train_loss: 0.4049, train_accuracy: 86.1567\n",
            "iteration: 400/500, train_loss: 0.4083, train_accuracy: 86.0050\n",
            "iteration: 500/500, train_loss: 0.4075, train_accuracy: 86.0660, test_loss: 0.4969, test_accuracy: 83.7900\n",
            "epoch 54/400:\n",
            "iteration: 100/500, train_loss: 0.3967, train_accuracy: 85.9700\n",
            "iteration: 200/500, train_loss: 0.4052, train_accuracy: 85.8050\n",
            "iteration: 300/500, train_loss: 0.4023, train_accuracy: 85.9667\n",
            "iteration: 400/500, train_loss: 0.4051, train_accuracy: 85.9500\n",
            "iteration: 500/500, train_loss: 0.4038, train_accuracy: 85.9940, test_loss: 0.5195, test_accuracy: 83.5100\n",
            "epoch 55/400:\n",
            "iteration: 100/500, train_loss: 0.4046, train_accuracy: 86.0600\n",
            "iteration: 200/500, train_loss: 0.4062, train_accuracy: 86.0500\n",
            "iteration: 300/500, train_loss: 0.4014, train_accuracy: 86.1133\n",
            "iteration: 400/500, train_loss: 0.4111, train_accuracy: 85.7400\n",
            "iteration: 500/500, train_loss: 0.4072, train_accuracy: 85.8760, test_loss: 0.5472, test_accuracy: 83.2800\n",
            "epoch 56/400:\n",
            "iteration: 100/500, train_loss: 0.4781, train_accuracy: 84.2500\n",
            "iteration: 200/500, train_loss: 0.5011, train_accuracy: 83.3700\n",
            "iteration: 300/500, train_loss: 0.4899, train_accuracy: 83.5300\n",
            "iteration: 400/500, train_loss: 0.4862, train_accuracy: 83.6925\n",
            "iteration: 500/500, train_loss: 0.4792, train_accuracy: 84.0500, test_loss: 0.5639, test_accuracy: 82.4400\n",
            "epoch 57/400:\n",
            "iteration: 100/500, train_loss: 0.5247, train_accuracy: 83.5900\n",
            "iteration: 200/500, train_loss: 0.5564, train_accuracy: 83.1700\n",
            "iteration: 300/500, train_loss: 0.5272, train_accuracy: 83.6733\n",
            "iteration: 400/500, train_loss: 0.5149, train_accuracy: 83.8675\n",
            "iteration: 500/500, train_loss: 0.4992, train_accuracy: 84.2120, test_loss: 0.5240, test_accuracy: 82.7600\n",
            "epoch 58/400:\n",
            "iteration: 100/500, train_loss: 0.4792, train_accuracy: 84.7600\n",
            "iteration: 200/500, train_loss: 0.4588, train_accuracy: 84.7850\n",
            "iteration: 300/500, train_loss: 0.4471, train_accuracy: 84.9200\n",
            "iteration: 400/500, train_loss: 0.4503, train_accuracy: 84.8400\n",
            "iteration: 500/500, train_loss: 0.4436, train_accuracy: 85.0900, test_loss: 0.5407, test_accuracy: 83.6400\n",
            "epoch 59/400:\n",
            "iteration: 100/500, train_loss: 0.4054, train_accuracy: 85.9500\n",
            "iteration: 200/500, train_loss: 0.4071, train_accuracy: 85.9950\n",
            "iteration: 300/500, train_loss: 0.4059, train_accuracy: 85.9133\n",
            "iteration: 400/500, train_loss: 0.4117, train_accuracy: 85.7750\n",
            "iteration: 500/500, train_loss: 0.4076, train_accuracy: 86.0320, test_loss: 0.6087, test_accuracy: 81.9100\n",
            "epoch 60/400:\n",
            "iteration: 100/500, train_loss: 0.4231, train_accuracy: 85.4000\n",
            "iteration: 200/500, train_loss: 0.4240, train_accuracy: 85.4200\n",
            "iteration: 300/500, train_loss: 0.4125, train_accuracy: 85.8000\n",
            "iteration: 400/500, train_loss: 0.4138, train_accuracy: 85.7425\n",
            "iteration: 500/500, train_loss: 0.4090, train_accuracy: 85.8000, test_loss: 0.5620, test_accuracy: 82.7000\n",
            "epoch 61/400:\n",
            "iteration: 100/500, train_loss: 0.4045, train_accuracy: 86.0300\n",
            "iteration: 200/500, train_loss: 0.4043, train_accuracy: 86.0050\n",
            "iteration: 300/500, train_loss: 0.3986, train_accuracy: 86.1567\n",
            "iteration: 400/500, train_loss: 0.3997, train_accuracy: 86.1475\n",
            "iteration: 500/500, train_loss: 0.3946, train_accuracy: 86.3080, test_loss: 0.5054, test_accuracy: 83.6200\n",
            "epoch 62/400:\n",
            "iteration: 100/500, train_loss: 0.3815, train_accuracy: 86.6100\n",
            "iteration: 200/500, train_loss: 0.3852, train_accuracy: 86.3050\n",
            "iteration: 300/500, train_loss: 0.3886, train_accuracy: 86.3767\n",
            "iteration: 400/500, train_loss: 0.3929, train_accuracy: 86.3050\n",
            "iteration: 500/500, train_loss: 0.3971, train_accuracy: 86.3000, test_loss: 0.4920, test_accuracy: 83.5800\n",
            "epoch 63/400:\n",
            "iteration: 100/500, train_loss: 0.3865, train_accuracy: 86.7200\n",
            "iteration: 200/500, train_loss: 0.4063, train_accuracy: 86.2900\n",
            "iteration: 300/500, train_loss: 0.4067, train_accuracy: 86.2333\n",
            "iteration: 400/500, train_loss: 0.4092, train_accuracy: 86.0800\n",
            "iteration: 500/500, train_loss: 0.4069, train_accuracy: 86.1040, test_loss: 0.5498, test_accuracy: 83.9000\n",
            "epoch 64/400:\n",
            "iteration: 100/500, train_loss: 0.3847, train_accuracy: 86.8200\n",
            "iteration: 200/500, train_loss: 0.4077, train_accuracy: 86.2450\n",
            "iteration: 300/500, train_loss: 0.4083, train_accuracy: 86.1833\n",
            "iteration: 400/500, train_loss: 0.4127, train_accuracy: 85.9375\n",
            "iteration: 500/500, train_loss: 0.4092, train_accuracy: 86.0280, test_loss: 0.5133, test_accuracy: 83.1200\n",
            "epoch 65/400:\n",
            "iteration: 100/500, train_loss: 0.3958, train_accuracy: 86.5700\n",
            "iteration: 200/500, train_loss: 0.3928, train_accuracy: 86.6800\n",
            "iteration: 300/500, train_loss: 0.3901, train_accuracy: 86.6267\n",
            "iteration: 400/500, train_loss: 0.3941, train_accuracy: 86.4425\n",
            "iteration: 500/500, train_loss: 0.3909, train_accuracy: 86.5100, test_loss: 0.4994, test_accuracy: 83.4800\n",
            "epoch 66/400:\n",
            "iteration: 100/500, train_loss: 0.3963, train_accuracy: 86.2300\n",
            "iteration: 200/500, train_loss: 0.3984, train_accuracy: 86.3100\n",
            "iteration: 300/500, train_loss: 0.3945, train_accuracy: 86.2833\n",
            "iteration: 400/500, train_loss: 0.4302, train_accuracy: 85.1950\n",
            "iteration: 500/500, train_loss: 0.4477, train_accuracy: 84.8300, test_loss: 0.5813, test_accuracy: 81.4200\n",
            "epoch 67/400:\n",
            "iteration: 100/500, train_loss: 0.4826, train_accuracy: 84.0800\n",
            "iteration: 200/500, train_loss: 0.4681, train_accuracy: 84.3850\n",
            "iteration: 300/500, train_loss: 0.4493, train_accuracy: 84.8300\n",
            "iteration: 400/500, train_loss: 0.4404, train_accuracy: 85.1275\n",
            "iteration: 500/500, train_loss: 0.4329, train_accuracy: 85.3580, test_loss: 0.5413, test_accuracy: 83.2000\n",
            "epoch 68/400:\n",
            "iteration: 100/500, train_loss: 0.3905, train_accuracy: 86.4200\n",
            "iteration: 200/500, train_loss: 0.3996, train_accuracy: 86.2000\n",
            "iteration: 300/500, train_loss: 0.3962, train_accuracy: 86.3400\n",
            "iteration: 400/500, train_loss: 0.3984, train_accuracy: 86.3275\n",
            "iteration: 500/500, train_loss: 0.3978, train_accuracy: 86.3840, test_loss: 0.5043, test_accuracy: 84.2700\n",
            "epoch 69/400:\n",
            "iteration: 100/500, train_loss: 0.3740, train_accuracy: 87.0500\n",
            "iteration: 200/500, train_loss: 0.3786, train_accuracy: 86.7950\n",
            "iteration: 300/500, train_loss: 0.3802, train_accuracy: 86.8767\n",
            "iteration: 400/500, train_loss: 0.3849, train_accuracy: 86.6500\n",
            "iteration: 500/500, train_loss: 0.3827, train_accuracy: 86.7680, test_loss: 0.4983, test_accuracy: 83.3200\n",
            "epoch 70/400:\n",
            "iteration: 100/500, train_loss: 0.3948, train_accuracy: 86.3800\n",
            "iteration: 200/500, train_loss: 0.3904, train_accuracy: 86.6150\n",
            "iteration: 300/500, train_loss: 0.3860, train_accuracy: 86.6533\n",
            "iteration: 400/500, train_loss: 0.3870, train_accuracy: 86.6550\n",
            "iteration: 500/500, train_loss: 0.3841, train_accuracy: 86.8200, test_loss: 0.5046, test_accuracy: 84.3200\n",
            "epoch 71/400:\n",
            "iteration: 100/500, train_loss: 0.3649, train_accuracy: 87.1400\n",
            "iteration: 200/500, train_loss: 0.3701, train_accuracy: 86.9750\n",
            "iteration: 300/500, train_loss: 0.3748, train_accuracy: 86.9133\n",
            "iteration: 400/500, train_loss: 0.3856, train_accuracy: 86.6600\n",
            "iteration: 500/500, train_loss: 0.3892, train_accuracy: 86.5860, test_loss: 0.5508, test_accuracy: 83.3600\n",
            "epoch 72/400:\n",
            "iteration: 100/500, train_loss: 0.3834, train_accuracy: 86.5500\n",
            "iteration: 200/500, train_loss: 0.3777, train_accuracy: 86.8300\n",
            "iteration: 300/500, train_loss: 0.3832, train_accuracy: 86.7133\n",
            "iteration: 400/500, train_loss: 0.3881, train_accuracy: 86.5800\n",
            "iteration: 500/500, train_loss: 0.3857, train_accuracy: 86.6320, test_loss: 0.4979, test_accuracy: 84.0100\n",
            "epoch 73/400:\n",
            "iteration: 100/500, train_loss: 0.3657, train_accuracy: 87.4200\n",
            "iteration: 200/500, train_loss: 0.3828, train_accuracy: 87.0200\n",
            "iteration: 300/500, train_loss: 0.4052, train_accuracy: 86.3267\n",
            "iteration: 400/500, train_loss: 0.4068, train_accuracy: 86.2000\n",
            "iteration: 500/500, train_loss: 0.4016, train_accuracy: 86.3000, test_loss: 0.4936, test_accuracy: 84.2100\n",
            "epoch 74/400:\n",
            "iteration: 100/500, train_loss: 0.3656, train_accuracy: 87.4100\n",
            "iteration: 200/500, train_loss: 0.3775, train_accuracy: 87.0800\n",
            "iteration: 300/500, train_loss: 0.4003, train_accuracy: 86.5700\n",
            "iteration: 400/500, train_loss: 0.4083, train_accuracy: 86.3050\n",
            "iteration: 500/500, train_loss: 0.4121, train_accuracy: 86.2920, test_loss: 0.7106, test_accuracy: 79.8700\n",
            "epoch 75/400:\n",
            "iteration: 100/500, train_loss: 0.5509, train_accuracy: 83.3100\n",
            "iteration: 200/500, train_loss: 0.4882, train_accuracy: 84.3150\n",
            "iteration: 300/500, train_loss: 0.4572, train_accuracy: 84.9733\n",
            "iteration: 400/500, train_loss: 0.4551, train_accuracy: 85.0050\n",
            "iteration: 500/500, train_loss: 0.4536, train_accuracy: 85.0960, test_loss: 0.5457, test_accuracy: 83.1800\n",
            "epoch 76/400:\n",
            "iteration: 100/500, train_loss: 0.4232, train_accuracy: 86.0700\n",
            "iteration: 200/500, train_loss: 0.4082, train_accuracy: 86.3450\n",
            "iteration: 300/500, train_loss: 0.4012, train_accuracy: 86.4933\n",
            "iteration: 400/500, train_loss: 0.4028, train_accuracy: 86.4450\n",
            "iteration: 500/500, train_loss: 0.3982, train_accuracy: 86.5380, test_loss: 0.5161, test_accuracy: 83.8400\n",
            "epoch 77/400:\n",
            "iteration: 100/500, train_loss: 0.3828, train_accuracy: 86.6600\n",
            "iteration: 200/500, train_loss: 0.3772, train_accuracy: 86.8450\n",
            "iteration: 300/500, train_loss: 0.3767, train_accuracy: 86.9400\n",
            "iteration: 400/500, train_loss: 0.3840, train_accuracy: 86.8600\n",
            "iteration: 500/500, train_loss: 0.3828, train_accuracy: 86.8440, test_loss: 0.4884, test_accuracy: 84.1100\n",
            "epoch 78/400:\n",
            "iteration: 100/500, train_loss: 0.3769, train_accuracy: 86.9200\n",
            "iteration: 200/500, train_loss: 0.3774, train_accuracy: 86.8650\n",
            "iteration: 300/500, train_loss: 0.3763, train_accuracy: 86.9133\n",
            "iteration: 400/500, train_loss: 0.3747, train_accuracy: 86.9275\n",
            "iteration: 500/500, train_loss: 0.3724, train_accuracy: 86.9400, test_loss: 0.4913, test_accuracy: 84.3100\n",
            "epoch 79/400:\n",
            "iteration: 100/500, train_loss: 0.3588, train_accuracy: 87.2800\n",
            "iteration: 200/500, train_loss: 0.3679, train_accuracy: 87.0800\n",
            "iteration: 300/500, train_loss: 0.3670, train_accuracy: 87.2500\n",
            "iteration: 400/500, train_loss: 0.3690, train_accuracy: 87.1650\n",
            "iteration: 500/500, train_loss: 0.3710, train_accuracy: 87.1640, test_loss: 0.5109, test_accuracy: 83.9700\n",
            "epoch 80/400:\n",
            "iteration: 100/500, train_loss: 0.3574, train_accuracy: 87.7100\n",
            "iteration: 200/500, train_loss: 0.3612, train_accuracy: 87.5200\n",
            "iteration: 300/500, train_loss: 0.3617, train_accuracy: 87.5000\n",
            "iteration: 400/500, train_loss: 0.3643, train_accuracy: 87.3750\n",
            "iteration: 500/500, train_loss: 0.3639, train_accuracy: 87.3540, test_loss: 0.4936, test_accuracy: 84.4100\n",
            "epoch 81/400:\n",
            "iteration: 100/500, train_loss: 0.3651, train_accuracy: 87.2500\n",
            "iteration: 200/500, train_loss: 0.3642, train_accuracy: 87.4400\n",
            "iteration: 300/500, train_loss: 0.3607, train_accuracy: 87.4867\n",
            "iteration: 400/500, train_loss: 0.3620, train_accuracy: 87.4000\n",
            "iteration: 500/500, train_loss: 0.3607, train_accuracy: 87.4760, test_loss: 0.5275, test_accuracy: 83.5800\n",
            "epoch 82/400:\n",
            "iteration: 100/500, train_loss: 0.3892, train_accuracy: 86.9100\n",
            "iteration: 200/500, train_loss: 0.3916, train_accuracy: 86.5000\n",
            "iteration: 300/500, train_loss: 0.3887, train_accuracy: 86.6267\n",
            "iteration: 400/500, train_loss: 0.3906, train_accuracy: 86.6475\n",
            "iteration: 500/500, train_loss: 0.3919, train_accuracy: 86.6740, test_loss: 0.6032, test_accuracy: 81.4800\n",
            "epoch 83/400:\n",
            "iteration: 100/500, train_loss: 0.3965, train_accuracy: 86.9100\n",
            "iteration: 200/500, train_loss: 0.3849, train_accuracy: 87.0350\n",
            "iteration: 300/500, train_loss: 0.3747, train_accuracy: 87.2200\n",
            "iteration: 400/500, train_loss: 0.3725, train_accuracy: 87.2525\n",
            "iteration: 500/500, train_loss: 0.3730, train_accuracy: 87.2720, test_loss: 0.5408, test_accuracy: 83.3700\n",
            "epoch 84/400:\n",
            "iteration: 100/500, train_loss: 0.3595, train_accuracy: 87.5000\n",
            "iteration: 200/500, train_loss: 0.3612, train_accuracy: 87.6200\n",
            "iteration: 300/500, train_loss: 0.3673, train_accuracy: 87.3067\n",
            "iteration: 400/500, train_loss: 0.3743, train_accuracy: 87.1000\n",
            "iteration: 500/500, train_loss: 0.3707, train_accuracy: 87.2620, test_loss: 0.5295, test_accuracy: 84.0400\n",
            "epoch 85/400:\n",
            "iteration: 100/500, train_loss: 0.4153, train_accuracy: 86.0200\n",
            "iteration: 200/500, train_loss: 0.3962, train_accuracy: 86.4300\n",
            "iteration: 300/500, train_loss: 0.3842, train_accuracy: 86.7033\n",
            "iteration: 400/500, train_loss: 0.3820, train_accuracy: 86.7950\n",
            "iteration: 500/500, train_loss: 0.3786, train_accuracy: 86.9860, test_loss: 0.5173, test_accuracy: 83.9100\n",
            "epoch 86/400:\n",
            "iteration: 100/500, train_loss: 0.3613, train_accuracy: 87.3500\n",
            "iteration: 200/500, train_loss: 0.3681, train_accuracy: 87.3600\n",
            "iteration: 300/500, train_loss: 0.3712, train_accuracy: 87.3633\n",
            "iteration: 400/500, train_loss: 0.3774, train_accuracy: 87.1950\n",
            "iteration: 500/500, train_loss: 0.3718, train_accuracy: 87.3320, test_loss: 0.4769, test_accuracy: 84.6900\n",
            "epoch 87/400:\n",
            "iteration: 100/500, train_loss: 0.3503, train_accuracy: 87.8100\n",
            "iteration: 200/500, train_loss: 0.3575, train_accuracy: 87.5800\n",
            "iteration: 300/500, train_loss: 0.3573, train_accuracy: 87.5000\n",
            "iteration: 400/500, train_loss: 0.3584, train_accuracy: 87.4900\n",
            "iteration: 500/500, train_loss: 0.3548, train_accuracy: 87.6560, test_loss: 0.4910, test_accuracy: 84.4100\n",
            "epoch 88/400:\n",
            "iteration: 100/500, train_loss: 0.3447, train_accuracy: 88.3800\n",
            "iteration: 200/500, train_loss: 0.3452, train_accuracy: 88.0450\n",
            "iteration: 300/500, train_loss: 0.3454, train_accuracy: 88.0367\n",
            "iteration: 400/500, train_loss: 0.3476, train_accuracy: 87.9275\n",
            "iteration: 500/500, train_loss: 0.3466, train_accuracy: 87.9560, test_loss: 0.4801, test_accuracy: 84.7100\n",
            "epoch 89/400:\n",
            "iteration: 100/500, train_loss: 0.3501, train_accuracy: 88.2200\n",
            "iteration: 200/500, train_loss: 0.3590, train_accuracy: 87.8900\n",
            "iteration: 300/500, train_loss: 0.3621, train_accuracy: 87.7467\n",
            "iteration: 400/500, train_loss: 0.3665, train_accuracy: 87.4725\n",
            "iteration: 500/500, train_loss: 0.3741, train_accuracy: 87.3940, test_loss: 0.7901, test_accuracy: 79.3000\n",
            "epoch 90/400:\n",
            "iteration: 100/500, train_loss: 0.6327, train_accuracy: 81.6700\n",
            "iteration: 200/500, train_loss: 0.5419, train_accuracy: 83.0400\n",
            "iteration: 300/500, train_loss: 0.4903, train_accuracy: 84.2333\n",
            "iteration: 400/500, train_loss: 0.4635, train_accuracy: 84.8775\n",
            "iteration: 500/500, train_loss: 0.4407, train_accuracy: 85.4720, test_loss: 0.4965, test_accuracy: 84.3900\n",
            "epoch 91/400:\n",
            "iteration: 100/500, train_loss: 0.3650, train_accuracy: 87.3900\n",
            "iteration: 200/500, train_loss: 0.3640, train_accuracy: 87.4150\n",
            "iteration: 300/500, train_loss: 0.3652, train_accuracy: 87.3967\n",
            "iteration: 400/500, train_loss: 0.3658, train_accuracy: 87.4150\n",
            "iteration: 500/500, train_loss: 0.3750, train_accuracy: 87.2760, test_loss: 0.5228, test_accuracy: 83.9000\n",
            "epoch 92/400:\n",
            "iteration: 100/500, train_loss: 0.3853, train_accuracy: 87.2100\n",
            "iteration: 200/500, train_loss: 0.3831, train_accuracy: 87.0450\n",
            "iteration: 300/500, train_loss: 0.3766, train_accuracy: 87.1367\n",
            "iteration: 400/500, train_loss: 0.3770, train_accuracy: 87.1025\n",
            "iteration: 500/500, train_loss: 0.3721, train_accuracy: 87.1820, test_loss: 0.4820, test_accuracy: 84.5900\n",
            "epoch 93/400:\n",
            "iteration: 100/500, train_loss: 0.3346, train_accuracy: 88.1200\n",
            "iteration: 200/500, train_loss: 0.3404, train_accuracy: 88.1850\n",
            "iteration: 300/500, train_loss: 0.3396, train_accuracy: 88.1533\n",
            "iteration: 400/500, train_loss: 0.3447, train_accuracy: 87.9975\n",
            "iteration: 500/500, train_loss: 0.3462, train_accuracy: 87.9460, test_loss: 0.5110, test_accuracy: 84.3900\n",
            "epoch 94/400:\n",
            "iteration: 100/500, train_loss: 0.3399, train_accuracy: 88.3600\n",
            "iteration: 200/500, train_loss: 0.3693, train_accuracy: 87.4500\n",
            "iteration: 300/500, train_loss: 0.4194, train_accuracy: 86.4367\n",
            "iteration: 400/500, train_loss: 0.4190, train_accuracy: 86.2650\n",
            "iteration: 500/500, train_loss: 0.4096, train_accuracy: 86.4340, test_loss: 0.5095, test_accuracy: 83.8600\n",
            "epoch 95/400:\n",
            "iteration: 100/500, train_loss: 0.3944, train_accuracy: 87.1100\n",
            "iteration: 200/500, train_loss: 0.3798, train_accuracy: 87.0000\n",
            "iteration: 300/500, train_loss: 0.3735, train_accuracy: 87.1967\n",
            "iteration: 400/500, train_loss: 0.3876, train_accuracy: 86.7925\n",
            "iteration: 500/500, train_loss: 0.3858, train_accuracy: 86.9700, test_loss: 0.5142, test_accuracy: 83.7900\n",
            "epoch 96/400:\n",
            "iteration: 100/500, train_loss: 0.3513, train_accuracy: 88.0000\n",
            "iteration: 200/500, train_loss: 0.3572, train_accuracy: 87.7850\n",
            "iteration: 300/500, train_loss: 0.3501, train_accuracy: 88.0733\n",
            "iteration: 400/500, train_loss: 0.3512, train_accuracy: 88.0100\n",
            "iteration: 500/500, train_loss: 0.3487, train_accuracy: 88.1340, test_loss: 0.5139, test_accuracy: 84.5500\n",
            "epoch 97/400:\n",
            "iteration: 100/500, train_loss: 0.3495, train_accuracy: 87.8900\n",
            "iteration: 200/500, train_loss: 0.3491, train_accuracy: 87.9850\n",
            "iteration: 300/500, train_loss: 0.3466, train_accuracy: 88.0967\n",
            "iteration: 400/500, train_loss: 0.3494, train_accuracy: 88.0050\n",
            "iteration: 500/500, train_loss: 0.3467, train_accuracy: 88.0140, test_loss: 0.4891, test_accuracy: 84.7200\n",
            "epoch 98/400:\n",
            "iteration: 100/500, train_loss: 0.3378, train_accuracy: 88.3000\n",
            "iteration: 200/500, train_loss: 0.3448, train_accuracy: 88.2000\n",
            "iteration: 300/500, train_loss: 0.3411, train_accuracy: 88.2733\n",
            "iteration: 400/500, train_loss: 0.3479, train_accuracy: 87.9950\n",
            "iteration: 500/500, train_loss: 0.3483, train_accuracy: 87.9540, test_loss: 0.4890, test_accuracy: 84.6700\n",
            "epoch 99/400:\n",
            "iteration: 100/500, train_loss: 0.3289, train_accuracy: 88.5700\n",
            "iteration: 200/500, train_loss: 0.3688, train_accuracy: 87.8750\n",
            "iteration: 300/500, train_loss: 0.3720, train_accuracy: 87.4767\n",
            "iteration: 400/500, train_loss: 0.3804, train_accuracy: 87.1850\n",
            "iteration: 500/500, train_loss: 0.3787, train_accuracy: 87.2460, test_loss: 0.5089, test_accuracy: 83.6100\n",
            "epoch 100/400:\n",
            "iteration: 100/500, train_loss: 0.3694, train_accuracy: 87.3600\n",
            "iteration: 200/500, train_loss: 0.3595, train_accuracy: 87.5800\n",
            "iteration: 300/500, train_loss: 0.3514, train_accuracy: 87.7433\n",
            "iteration: 400/500, train_loss: 0.3658, train_accuracy: 87.4475\n",
            "iteration: 500/500, train_loss: 0.3689, train_accuracy: 87.4000, test_loss: 0.5170, test_accuracy: 84.1200\n",
            "epoch 101/400:\n",
            "iteration: 100/500, train_loss: 0.3731, train_accuracy: 87.4900\n",
            "iteration: 200/500, train_loss: 0.3802, train_accuracy: 87.3250\n",
            "iteration: 300/500, train_loss: 0.3819, train_accuracy: 87.0667\n",
            "iteration: 400/500, train_loss: 0.3835, train_accuracy: 86.9750\n",
            "iteration: 500/500, train_loss: 0.3768, train_accuracy: 87.2100, test_loss: 0.5161, test_accuracy: 84.1400\n",
            "epoch 102/400:\n",
            "iteration: 100/500, train_loss: 0.3522, train_accuracy: 87.8700\n",
            "iteration: 200/500, train_loss: 0.3565, train_accuracy: 87.6300\n",
            "iteration: 300/500, train_loss: 0.3523, train_accuracy: 87.6567\n",
            "iteration: 400/500, train_loss: 0.3525, train_accuracy: 87.6550\n",
            "iteration: 500/500, train_loss: 0.3491, train_accuracy: 87.8320, test_loss: 0.5304, test_accuracy: 84.4800\n",
            "epoch 103/400:\n",
            "iteration: 100/500, train_loss: 0.3323, train_accuracy: 88.8100\n",
            "iteration: 200/500, train_loss: 0.3390, train_accuracy: 88.2750\n",
            "iteration: 300/500, train_loss: 0.3395, train_accuracy: 88.0867\n",
            "iteration: 400/500, train_loss: 0.3437, train_accuracy: 87.9175\n",
            "iteration: 500/500, train_loss: 0.3420, train_accuracy: 88.0740, test_loss: 0.5247, test_accuracy: 83.7100\n",
            "epoch 104/400:\n",
            "iteration: 100/500, train_loss: 0.3639, train_accuracy: 87.6400\n",
            "iteration: 200/500, train_loss: 0.3627, train_accuracy: 87.5650\n",
            "iteration: 300/500, train_loss: 0.3573, train_accuracy: 87.8600\n",
            "iteration: 400/500, train_loss: 0.3563, train_accuracy: 87.8700\n",
            "iteration: 500/500, train_loss: 0.3535, train_accuracy: 87.9580, test_loss: 0.4906, test_accuracy: 84.6000\n",
            "epoch 105/400:\n",
            "iteration: 100/500, train_loss: 0.3459, train_accuracy: 87.8300\n",
            "iteration: 200/500, train_loss: 0.3577, train_accuracy: 87.6050\n",
            "iteration: 300/500, train_loss: 0.3494, train_accuracy: 87.7967\n",
            "iteration: 400/500, train_loss: 0.3506, train_accuracy: 87.7325\n",
            "iteration: 500/500, train_loss: 0.3526, train_accuracy: 87.7880, test_loss: 0.6125, test_accuracy: 82.2900\n",
            "epoch 106/400:\n",
            "iteration: 100/500, train_loss: 0.3692, train_accuracy: 87.1500\n",
            "iteration: 200/500, train_loss: 0.3595, train_accuracy: 87.4300\n",
            "iteration: 300/500, train_loss: 0.3889, train_accuracy: 86.6733\n",
            "iteration: 400/500, train_loss: 0.4032, train_accuracy: 86.5425\n",
            "iteration: 500/500, train_loss: 0.3967, train_accuracy: 86.7140, test_loss: 0.5463, test_accuracy: 84.0300\n",
            "epoch 107/400:\n",
            "iteration: 100/500, train_loss: 0.3473, train_accuracy: 87.8800\n",
            "iteration: 200/500, train_loss: 0.3527, train_accuracy: 87.9100\n",
            "iteration: 300/500, train_loss: 0.3491, train_accuracy: 88.0100\n",
            "iteration: 400/500, train_loss: 0.3594, train_accuracy: 87.6775\n",
            "iteration: 500/500, train_loss: 0.3589, train_accuracy: 87.6460, test_loss: 0.4665, test_accuracy: 84.9900\n",
            "epoch 108/400:\n",
            "iteration: 100/500, train_loss: 0.3313, train_accuracy: 88.4900\n",
            "iteration: 200/500, train_loss: 0.3330, train_accuracy: 88.4450\n",
            "iteration: 300/500, train_loss: 0.3309, train_accuracy: 88.5467\n",
            "iteration: 400/500, train_loss: 0.3325, train_accuracy: 88.4500\n",
            "iteration: 500/500, train_loss: 0.3310, train_accuracy: 88.5120, test_loss: 0.4762, test_accuracy: 85.0400\n",
            "epoch 109/400:\n",
            "iteration: 100/500, train_loss: 0.3268, train_accuracy: 88.6800\n",
            "iteration: 200/500, train_loss: 0.3887, train_accuracy: 87.2900\n",
            "iteration: 300/500, train_loss: 0.4123, train_accuracy: 86.5667\n",
            "iteration: 400/500, train_loss: 0.4089, train_accuracy: 86.4875\n",
            "iteration: 500/500, train_loss: 0.3992, train_accuracy: 86.7680, test_loss: 0.5371, test_accuracy: 84.2000\n",
            "epoch 110/400:\n",
            "iteration: 100/500, train_loss: 0.3488, train_accuracy: 88.0200\n",
            "iteration: 200/500, train_loss: 0.3473, train_accuracy: 88.0100\n",
            "iteration: 300/500, train_loss: 0.3452, train_accuracy: 88.0133\n",
            "iteration: 400/500, train_loss: 0.3486, train_accuracy: 87.9625\n",
            "iteration: 500/500, train_loss: 0.3433, train_accuracy: 88.1140, test_loss: 0.4940, test_accuracy: 84.3200\n",
            "epoch 111/400:\n",
            "iteration: 100/500, train_loss: 0.3245, train_accuracy: 88.6000\n",
            "iteration: 200/500, train_loss: 0.3294, train_accuracy: 88.5350\n",
            "iteration: 300/500, train_loss: 0.3285, train_accuracy: 88.5900\n",
            "iteration: 400/500, train_loss: 0.3320, train_accuracy: 88.4400\n",
            "iteration: 500/500, train_loss: 0.3304, train_accuracy: 88.4980, test_loss: 0.5165, test_accuracy: 84.1000\n",
            "epoch 112/400:\n",
            "iteration: 100/500, train_loss: 0.3806, train_accuracy: 87.8600\n",
            "iteration: 200/500, train_loss: 0.3705, train_accuracy: 87.8650\n",
            "iteration: 300/500, train_loss: 0.3558, train_accuracy: 88.1067\n",
            "iteration: 400/500, train_loss: 0.3700, train_accuracy: 87.6425\n",
            "iteration: 500/500, train_loss: 0.3734, train_accuracy: 87.5460, test_loss: 0.5046, test_accuracy: 84.2100\n",
            "epoch 113/400:\n",
            "iteration: 100/500, train_loss: 0.3593, train_accuracy: 87.7100\n",
            "iteration: 200/500, train_loss: 0.3751, train_accuracy: 87.3600\n",
            "iteration: 300/500, train_loss: 0.3637, train_accuracy: 87.5333\n",
            "iteration: 400/500, train_loss: 0.3668, train_accuracy: 87.5100\n",
            "iteration: 500/500, train_loss: 0.3604, train_accuracy: 87.6620, test_loss: 0.4789, test_accuracy: 84.5600\n",
            "epoch 114/400:\n",
            "iteration: 100/500, train_loss: 0.3344, train_accuracy: 88.6000\n",
            "iteration: 200/500, train_loss: 0.3401, train_accuracy: 88.3650\n",
            "iteration: 300/500, train_loss: 0.3399, train_accuracy: 88.2833\n",
            "iteration: 400/500, train_loss: 0.3448, train_accuracy: 88.0825\n",
            "iteration: 500/500, train_loss: 0.3426, train_accuracy: 88.1500, test_loss: 0.4913, test_accuracy: 84.5900\n",
            "epoch 115/400:\n",
            "iteration: 100/500, train_loss: 0.3237, train_accuracy: 88.6100\n",
            "iteration: 200/500, train_loss: 0.3262, train_accuracy: 88.6550\n",
            "iteration: 300/500, train_loss: 0.3272, train_accuracy: 88.5933\n",
            "iteration: 400/500, train_loss: 0.3364, train_accuracy: 88.3400\n",
            "iteration: 500/500, train_loss: 0.3378, train_accuracy: 88.3040, test_loss: 0.6142, test_accuracy: 80.8200\n",
            "epoch 116/400:\n",
            "iteration: 100/500, train_loss: 0.4044, train_accuracy: 86.0200\n",
            "iteration: 200/500, train_loss: 0.3813, train_accuracy: 86.8900\n",
            "iteration: 300/500, train_loss: 0.3696, train_accuracy: 87.2667\n",
            "iteration: 400/500, train_loss: 0.3664, train_accuracy: 87.3575\n",
            "iteration: 500/500, train_loss: 0.3606, train_accuracy: 87.5520, test_loss: 0.5398, test_accuracy: 84.4000\n",
            "epoch 117/400:\n",
            "iteration: 100/500, train_loss: 0.3396, train_accuracy: 88.3100\n",
            "iteration: 200/500, train_loss: 0.3493, train_accuracy: 88.0300\n",
            "iteration: 300/500, train_loss: 0.3468, train_accuracy: 88.1867\n",
            "iteration: 400/500, train_loss: 0.3447, train_accuracy: 88.2200\n",
            "iteration: 500/500, train_loss: 0.3431, train_accuracy: 88.3260, test_loss: 0.5074, test_accuracy: 84.7200\n",
            "epoch 118/400:\n",
            "iteration: 100/500, train_loss: 0.3788, train_accuracy: 87.3600\n",
            "iteration: 200/500, train_loss: 0.3691, train_accuracy: 87.5350\n",
            "iteration: 300/500, train_loss: 0.3539, train_accuracy: 87.9300\n",
            "iteration: 400/500, train_loss: 0.3562, train_accuracy: 87.8375\n",
            "iteration: 500/500, train_loss: 0.3578, train_accuracy: 87.8240, test_loss: 0.5313, test_accuracy: 84.0800\n",
            "epoch 119/400:\n",
            "iteration: 100/500, train_loss: 0.3336, train_accuracy: 88.4000\n",
            "iteration: 200/500, train_loss: 0.3352, train_accuracy: 88.5100\n",
            "iteration: 300/500, train_loss: 0.3343, train_accuracy: 88.4533\n",
            "iteration: 400/500, train_loss: 0.3349, train_accuracy: 88.4125\n",
            "iteration: 500/500, train_loss: 0.3336, train_accuracy: 88.4200, test_loss: 0.5042, test_accuracy: 84.4600\n",
            "epoch 120/400:\n",
            "iteration: 100/500, train_loss: 0.3227, train_accuracy: 89.2900\n",
            "iteration: 200/500, train_loss: 0.3265, train_accuracy: 88.8450\n",
            "iteration: 300/500, train_loss: 0.3199, train_accuracy: 88.9233\n",
            "iteration: 400/500, train_loss: 0.3258, train_accuracy: 88.7900\n",
            "iteration: 500/500, train_loss: 0.3250, train_accuracy: 88.7780, test_loss: 0.5048, test_accuracy: 84.9000\n",
            "epoch 121/400:\n",
            "iteration: 100/500, train_loss: 0.3335, train_accuracy: 88.7000\n",
            "iteration: 200/500, train_loss: 0.3394, train_accuracy: 88.4600\n",
            "iteration: 300/500, train_loss: 0.3431, train_accuracy: 88.4167\n",
            "iteration: 400/500, train_loss: 0.3502, train_accuracy: 88.1925\n",
            "iteration: 500/500, train_loss: 0.3428, train_accuracy: 88.3340, test_loss: 0.5115, test_accuracy: 84.3400\n",
            "epoch 122/400:\n",
            "iteration: 100/500, train_loss: 0.3453, train_accuracy: 88.3900\n",
            "iteration: 200/500, train_loss: 0.3472, train_accuracy: 88.2050\n",
            "iteration: 300/500, train_loss: 0.3444, train_accuracy: 88.0667\n",
            "iteration: 400/500, train_loss: 0.3437, train_accuracy: 88.0650\n",
            "iteration: 500/500, train_loss: 0.3384, train_accuracy: 88.2620, test_loss: 0.4938, test_accuracy: 85.0800\n",
            "epoch 123/400:\n",
            "iteration: 100/500, train_loss: 0.3034, train_accuracy: 89.3400\n",
            "iteration: 200/500, train_loss: 0.3054, train_accuracy: 89.0850\n",
            "iteration: 300/500, train_loss: 0.3080, train_accuracy: 89.0567\n",
            "iteration: 400/500, train_loss: 0.3173, train_accuracy: 88.8350\n",
            "iteration: 500/500, train_loss: 0.3199, train_accuracy: 88.7620, test_loss: 0.4751, test_accuracy: 85.1200\n",
            "epoch 124/400:\n",
            "iteration: 100/500, train_loss: 0.3155, train_accuracy: 89.0700\n",
            "iteration: 200/500, train_loss: 0.3155, train_accuracy: 88.8650\n",
            "iteration: 300/500, train_loss: 0.3146, train_accuracy: 88.9167\n",
            "iteration: 400/500, train_loss: 0.3220, train_accuracy: 88.7950\n",
            "iteration: 500/500, train_loss: 0.3212, train_accuracy: 88.7960, test_loss: 0.4868, test_accuracy: 84.9500\n",
            "epoch 125/400:\n",
            "iteration: 100/500, train_loss: 0.3130, train_accuracy: 88.9800\n",
            "iteration: 200/500, train_loss: 0.3168, train_accuracy: 88.8200\n",
            "iteration: 300/500, train_loss: 0.3145, train_accuracy: 88.9467\n",
            "iteration: 400/500, train_loss: 0.3170, train_accuracy: 88.8800\n",
            "iteration: 500/500, train_loss: 0.3478, train_accuracy: 88.2700, test_loss: 0.5606, test_accuracy: 82.4400\n",
            "epoch 126/400:\n",
            "iteration: 100/500, train_loss: 0.3774, train_accuracy: 86.9200\n",
            "iteration: 200/500, train_loss: 0.3745, train_accuracy: 87.0900\n",
            "iteration: 300/500, train_loss: 0.3631, train_accuracy: 87.5100\n",
            "iteration: 400/500, train_loss: 0.3575, train_accuracy: 87.6825\n",
            "iteration: 500/500, train_loss: 0.3518, train_accuracy: 87.8460, test_loss: 0.4749, test_accuracy: 84.5400\n",
            "epoch 127/400:\n",
            "iteration: 100/500, train_loss: 0.3182, train_accuracy: 88.9800\n",
            "iteration: 200/500, train_loss: 0.3282, train_accuracy: 88.6150\n",
            "iteration: 300/500, train_loss: 0.3225, train_accuracy: 88.6633\n",
            "iteration: 400/500, train_loss: 0.3264, train_accuracy: 88.5925\n",
            "iteration: 500/500, train_loss: 0.3325, train_accuracy: 88.6740, test_loss: 0.5653, test_accuracy: 84.1400\n",
            "epoch 128/400:\n",
            "iteration: 100/500, train_loss: 0.3398, train_accuracy: 88.6200\n",
            "iteration: 200/500, train_loss: 0.3331, train_accuracy: 88.4750\n",
            "iteration: 300/500, train_loss: 0.3291, train_accuracy: 88.5367\n",
            "iteration: 400/500, train_loss: 0.3285, train_accuracy: 88.5775\n",
            "iteration: 500/500, train_loss: 0.3228, train_accuracy: 88.7960, test_loss: 0.4658, test_accuracy: 85.1200\n",
            "epoch 129/400:\n",
            "iteration: 100/500, train_loss: 0.3010, train_accuracy: 89.4200\n",
            "iteration: 200/500, train_loss: 0.3081, train_accuracy: 89.1600\n",
            "iteration: 300/500, train_loss: 0.3083, train_accuracy: 89.1233\n",
            "iteration: 400/500, train_loss: 0.3124, train_accuracy: 88.9925\n",
            "iteration: 500/500, train_loss: 0.3156, train_accuracy: 88.9900, test_loss: 0.5065, test_accuracy: 84.6000\n",
            "epoch 130/400:\n",
            "iteration: 100/500, train_loss: 0.3131, train_accuracy: 89.3500\n",
            "iteration: 200/500, train_loss: 0.3195, train_accuracy: 89.0250\n",
            "iteration: 300/500, train_loss: 0.3190, train_accuracy: 89.0233\n",
            "iteration: 400/500, train_loss: 0.3270, train_accuracy: 88.7375\n",
            "iteration: 500/500, train_loss: 0.3224, train_accuracy: 88.9020, test_loss: 0.4761, test_accuracy: 84.9300\n",
            "epoch 131/400:\n",
            "iteration: 100/500, train_loss: 0.3114, train_accuracy: 88.9300\n",
            "iteration: 200/500, train_loss: 0.3182, train_accuracy: 88.9300\n",
            "iteration: 300/500, train_loss: 0.3196, train_accuracy: 89.0067\n",
            "iteration: 400/500, train_loss: 0.3271, train_accuracy: 88.7900\n",
            "iteration: 500/500, train_loss: 0.3270, train_accuracy: 88.7480, test_loss: 0.4830, test_accuracy: 84.8400\n",
            "epoch 132/400:\n",
            "iteration: 100/500, train_loss: 0.3093, train_accuracy: 89.3500\n",
            "iteration: 200/500, train_loss: 0.3163, train_accuracy: 89.2050\n",
            "iteration: 300/500, train_loss: 0.3137, train_accuracy: 89.2100\n",
            "iteration: 400/500, train_loss: 0.3172, train_accuracy: 89.1000\n",
            "iteration: 500/500, train_loss: 0.3228, train_accuracy: 89.0300, test_loss: 0.5225, test_accuracy: 84.0400\n",
            "epoch 133/400:\n",
            "iteration: 100/500, train_loss: 0.3519, train_accuracy: 88.4800\n",
            "iteration: 200/500, train_loss: 0.3467, train_accuracy: 88.4600\n",
            "iteration: 300/500, train_loss: 0.3362, train_accuracy: 88.5467\n",
            "iteration: 400/500, train_loss: 0.3344, train_accuracy: 88.5350\n",
            "iteration: 500/500, train_loss: 0.3260, train_accuracy: 88.8040, test_loss: 0.5022, test_accuracy: 85.4000\n",
            "epoch 134/400:\n",
            "iteration: 100/500, train_loss: 0.3066, train_accuracy: 89.0200\n",
            "iteration: 200/500, train_loss: 0.3122, train_accuracy: 88.8300\n",
            "iteration: 300/500, train_loss: 0.3132, train_accuracy: 88.9400\n",
            "iteration: 400/500, train_loss: 0.3169, train_accuracy: 88.8975\n",
            "iteration: 500/500, train_loss: 0.3135, train_accuracy: 89.0280, test_loss: 0.4607, test_accuracy: 85.0800\n",
            "epoch 135/400:\n",
            "iteration: 100/500, train_loss: 0.3315, train_accuracy: 88.7500\n",
            "iteration: 200/500, train_loss: 0.3714, train_accuracy: 88.3500\n",
            "iteration: 300/500, train_loss: 0.3521, train_accuracy: 88.5400\n",
            "iteration: 400/500, train_loss: 0.3787, train_accuracy: 88.0475\n",
            "iteration: 500/500, train_loss: 0.3831, train_accuracy: 87.7800, test_loss: 0.5411, test_accuracy: 83.8000\n",
            "epoch 136/400:\n",
            "iteration: 100/500, train_loss: 0.3506, train_accuracy: 88.2200\n",
            "iteration: 200/500, train_loss: 0.3822, train_accuracy: 87.7050\n",
            "iteration: 300/500, train_loss: 0.3710, train_accuracy: 87.6933\n",
            "iteration: 400/500, train_loss: 0.3689, train_accuracy: 87.8000\n",
            "iteration: 500/500, train_loss: 0.3607, train_accuracy: 87.9700, test_loss: 0.5644, test_accuracy: 85.0000\n",
            "epoch 137/400:\n",
            "iteration: 100/500, train_loss: 0.3252, train_accuracy: 88.9100\n",
            "iteration: 200/500, train_loss: 0.3291, train_accuracy: 88.6850\n",
            "iteration: 300/500, train_loss: 0.3196, train_accuracy: 88.9267\n",
            "iteration: 400/500, train_loss: 0.3217, train_accuracy: 88.8125\n",
            "iteration: 500/500, train_loss: 0.3243, train_accuracy: 88.8180, test_loss: 0.5198, test_accuracy: 84.7300\n",
            "epoch 138/400:\n",
            "iteration: 100/500, train_loss: 0.3202, train_accuracy: 89.1900\n",
            "iteration: 200/500, train_loss: 0.3191, train_accuracy: 89.0500\n",
            "iteration: 300/500, train_loss: 0.3198, train_accuracy: 88.9700\n",
            "iteration: 400/500, train_loss: 0.3232, train_accuracy: 88.7900\n",
            "iteration: 500/500, train_loss: 0.3213, train_accuracy: 88.8000, test_loss: 0.4856, test_accuracy: 84.6600\n",
            "epoch 139/400:\n",
            "iteration: 100/500, train_loss: 0.3052, train_accuracy: 89.1500\n",
            "iteration: 200/500, train_loss: 0.3118, train_accuracy: 89.2250\n",
            "iteration: 300/500, train_loss: 0.3097, train_accuracy: 89.3033\n",
            "iteration: 400/500, train_loss: 0.3142, train_accuracy: 89.0900\n",
            "iteration: 500/500, train_loss: 0.3135, train_accuracy: 89.1260, test_loss: 0.4596, test_accuracy: 85.4400\n",
            "epoch 140/400:\n",
            "iteration: 100/500, train_loss: 0.3033, train_accuracy: 89.5800\n",
            "iteration: 200/500, train_loss: 0.3121, train_accuracy: 89.2250\n",
            "iteration: 300/500, train_loss: 0.3104, train_accuracy: 89.2233\n",
            "iteration: 400/500, train_loss: 0.3179, train_accuracy: 89.0650\n",
            "iteration: 500/500, train_loss: 0.3167, train_accuracy: 89.0880, test_loss: 0.4716, test_accuracy: 85.3800\n",
            "epoch 141/400:\n",
            "iteration: 100/500, train_loss: 0.3075, train_accuracy: 89.2800\n",
            "iteration: 200/500, train_loss: 0.3098, train_accuracy: 89.2250\n",
            "iteration: 300/500, train_loss: 0.3072, train_accuracy: 89.1867\n",
            "iteration: 400/500, train_loss: 0.3114, train_accuracy: 89.0300\n",
            "iteration: 500/500, train_loss: 0.3178, train_accuracy: 88.9340, test_loss: 0.5299, test_accuracy: 84.3100\n",
            "epoch 142/400:\n",
            "iteration: 100/500, train_loss: 0.3379, train_accuracy: 88.5200\n",
            "iteration: 200/500, train_loss: 0.3334, train_accuracy: 88.5000\n",
            "iteration: 300/500, train_loss: 0.3318, train_accuracy: 88.5000\n",
            "iteration: 400/500, train_loss: 0.3302, train_accuracy: 88.5125\n",
            "iteration: 500/500, train_loss: 0.3252, train_accuracy: 88.6720, test_loss: 0.4872, test_accuracy: 85.0100\n",
            "epoch 143/400:\n",
            "iteration: 100/500, train_loss: 0.3019, train_accuracy: 89.5400\n",
            "iteration: 200/500, train_loss: 0.3054, train_accuracy: 89.2950\n",
            "iteration: 300/500, train_loss: 0.3020, train_accuracy: 89.4333\n",
            "iteration: 400/500, train_loss: 0.3063, train_accuracy: 89.3125\n",
            "iteration: 500/500, train_loss: 0.3034, train_accuracy: 89.3820, test_loss: 0.4723, test_accuracy: 85.0300\n",
            "epoch 144/400:\n",
            "iteration: 100/500, train_loss: 0.2879, train_accuracy: 89.6500\n",
            "iteration: 200/500, train_loss: 0.2948, train_accuracy: 89.4700\n",
            "iteration: 300/500, train_loss: 0.2978, train_accuracy: 89.4967\n",
            "iteration: 400/500, train_loss: 0.3154, train_accuracy: 89.0900\n",
            "iteration: 500/500, train_loss: 0.3238, train_accuracy: 88.8520, test_loss: 0.5613, test_accuracy: 84.0400\n",
            "epoch 145/400:\n",
            "iteration: 100/500, train_loss: 0.3166, train_accuracy: 89.0000\n",
            "iteration: 200/500, train_loss: 0.3175, train_accuracy: 89.0450\n",
            "iteration: 300/500, train_loss: 0.3170, train_accuracy: 89.0233\n",
            "iteration: 400/500, train_loss: 0.3180, train_accuracy: 88.9875\n",
            "iteration: 500/500, train_loss: 0.3184, train_accuracy: 88.9920, test_loss: 0.5327, test_accuracy: 84.2800\n",
            "epoch 146/400:\n",
            "iteration: 100/500, train_loss: 0.2987, train_accuracy: 89.5100\n",
            "iteration: 200/500, train_loss: 0.3267, train_accuracy: 88.9850\n",
            "iteration: 300/500, train_loss: 0.3206, train_accuracy: 89.0400\n",
            "iteration: 400/500, train_loss: 0.3219, train_accuracy: 89.0125\n",
            "iteration: 500/500, train_loss: 0.3190, train_accuracy: 89.0860, test_loss: 0.4889, test_accuracy: 84.9100\n",
            "epoch 147/400:\n",
            "iteration: 100/500, train_loss: 0.3248, train_accuracy: 89.3500\n",
            "iteration: 200/500, train_loss: 0.3180, train_accuracy: 89.2150\n",
            "iteration: 300/500, train_loss: 0.3120, train_accuracy: 89.2267\n",
            "iteration: 400/500, train_loss: 0.3122, train_accuracy: 89.1550\n",
            "iteration: 500/500, train_loss: 0.3079, train_accuracy: 89.3080, test_loss: 0.4818, test_accuracy: 85.3900\n",
            "epoch 148/400:\n",
            "iteration: 100/500, train_loss: 0.3191, train_accuracy: 88.8900\n",
            "iteration: 200/500, train_loss: 0.3248, train_accuracy: 88.7000\n",
            "iteration: 300/500, train_loss: 0.3482, train_accuracy: 88.1233\n",
            "iteration: 400/500, train_loss: 0.3535, train_accuracy: 87.9475\n",
            "iteration: 500/500, train_loss: 0.3473, train_accuracy: 88.1220, test_loss: 0.4805, test_accuracy: 84.5800\n",
            "epoch 149/400:\n",
            "iteration: 100/500, train_loss: 0.3093, train_accuracy: 89.1300\n",
            "iteration: 200/500, train_loss: 0.3094, train_accuracy: 89.2450\n",
            "iteration: 300/500, train_loss: 0.3101, train_accuracy: 89.1933\n",
            "iteration: 400/500, train_loss: 0.3122, train_accuracy: 89.0325\n",
            "iteration: 500/500, train_loss: 0.3093, train_accuracy: 89.1040, test_loss: 0.4768, test_accuracy: 85.1100\n",
            "epoch 150/400:\n",
            "iteration: 100/500, train_loss: 0.3045, train_accuracy: 89.4800\n",
            "iteration: 200/500, train_loss: 0.3123, train_accuracy: 89.4150\n",
            "iteration: 300/500, train_loss: 0.3103, train_accuracy: 89.2867\n",
            "iteration: 400/500, train_loss: 0.3103, train_accuracy: 89.3050\n",
            "iteration: 500/500, train_loss: 0.3098, train_accuracy: 89.3100, test_loss: 0.5001, test_accuracy: 84.5400\n",
            "epoch 151/400:\n",
            "iteration: 100/500, train_loss: 0.2958, train_accuracy: 89.7700\n",
            "iteration: 200/500, train_loss: 0.3049, train_accuracy: 89.4400\n",
            "iteration: 300/500, train_loss: 0.3048, train_accuracy: 89.3867\n",
            "iteration: 400/500, train_loss: 0.3078, train_accuracy: 89.2200\n",
            "iteration: 500/500, train_loss: 0.3098, train_accuracy: 89.2560, test_loss: 0.5818, test_accuracy: 83.1800\n",
            "epoch 152/400:\n",
            "iteration: 100/500, train_loss: 0.5340, train_accuracy: 82.9500\n",
            "iteration: 200/500, train_loss: 0.5010, train_accuracy: 84.6000\n",
            "iteration: 300/500, train_loss: 0.4887, train_accuracy: 85.1633\n",
            "iteration: 400/500, train_loss: 0.4631, train_accuracy: 85.5825\n",
            "iteration: 500/500, train_loss: 0.4379, train_accuracy: 86.1740, test_loss: 0.4856, test_accuracy: 84.7800\n",
            "epoch 153/400:\n",
            "iteration: 100/500, train_loss: 0.3253, train_accuracy: 88.7000\n",
            "iteration: 200/500, train_loss: 0.3331, train_accuracy: 88.4800\n",
            "iteration: 300/500, train_loss: 0.3250, train_accuracy: 88.7300\n",
            "iteration: 400/500, train_loss: 0.3309, train_accuracy: 88.7250\n",
            "iteration: 500/500, train_loss: 0.3388, train_accuracy: 88.6200, test_loss: 0.5558, test_accuracy: 83.3200\n",
            "epoch 154/400:\n",
            "iteration: 100/500, train_loss: 0.3341, train_accuracy: 88.2300\n",
            "iteration: 200/500, train_loss: 0.3259, train_accuracy: 88.6500\n",
            "iteration: 300/500, train_loss: 0.3234, train_accuracy: 88.6733\n",
            "iteration: 400/500, train_loss: 0.3264, train_accuracy: 88.6225\n",
            "iteration: 500/500, train_loss: 0.3209, train_accuracy: 88.7920, test_loss: 0.4569, test_accuracy: 85.6700\n",
            "epoch 155/400:\n",
            "iteration: 100/500, train_loss: 0.3265, train_accuracy: 89.4000\n",
            "iteration: 200/500, train_loss: 0.3217, train_accuracy: 89.3150\n",
            "iteration: 300/500, train_loss: 0.3172, train_accuracy: 89.3667\n",
            "iteration: 400/500, train_loss: 0.3197, train_accuracy: 89.2400\n",
            "iteration: 500/500, train_loss: 0.3184, train_accuracy: 89.2380, test_loss: 0.4889, test_accuracy: 85.1500\n",
            "epoch 156/400:\n",
            "iteration: 100/500, train_loss: 0.3042, train_accuracy: 89.3300\n",
            "iteration: 200/500, train_loss: 0.3114, train_accuracy: 89.3150\n",
            "iteration: 300/500, train_loss: 0.3108, train_accuracy: 89.2333\n",
            "iteration: 400/500, train_loss: 0.3176, train_accuracy: 89.0575\n",
            "iteration: 500/500, train_loss: 0.3142, train_accuracy: 89.1340, test_loss: 0.4775, test_accuracy: 85.1100\n",
            "epoch 157/400:\n",
            "iteration: 100/500, train_loss: 0.3040, train_accuracy: 89.4800\n",
            "iteration: 200/500, train_loss: 0.3102, train_accuracy: 89.3450\n",
            "iteration: 300/500, train_loss: 0.3047, train_accuracy: 89.3467\n",
            "iteration: 400/500, train_loss: 0.3078, train_accuracy: 89.2475\n",
            "iteration: 500/500, train_loss: 0.3038, train_accuracy: 89.4240, test_loss: 0.4732, test_accuracy: 85.0300\n",
            "epoch 158/400:\n",
            "iteration: 100/500, train_loss: 0.2863, train_accuracy: 90.0500\n",
            "iteration: 200/500, train_loss: 0.3021, train_accuracy: 89.4850\n",
            "iteration: 300/500, train_loss: 0.2979, train_accuracy: 89.5167\n",
            "iteration: 400/500, train_loss: 0.2985, train_accuracy: 89.4900\n",
            "iteration: 500/500, train_loss: 0.2970, train_accuracy: 89.5500, test_loss: 0.4723, test_accuracy: 85.1400\n",
            "epoch 159/400:\n",
            "iteration: 100/500, train_loss: 0.2820, train_accuracy: 90.1200\n",
            "iteration: 200/500, train_loss: 0.2962, train_accuracy: 89.7200\n",
            "iteration: 300/500, train_loss: 0.3001, train_accuracy: 89.5600\n",
            "iteration: 400/500, train_loss: 0.3023, train_accuracy: 89.3750\n",
            "iteration: 500/500, train_loss: 0.3073, train_accuracy: 89.3420, test_loss: 0.5366, test_accuracy: 84.1500\n",
            "epoch 160/400:\n",
            "iteration: 100/500, train_loss: 0.3062, train_accuracy: 89.1300\n",
            "iteration: 200/500, train_loss: 0.3135, train_accuracy: 89.0250\n",
            "iteration: 300/500, train_loss: 0.3104, train_accuracy: 89.0033\n",
            "iteration: 400/500, train_loss: 0.3112, train_accuracy: 88.9325\n",
            "iteration: 500/500, train_loss: 0.3088, train_accuracy: 89.0560, test_loss: 0.4874, test_accuracy: 85.3200\n",
            "epoch 161/400:\n",
            "iteration: 100/500, train_loss: 0.3123, train_accuracy: 89.0400\n",
            "iteration: 200/500, train_loss: 0.3121, train_accuracy: 89.1350\n",
            "iteration: 300/500, train_loss: 0.3105, train_accuracy: 89.1133\n",
            "iteration: 400/500, train_loss: 0.3125, train_accuracy: 89.0625\n",
            "iteration: 500/500, train_loss: 0.3125, train_accuracy: 89.1320, test_loss: 0.4671, test_accuracy: 85.0900\n",
            "epoch 162/400:\n",
            "iteration: 100/500, train_loss: 0.2920, train_accuracy: 90.0200\n",
            "iteration: 200/500, train_loss: 0.2953, train_accuracy: 89.7000\n",
            "iteration: 300/500, train_loss: 0.3199, train_accuracy: 89.4200\n",
            "iteration: 400/500, train_loss: 0.3183, train_accuracy: 89.3200\n",
            "iteration: 500/500, train_loss: 0.3133, train_accuracy: 89.3460, test_loss: 0.4680, test_accuracy: 84.9600\n",
            "epoch 163/400:\n",
            "iteration: 100/500, train_loss: 0.2939, train_accuracy: 89.7800\n",
            "iteration: 200/500, train_loss: 0.2987, train_accuracy: 89.6400\n",
            "iteration: 300/500, train_loss: 0.3014, train_accuracy: 89.5967\n",
            "iteration: 400/500, train_loss: 0.3036, train_accuracy: 89.5000\n",
            "iteration: 500/500, train_loss: 0.2989, train_accuracy: 89.5740, test_loss: 0.4729, test_accuracy: 84.7800\n",
            "epoch 164/400:\n",
            "iteration: 100/500, train_loss: 0.2838, train_accuracy: 89.9200\n",
            "iteration: 200/500, train_loss: 0.3044, train_accuracy: 89.3500\n",
            "iteration: 300/500, train_loss: 0.3014, train_accuracy: 89.3833\n",
            "iteration: 400/500, train_loss: 0.3017, train_accuracy: 89.4250\n",
            "iteration: 500/500, train_loss: 0.3033, train_accuracy: 89.4340, test_loss: 0.6766, test_accuracy: 81.6700\n",
            "epoch 165/400:\n",
            "iteration: 100/500, train_loss: 0.4272, train_accuracy: 86.1900\n",
            "iteration: 200/500, train_loss: 0.4015, train_accuracy: 86.8450\n",
            "iteration: 300/500, train_loss: 0.3773, train_accuracy: 87.3600\n",
            "iteration: 400/500, train_loss: 0.3677, train_accuracy: 87.6300\n",
            "iteration: 500/500, train_loss: 0.3540, train_accuracy: 87.9760, test_loss: 0.5064, test_accuracy: 85.4400\n",
            "epoch 166/400:\n",
            "iteration: 100/500, train_loss: 0.3121, train_accuracy: 89.3900\n",
            "iteration: 200/500, train_loss: 0.3150, train_accuracy: 89.1950\n",
            "iteration: 300/500, train_loss: 0.3084, train_accuracy: 89.2367\n",
            "iteration: 400/500, train_loss: 0.3084, train_accuracy: 89.1525\n",
            "iteration: 500/500, train_loss: 0.3055, train_accuracy: 89.2580, test_loss: 0.4819, test_accuracy: 84.6300\n",
            "epoch 167/400:\n",
            "iteration: 100/500, train_loss: 0.3003, train_accuracy: 89.4800\n",
            "iteration: 200/500, train_loss: 0.3039, train_accuracy: 89.3450\n",
            "iteration: 300/500, train_loss: 0.3027, train_accuracy: 89.3467\n",
            "iteration: 400/500, train_loss: 0.3016, train_accuracy: 89.3825\n",
            "iteration: 500/500, train_loss: 0.2986, train_accuracy: 89.5480, test_loss: 0.4970, test_accuracy: 84.4800\n",
            "epoch 168/400:\n",
            "iteration: 100/500, train_loss: 0.2876, train_accuracy: 90.3500\n",
            "iteration: 200/500, train_loss: 0.2942, train_accuracy: 90.0150\n",
            "iteration: 300/500, train_loss: 0.2909, train_accuracy: 89.9333\n",
            "iteration: 400/500, train_loss: 0.2921, train_accuracy: 89.8700\n",
            "iteration: 500/500, train_loss: 0.2906, train_accuracy: 89.9320, test_loss: 0.4693, test_accuracy: 85.2900\n",
            "epoch 169/400:\n",
            "iteration: 100/500, train_loss: 0.2904, train_accuracy: 89.8100\n",
            "iteration: 200/500, train_loss: 0.2941, train_accuracy: 89.8400\n",
            "iteration: 300/500, train_loss: 0.2977, train_accuracy: 89.7800\n",
            "iteration: 400/500, train_loss: 0.3029, train_accuracy: 89.6200\n",
            "iteration: 500/500, train_loss: 0.3034, train_accuracy: 89.6080, test_loss: 0.5327, test_accuracy: 84.4500\n",
            "epoch 170/400:\n",
            "iteration: 100/500, train_loss: 0.3435, train_accuracy: 89.0100\n",
            "iteration: 200/500, train_loss: 0.3730, train_accuracy: 88.4000\n",
            "iteration: 300/500, train_loss: 0.3622, train_accuracy: 88.2933\n",
            "iteration: 400/500, train_loss: 0.3567, train_accuracy: 88.2725\n",
            "iteration: 500/500, train_loss: 0.3515, train_accuracy: 88.4360, test_loss: 0.5849, test_accuracy: 84.3800\n",
            "epoch 171/400:\n",
            "iteration: 100/500, train_loss: 0.3483, train_accuracy: 88.0500\n",
            "iteration: 200/500, train_loss: 0.3343, train_accuracy: 88.4650\n",
            "iteration: 300/500, train_loss: 0.3228, train_accuracy: 88.7933\n",
            "iteration: 400/500, train_loss: 0.3196, train_accuracy: 88.9550\n",
            "iteration: 500/500, train_loss: 0.3143, train_accuracy: 89.1240, test_loss: 0.4700, test_accuracy: 85.7800\n",
            "epoch 172/400:\n",
            "iteration: 100/500, train_loss: 0.2881, train_accuracy: 90.0700\n",
            "iteration: 200/500, train_loss: 0.2900, train_accuracy: 89.8200\n",
            "iteration: 300/500, train_loss: 0.3097, train_accuracy: 89.3367\n",
            "iteration: 400/500, train_loss: 0.3126, train_accuracy: 89.2025\n",
            "iteration: 500/500, train_loss: 0.3078, train_accuracy: 89.3360, test_loss: 0.4665, test_accuracy: 85.3100\n",
            "epoch 173/400:\n",
            "iteration: 100/500, train_loss: 0.3251, train_accuracy: 89.6600\n",
            "iteration: 200/500, train_loss: 0.3210, train_accuracy: 89.3700\n",
            "iteration: 300/500, train_loss: 0.3104, train_accuracy: 89.5667\n",
            "iteration: 400/500, train_loss: 0.3079, train_accuracy: 89.5075\n",
            "iteration: 500/500, train_loss: 0.3059, train_accuracy: 89.6100, test_loss: 0.5380, test_accuracy: 85.1300\n",
            "epoch 174/400:\n",
            "iteration: 100/500, train_loss: 0.2919, train_accuracy: 90.0000\n",
            "iteration: 200/500, train_loss: 0.2958, train_accuracy: 89.8350\n",
            "iteration: 300/500, train_loss: 0.2944, train_accuracy: 89.7900\n",
            "iteration: 400/500, train_loss: 0.2999, train_accuracy: 89.5575\n",
            "iteration: 500/500, train_loss: 0.2957, train_accuracy: 89.6380, test_loss: 0.4838, test_accuracy: 84.9400\n",
            "epoch 175/400:\n",
            "iteration: 100/500, train_loss: 0.2950, train_accuracy: 89.4700\n",
            "iteration: 200/500, train_loss: 0.2890, train_accuracy: 89.7350\n",
            "iteration: 300/500, train_loss: 0.2913, train_accuracy: 89.7567\n",
            "iteration: 400/500, train_loss: 0.2938, train_accuracy: 89.7125\n",
            "iteration: 500/500, train_loss: 0.2910, train_accuracy: 89.8120, test_loss: 0.4961, test_accuracy: 85.2000\n",
            "epoch 176/400:\n",
            "iteration: 100/500, train_loss: 0.2720, train_accuracy: 90.5700\n",
            "iteration: 200/500, train_loss: 0.2800, train_accuracy: 90.2250\n",
            "iteration: 300/500, train_loss: 0.2834, train_accuracy: 90.0633\n",
            "iteration: 400/500, train_loss: 0.2876, train_accuracy: 89.9250\n",
            "iteration: 500/500, train_loss: 0.2859, train_accuracy: 89.9880, test_loss: 0.4866, test_accuracy: 85.0500\n",
            "epoch 177/400:\n",
            "iteration: 100/500, train_loss: 0.2850, train_accuracy: 89.9400\n",
            "iteration: 200/500, train_loss: 0.2890, train_accuracy: 89.8450\n",
            "iteration: 300/500, train_loss: 0.2841, train_accuracy: 89.9967\n",
            "iteration: 400/500, train_loss: 0.2885, train_accuracy: 89.8550\n",
            "iteration: 500/500, train_loss: 0.2881, train_accuracy: 89.9380, test_loss: 0.4954, test_accuracy: 85.1300\n",
            "epoch 178/400:\n",
            "iteration: 100/500, train_loss: 0.2848, train_accuracy: 90.1700\n",
            "iteration: 200/500, train_loss: 0.2898, train_accuracy: 89.8850\n",
            "iteration: 300/500, train_loss: 0.2884, train_accuracy: 89.8833\n",
            "iteration: 400/500, train_loss: 0.2941, train_accuracy: 89.7275\n",
            "iteration: 500/500, train_loss: 0.2931, train_accuracy: 89.8000, test_loss: 0.4509, test_accuracy: 85.4000\n",
            "epoch 179/400:\n",
            "iteration: 100/500, train_loss: 0.2689, train_accuracy: 90.4600\n",
            "iteration: 200/500, train_loss: 0.2957, train_accuracy: 89.7050\n",
            "iteration: 300/500, train_loss: 0.2964, train_accuracy: 89.6767\n",
            "iteration: 400/500, train_loss: 0.3059, train_accuracy: 89.4950\n",
            "iteration: 500/500, train_loss: 0.3234, train_accuracy: 89.1880, test_loss: 0.6019, test_accuracy: 84.1800\n",
            "epoch 180/400:\n",
            "iteration: 100/500, train_loss: 0.3546, train_accuracy: 88.5900\n",
            "iteration: 200/500, train_loss: 0.3541, train_accuracy: 88.6100\n",
            "iteration: 300/500, train_loss: 0.3382, train_accuracy: 88.8200\n",
            "iteration: 400/500, train_loss: 0.3503, train_accuracy: 88.5175\n",
            "iteration: 500/500, train_loss: 0.3674, train_accuracy: 88.4260, test_loss: 0.5647, test_accuracy: 83.4000\n",
            "epoch 181/400:\n",
            "iteration: 100/500, train_loss: 0.3275, train_accuracy: 88.7400\n",
            "iteration: 200/500, train_loss: 0.3203, train_accuracy: 88.9000\n",
            "iteration: 300/500, train_loss: 0.3141, train_accuracy: 89.0100\n",
            "iteration: 400/500, train_loss: 0.3128, train_accuracy: 89.0650\n",
            "iteration: 500/500, train_loss: 0.3101, train_accuracy: 89.2260, test_loss: 0.5405, test_accuracy: 85.0500\n",
            "epoch 182/400:\n",
            "iteration: 100/500, train_loss: 0.3242, train_accuracy: 89.4100\n",
            "iteration: 200/500, train_loss: 0.3208, train_accuracy: 89.5100\n",
            "iteration: 300/500, train_loss: 0.3155, train_accuracy: 89.3733\n",
            "iteration: 400/500, train_loss: 0.3133, train_accuracy: 89.4100\n",
            "iteration: 500/500, train_loss: 0.3104, train_accuracy: 89.4800, test_loss: 0.5299, test_accuracy: 84.9800\n",
            "epoch 183/400:\n",
            "iteration: 100/500, train_loss: 0.2888, train_accuracy: 89.4700\n",
            "iteration: 200/500, train_loss: 0.2894, train_accuracy: 89.6400\n",
            "iteration: 300/500, train_loss: 0.2892, train_accuracy: 89.7667\n",
            "iteration: 400/500, train_loss: 0.2938, train_accuracy: 89.6225\n",
            "iteration: 500/500, train_loss: 0.2935, train_accuracy: 89.6760, test_loss: 0.5448, test_accuracy: 84.5900\n",
            "epoch 184/400:\n",
            "iteration: 100/500, train_loss: 0.2842, train_accuracy: 90.1500\n",
            "iteration: 200/500, train_loss: 0.2939, train_accuracy: 90.0050\n",
            "iteration: 300/500, train_loss: 0.2883, train_accuracy: 90.2100\n",
            "iteration: 400/500, train_loss: 0.2890, train_accuracy: 90.0500\n",
            "iteration: 500/500, train_loss: 0.2915, train_accuracy: 90.0040, test_loss: 0.5416, test_accuracy: 84.7000\n",
            "epoch 185/400:\n",
            "iteration: 100/500, train_loss: 0.2996, train_accuracy: 89.4700\n",
            "iteration: 200/500, train_loss: 0.3024, train_accuracy: 89.4050\n",
            "iteration: 300/500, train_loss: 0.2958, train_accuracy: 89.7333\n",
            "iteration: 400/500, train_loss: 0.3039, train_accuracy: 89.6650\n",
            "iteration: 500/500, train_loss: 0.2991, train_accuracy: 89.8040, test_loss: 0.4667, test_accuracy: 85.6500\n",
            "epoch 186/400:\n",
            "iteration: 100/500, train_loss: 0.2802, train_accuracy: 90.2700\n",
            "iteration: 200/500, train_loss: 0.2897, train_accuracy: 90.2150\n",
            "iteration: 300/500, train_loss: 0.2862, train_accuracy: 90.1333\n",
            "iteration: 400/500, train_loss: 0.2874, train_accuracy: 89.9950\n",
            "iteration: 500/500, train_loss: 0.2854, train_accuracy: 90.0520, test_loss: 0.4699, test_accuracy: 85.4100\n",
            "epoch 187/400:\n",
            "iteration: 100/500, train_loss: 0.2760, train_accuracy: 90.3400\n",
            "iteration: 200/500, train_loss: 0.2803, train_accuracy: 90.0300\n",
            "iteration: 300/500, train_loss: 0.2781, train_accuracy: 90.0833\n",
            "iteration: 400/500, train_loss: 0.2831, train_accuracy: 89.9450\n",
            "iteration: 500/500, train_loss: 0.2819, train_accuracy: 90.0320, test_loss: 0.4699, test_accuracy: 85.1700\n",
            "epoch 188/400:\n",
            "iteration: 100/500, train_loss: 0.2797, train_accuracy: 90.1600\n",
            "iteration: 200/500, train_loss: 0.2860, train_accuracy: 89.9500\n",
            "iteration: 300/500, train_loss: 0.2807, train_accuracy: 90.1200\n",
            "iteration: 400/500, train_loss: 0.2843, train_accuracy: 90.0225\n",
            "iteration: 500/500, train_loss: 0.2899, train_accuracy: 90.0100, test_loss: 0.4958, test_accuracy: 85.0300\n",
            "epoch 189/400:\n",
            "iteration: 100/500, train_loss: 0.2773, train_accuracy: 90.1900\n",
            "iteration: 200/500, train_loss: 0.2864, train_accuracy: 89.9600\n",
            "iteration: 300/500, train_loss: 0.2876, train_accuracy: 89.9500\n",
            "iteration: 400/500, train_loss: 0.3035, train_accuracy: 89.4625\n",
            "iteration: 500/500, train_loss: 0.3038, train_accuracy: 89.5180, test_loss: 0.4881, test_accuracy: 84.7400\n",
            "epoch 190/400:\n",
            "iteration: 100/500, train_loss: 0.2910, train_accuracy: 89.8400\n",
            "iteration: 200/500, train_loss: 0.2925, train_accuracy: 89.8600\n",
            "iteration: 300/500, train_loss: 0.2864, train_accuracy: 89.9767\n",
            "iteration: 400/500, train_loss: 0.2897, train_accuracy: 89.8500\n",
            "iteration: 500/500, train_loss: 0.2864, train_accuracy: 89.9500, test_loss: 0.4793, test_accuracy: 85.2100\n",
            "epoch 191/400:\n",
            "iteration: 100/500, train_loss: 0.2787, train_accuracy: 90.3200\n",
            "iteration: 200/500, train_loss: 0.2861, train_accuracy: 90.1050\n",
            "iteration: 300/500, train_loss: 0.2850, train_accuracy: 90.1800\n",
            "iteration: 400/500, train_loss: 0.2899, train_accuracy: 90.0675\n",
            "iteration: 500/500, train_loss: 0.2880, train_accuracy: 90.1300, test_loss: 0.5216, test_accuracy: 85.3900\n",
            "epoch 192/400:\n",
            "iteration: 100/500, train_loss: 0.3407, train_accuracy: 88.7900\n",
            "iteration: 200/500, train_loss: 0.3236, train_accuracy: 89.2900\n",
            "iteration: 300/500, train_loss: 0.3101, train_accuracy: 89.5267\n",
            "iteration: 400/500, train_loss: 0.3062, train_accuracy: 89.6450\n",
            "iteration: 500/500, train_loss: 0.3025, train_accuracy: 89.7600, test_loss: 0.4972, test_accuracy: 84.0800\n",
            "epoch 193/400:\n",
            "iteration: 100/500, train_loss: 0.3059, train_accuracy: 89.6600\n",
            "iteration: 200/500, train_loss: 0.2960, train_accuracy: 89.8750\n",
            "iteration: 300/500, train_loss: 0.2901, train_accuracy: 89.8767\n",
            "iteration: 400/500, train_loss: 0.2914, train_accuracy: 89.8900\n",
            "iteration: 500/500, train_loss: 0.2881, train_accuracy: 89.9680, test_loss: 0.4900, test_accuracy: 85.1900\n",
            "epoch 194/400:\n",
            "iteration: 100/500, train_loss: 0.2795, train_accuracy: 90.4000\n",
            "iteration: 200/500, train_loss: 0.2860, train_accuracy: 90.0350\n",
            "iteration: 300/500, train_loss: 0.2885, train_accuracy: 89.8500\n",
            "iteration: 400/500, train_loss: 0.2907, train_accuracy: 89.8000\n",
            "iteration: 500/500, train_loss: 0.2881, train_accuracy: 89.9500, test_loss: 0.4755, test_accuracy: 85.2500\n",
            "epoch 195/400:\n",
            "iteration: 100/500, train_loss: 0.2810, train_accuracy: 90.1500\n",
            "iteration: 200/500, train_loss: 0.2804, train_accuracy: 90.2050\n",
            "iteration: 300/500, train_loss: 0.2782, train_accuracy: 90.3133\n",
            "iteration: 400/500, train_loss: 0.2881, train_accuracy: 90.0000\n",
            "iteration: 500/500, train_loss: 0.3115, train_accuracy: 89.6560, test_loss: 0.5718, test_accuracy: 83.1800\n",
            "epoch 196/400:\n",
            "iteration: 100/500, train_loss: 0.3863, train_accuracy: 87.5200\n",
            "iteration: 200/500, train_loss: 0.3529, train_accuracy: 88.4550\n",
            "iteration: 300/500, train_loss: 0.3304, train_accuracy: 88.9667\n",
            "iteration: 400/500, train_loss: 0.3248, train_accuracy: 89.0000\n",
            "iteration: 500/500, train_loss: 0.3182, train_accuracy: 89.1580, test_loss: 0.4714, test_accuracy: 85.1200\n",
            "epoch 197/400:\n",
            "iteration: 100/500, train_loss: 0.2865, train_accuracy: 89.7000\n",
            "iteration: 200/500, train_loss: 0.2951, train_accuracy: 89.6800\n",
            "iteration: 300/500, train_loss: 0.2909, train_accuracy: 89.7867\n",
            "iteration: 400/500, train_loss: 0.2921, train_accuracy: 89.7425\n",
            "iteration: 500/500, train_loss: 0.2885, train_accuracy: 89.8360, test_loss: 0.4673, test_accuracy: 85.3300\n",
            "epoch 198/400:\n",
            "iteration: 100/500, train_loss: 0.2809, train_accuracy: 90.3200\n",
            "iteration: 200/500, train_loss: 0.2794, train_accuracy: 90.2400\n",
            "iteration: 300/500, train_loss: 0.2803, train_accuracy: 90.3033\n",
            "iteration: 400/500, train_loss: 0.2835, train_accuracy: 90.2500\n",
            "iteration: 500/500, train_loss: 0.2843, train_accuracy: 90.3120, test_loss: 0.4860, test_accuracy: 84.9700\n",
            "epoch 199/400:\n",
            "iteration: 100/500, train_loss: 0.2941, train_accuracy: 89.6500\n",
            "iteration: 200/500, train_loss: 0.2907, train_accuracy: 89.9450\n",
            "iteration: 300/500, train_loss: 0.2814, train_accuracy: 90.1433\n",
            "iteration: 400/500, train_loss: 0.2842, train_accuracy: 90.1225\n",
            "iteration: 500/500, train_loss: 0.2811, train_accuracy: 90.2280, test_loss: 0.4545, test_accuracy: 85.6900\n",
            "epoch 200/400:\n",
            "iteration: 100/500, train_loss: 0.2665, train_accuracy: 90.5600\n",
            "iteration: 200/500, train_loss: 0.2729, train_accuracy: 90.3400\n",
            "iteration: 300/500, train_loss: 0.2732, train_accuracy: 90.2900\n",
            "iteration: 400/500, train_loss: 0.2785, train_accuracy: 90.0975\n",
            "iteration: 500/500, train_loss: 0.2761, train_accuracy: 90.1580, test_loss: 0.4829, test_accuracy: 85.1700\n",
            "epoch 201/400:\n",
            "iteration: 100/500, train_loss: 0.2657, train_accuracy: 90.8600\n",
            "iteration: 200/500, train_loss: 0.2683, train_accuracy: 90.6450\n",
            "iteration: 300/500, train_loss: 0.2673, train_accuracy: 90.5667\n",
            "iteration: 400/500, train_loss: 0.2741, train_accuracy: 90.3700\n",
            "iteration: 500/500, train_loss: 0.2737, train_accuracy: 90.4040, test_loss: 0.4595, test_accuracy: 85.6100\n",
            "epoch 202/400:\n",
            "iteration: 100/500, train_loss: 0.2666, train_accuracy: 90.6500\n",
            "iteration: 200/500, train_loss: 0.2748, train_accuracy: 90.4950\n",
            "iteration: 300/500, train_loss: 0.2765, train_accuracy: 90.3467\n",
            "iteration: 400/500, train_loss: 0.2770, train_accuracy: 90.2700\n",
            "iteration: 500/500, train_loss: 0.2746, train_accuracy: 90.3580, test_loss: 0.4997, test_accuracy: 85.2300\n",
            "epoch 203/400:\n",
            "iteration: 100/500, train_loss: 0.2688, train_accuracy: 90.8700\n",
            "iteration: 200/500, train_loss: 0.2768, train_accuracy: 90.5000\n",
            "iteration: 300/500, train_loss: 0.2763, train_accuracy: 90.3933\n",
            "iteration: 400/500, train_loss: 0.2818, train_accuracy: 90.1100\n",
            "iteration: 500/500, train_loss: 0.2850, train_accuracy: 89.9820, test_loss: 0.4669, test_accuracy: 84.8700\n",
            "epoch 204/400:\n",
            "iteration: 100/500, train_loss: 0.2676, train_accuracy: 90.8600\n",
            "iteration: 200/500, train_loss: 0.2879, train_accuracy: 90.2450\n",
            "iteration: 300/500, train_loss: 0.2928, train_accuracy: 90.2700\n",
            "iteration: 400/500, train_loss: 0.2927, train_accuracy: 90.1550\n",
            "iteration: 500/500, train_loss: 0.2915, train_accuracy: 90.1720, test_loss: 0.4930, test_accuracy: 85.3800\n",
            "epoch 205/400:\n",
            "iteration: 100/500, train_loss: 0.2766, train_accuracy: 90.3000\n",
            "iteration: 200/500, train_loss: 0.2814, train_accuracy: 90.1450\n",
            "iteration: 300/500, train_loss: 0.2847, train_accuracy: 90.1333\n",
            "iteration: 400/500, train_loss: 0.2853, train_accuracy: 90.1600\n",
            "iteration: 500/500, train_loss: 0.2841, train_accuracy: 90.1500, test_loss: 0.4638, test_accuracy: 85.3000\n",
            "epoch 206/400:\n",
            "iteration: 100/500, train_loss: 0.2699, train_accuracy: 90.3300\n",
            "iteration: 200/500, train_loss: 0.2747, train_accuracy: 90.2100\n",
            "iteration: 300/500, train_loss: 0.2732, train_accuracy: 90.2800\n",
            "iteration: 400/500, train_loss: 0.2938, train_accuracy: 89.9125\n",
            "iteration: 500/500, train_loss: 0.2969, train_accuracy: 89.8080, test_loss: 0.4977, test_accuracy: 84.9600\n",
            "epoch 207/400:\n",
            "iteration: 100/500, train_loss: 0.3058, train_accuracy: 89.6400\n",
            "iteration: 200/500, train_loss: 0.3340, train_accuracy: 88.9300\n",
            "iteration: 300/500, train_loss: 0.3225, train_accuracy: 89.1200\n",
            "iteration: 400/500, train_loss: 0.3197, train_accuracy: 89.2200\n",
            "iteration: 500/500, train_loss: 0.3116, train_accuracy: 89.4020, test_loss: 0.5015, test_accuracy: 85.5800\n",
            "epoch 208/400:\n",
            "iteration: 100/500, train_loss: 0.2849, train_accuracy: 89.9300\n",
            "iteration: 200/500, train_loss: 0.2807, train_accuracy: 90.0950\n",
            "iteration: 300/500, train_loss: 0.2786, train_accuracy: 90.1100\n",
            "iteration: 400/500, train_loss: 0.2815, train_accuracy: 90.0625\n",
            "iteration: 500/500, train_loss: 0.2782, train_accuracy: 90.2080, test_loss: 0.4689, test_accuracy: 85.4100\n",
            "epoch 209/400:\n",
            "iteration: 100/500, train_loss: 0.2802, train_accuracy: 90.1100\n",
            "iteration: 200/500, train_loss: 0.2811, train_accuracy: 90.1200\n",
            "iteration: 300/500, train_loss: 0.2736, train_accuracy: 90.3067\n",
            "iteration: 400/500, train_loss: 0.2772, train_accuracy: 90.1700\n",
            "iteration: 500/500, train_loss: 0.2764, train_accuracy: 90.2480, test_loss: 0.4823, test_accuracy: 85.5300\n",
            "epoch 210/400:\n",
            "iteration: 100/500, train_loss: 0.2698, train_accuracy: 90.4200\n",
            "iteration: 200/500, train_loss: 0.2734, train_accuracy: 90.3450\n",
            "iteration: 300/500, train_loss: 0.2753, train_accuracy: 90.3500\n",
            "iteration: 400/500, train_loss: 0.2766, train_accuracy: 90.2725\n",
            "iteration: 500/500, train_loss: 0.2772, train_accuracy: 90.2760, test_loss: 0.4779, test_accuracy: 85.8300\n",
            "epoch 211/400:\n",
            "iteration: 100/500, train_loss: 0.2677, train_accuracy: 90.4900\n",
            "iteration: 200/500, train_loss: 0.2725, train_accuracy: 90.4250\n",
            "iteration: 300/500, train_loss: 0.2725, train_accuracy: 90.3000\n",
            "iteration: 400/500, train_loss: 0.2837, train_accuracy: 89.9850\n",
            "iteration: 500/500, train_loss: 0.2841, train_accuracy: 89.9980, test_loss: 0.4856, test_accuracy: 85.5300\n",
            "epoch 212/400:\n",
            "iteration: 100/500, train_loss: 0.2671, train_accuracy: 90.6400\n",
            "iteration: 200/500, train_loss: 0.2790, train_accuracy: 90.2900\n",
            "iteration: 300/500, train_loss: 0.2727, train_accuracy: 90.4667\n",
            "iteration: 400/500, train_loss: 0.2757, train_accuracy: 90.3300\n",
            "iteration: 500/500, train_loss: 0.2731, train_accuracy: 90.4460, test_loss: 0.4902, test_accuracy: 85.6500\n",
            "epoch 213/400:\n",
            "iteration: 100/500, train_loss: 0.2691, train_accuracy: 90.2500\n",
            "iteration: 200/500, train_loss: 0.2700, train_accuracy: 90.4100\n",
            "iteration: 300/500, train_loss: 0.2748, train_accuracy: 90.4433\n",
            "iteration: 400/500, train_loss: 0.2989, train_accuracy: 89.9025\n",
            "iteration: 500/500, train_loss: 0.2977, train_accuracy: 89.8940, test_loss: 0.4857, test_accuracy: 84.9700\n",
            "epoch 214/400:\n",
            "iteration: 100/500, train_loss: 0.2884, train_accuracy: 89.8200\n",
            "iteration: 200/500, train_loss: 0.2964, train_accuracy: 89.8000\n",
            "iteration: 300/500, train_loss: 0.2881, train_accuracy: 89.9233\n",
            "iteration: 400/500, train_loss: 0.2887, train_accuracy: 89.8150\n",
            "iteration: 500/500, train_loss: 0.2885, train_accuracy: 89.9360, test_loss: 0.4821, test_accuracy: 85.0300\n",
            "epoch 215/400:\n",
            "iteration: 100/500, train_loss: 0.3185, train_accuracy: 89.1900\n",
            "iteration: 200/500, train_loss: 0.3097, train_accuracy: 89.3800\n",
            "iteration: 300/500, train_loss: 0.3029, train_accuracy: 89.6133\n",
            "iteration: 400/500, train_loss: 0.2984, train_accuracy: 89.6550\n",
            "iteration: 500/500, train_loss: 0.2943, train_accuracy: 89.7580, test_loss: 0.4562, test_accuracy: 85.6700\n",
            "epoch 216/400:\n",
            "iteration: 100/500, train_loss: 0.2739, train_accuracy: 90.6500\n",
            "iteration: 200/500, train_loss: 0.2868, train_accuracy: 90.1400\n",
            "iteration: 300/500, train_loss: 0.2850, train_accuracy: 90.0800\n",
            "iteration: 400/500, train_loss: 0.2900, train_accuracy: 89.9250\n",
            "iteration: 500/500, train_loss: 0.2879, train_accuracy: 90.0260, test_loss: 0.5130, test_accuracy: 85.1800\n",
            "epoch 217/400:\n",
            "iteration: 100/500, train_loss: 0.2610, train_accuracy: 91.0000\n",
            "iteration: 200/500, train_loss: 0.2673, train_accuracy: 90.7100\n",
            "iteration: 300/500, train_loss: 0.2684, train_accuracy: 90.6467\n",
            "iteration: 400/500, train_loss: 0.2720, train_accuracy: 90.5000\n",
            "iteration: 500/500, train_loss: 0.2712, train_accuracy: 90.5440, test_loss: 0.4521, test_accuracy: 85.7900\n",
            "epoch 218/400:\n",
            "iteration: 100/500, train_loss: 0.2567, train_accuracy: 91.0500\n",
            "iteration: 200/500, train_loss: 0.2646, train_accuracy: 90.7600\n",
            "iteration: 300/500, train_loss: 0.2628, train_accuracy: 90.7800\n",
            "iteration: 400/500, train_loss: 0.2692, train_accuracy: 90.6150\n",
            "iteration: 500/500, train_loss: 0.2699, train_accuracy: 90.6200, test_loss: 0.5029, test_accuracy: 85.1500\n",
            "epoch 219/400:\n",
            "iteration: 100/500, train_loss: 0.2660, train_accuracy: 90.7500\n",
            "iteration: 200/500, train_loss: 0.2869, train_accuracy: 90.3650\n",
            "iteration: 300/500, train_loss: 0.2947, train_accuracy: 90.0300\n",
            "iteration: 400/500, train_loss: 0.2968, train_accuracy: 89.9025\n",
            "iteration: 500/500, train_loss: 0.3050, train_accuracy: 89.6260, test_loss: 0.5039, test_accuracy: 84.8500\n",
            "epoch 220/400:\n",
            "iteration: 100/500, train_loss: 0.2879, train_accuracy: 90.1400\n",
            "iteration: 200/500, train_loss: 0.2833, train_accuracy: 90.0900\n",
            "iteration: 300/500, train_loss: 0.2814, train_accuracy: 90.1833\n",
            "iteration: 400/500, train_loss: 0.2918, train_accuracy: 89.9900\n",
            "iteration: 500/500, train_loss: 0.2895, train_accuracy: 90.0040, test_loss: 0.5041, test_accuracy: 85.6200\n",
            "epoch 221/400:\n",
            "iteration: 100/500, train_loss: 0.2657, train_accuracy: 90.9500\n",
            "iteration: 200/500, train_loss: 0.2705, train_accuracy: 90.7250\n",
            "iteration: 300/500, train_loss: 0.2716, train_accuracy: 90.4567\n",
            "iteration: 400/500, train_loss: 0.2733, train_accuracy: 90.4400\n",
            "iteration: 500/500, train_loss: 0.2718, train_accuracy: 90.4960, test_loss: 0.4799, test_accuracy: 85.5600\n",
            "epoch 222/400:\n",
            "iteration: 100/500, train_loss: 0.2879, train_accuracy: 90.2000\n",
            "iteration: 200/500, train_loss: 0.2975, train_accuracy: 89.8850\n",
            "iteration: 300/500, train_loss: 0.2890, train_accuracy: 89.9800\n",
            "iteration: 400/500, train_loss: 0.2895, train_accuracy: 89.8900\n",
            "iteration: 500/500, train_loss: 0.2856, train_accuracy: 89.9700, test_loss: 0.4619, test_accuracy: 85.6700\n",
            "epoch 223/400:\n",
            "iteration: 100/500, train_loss: 0.2689, train_accuracy: 90.3100\n",
            "iteration: 200/500, train_loss: 0.2699, train_accuracy: 90.5300\n",
            "iteration: 300/500, train_loss: 0.2737, train_accuracy: 90.2533\n",
            "iteration: 400/500, train_loss: 0.2751, train_accuracy: 90.2200\n",
            "iteration: 500/500, train_loss: 0.2734, train_accuracy: 90.2680, test_loss: 0.4497, test_accuracy: 85.9100\n",
            "epoch 224/400:\n",
            "iteration: 100/500, train_loss: 0.2575, train_accuracy: 90.7800\n",
            "iteration: 200/500, train_loss: 0.2662, train_accuracy: 90.5950\n",
            "iteration: 300/500, train_loss: 0.2636, train_accuracy: 90.6733\n",
            "iteration: 400/500, train_loss: 0.2688, train_accuracy: 90.5175\n",
            "iteration: 500/500, train_loss: 0.2685, train_accuracy: 90.4940, test_loss: 0.4494, test_accuracy: 85.7900\n",
            "epoch 225/400:\n",
            "iteration: 100/500, train_loss: 0.2690, train_accuracy: 90.4800\n",
            "iteration: 200/500, train_loss: 0.2728, train_accuracy: 90.3500\n",
            "iteration: 300/500, train_loss: 0.2686, train_accuracy: 90.5433\n",
            "iteration: 400/500, train_loss: 0.2697, train_accuracy: 90.5450\n",
            "iteration: 500/500, train_loss: 0.2682, train_accuracy: 90.5460, test_loss: 0.4579, test_accuracy: 85.4200\n",
            "epoch 226/400:\n",
            "iteration: 100/500, train_loss: 0.2882, train_accuracy: 90.0700\n",
            "iteration: 200/500, train_loss: 0.3212, train_accuracy: 89.6900\n",
            "iteration: 300/500, train_loss: 0.3232, train_accuracy: 89.3267\n",
            "iteration: 400/500, train_loss: 0.3173, train_accuracy: 89.4475\n",
            "iteration: 500/500, train_loss: 0.3100, train_accuracy: 89.5140, test_loss: 0.5047, test_accuracy: 84.9500\n",
            "epoch 227/400:\n",
            "iteration: 100/500, train_loss: 0.2692, train_accuracy: 90.5900\n",
            "iteration: 200/500, train_loss: 0.2729, train_accuracy: 90.5750\n",
            "iteration: 300/500, train_loss: 0.2789, train_accuracy: 90.4867\n",
            "iteration: 400/500, train_loss: 0.2767, train_accuracy: 90.4625\n",
            "iteration: 500/500, train_loss: 0.2747, train_accuracy: 90.4880, test_loss: 0.4620, test_accuracy: 85.6000\n",
            "epoch 228/400:\n",
            "iteration: 100/500, train_loss: 0.2731, train_accuracy: 90.7100\n",
            "iteration: 200/500, train_loss: 0.2832, train_accuracy: 90.1650\n",
            "iteration: 300/500, train_loss: 0.2776, train_accuracy: 90.3367\n",
            "iteration: 400/500, train_loss: 0.2793, train_accuracy: 90.2375\n",
            "iteration: 500/500, train_loss: 0.2749, train_accuracy: 90.4500, test_loss: 0.5044, test_accuracy: 85.4800\n",
            "epoch 229/400:\n",
            "iteration: 100/500, train_loss: 0.2724, train_accuracy: 90.4700\n",
            "iteration: 200/500, train_loss: 0.2776, train_accuracy: 90.2700\n",
            "iteration: 300/500, train_loss: 0.2912, train_accuracy: 90.1600\n",
            "iteration: 400/500, train_loss: 0.2936, train_accuracy: 89.9575\n",
            "iteration: 500/500, train_loss: 0.2877, train_accuracy: 90.0900, test_loss: 0.4957, test_accuracy: 85.7200\n",
            "epoch 230/400:\n",
            "iteration: 100/500, train_loss: 0.3186, train_accuracy: 89.6400\n",
            "iteration: 200/500, train_loss: 0.3683, train_accuracy: 87.9900\n",
            "iteration: 300/500, train_loss: 0.3546, train_accuracy: 88.1367\n",
            "iteration: 400/500, train_loss: 0.3565, train_accuracy: 88.1300\n",
            "iteration: 500/500, train_loss: 0.3453, train_accuracy: 88.3660, test_loss: 0.5238, test_accuracy: 85.0700\n",
            "epoch 231/400:\n",
            "iteration: 100/500, train_loss: 0.2741, train_accuracy: 90.1800\n",
            "iteration: 200/500, train_loss: 0.2867, train_accuracy: 89.9450\n",
            "iteration: 300/500, train_loss: 0.2945, train_accuracy: 89.7667\n",
            "iteration: 400/500, train_loss: 0.3109, train_accuracy: 89.4950\n",
            "iteration: 500/500, train_loss: 0.3112, train_accuracy: 89.4220, test_loss: 0.5762, test_accuracy: 84.6600\n",
            "epoch 232/400:\n",
            "iteration: 100/500, train_loss: 0.2862, train_accuracy: 90.2900\n",
            "iteration: 200/500, train_loss: 0.2900, train_accuracy: 90.1550\n",
            "iteration: 300/500, train_loss: 0.2876, train_accuracy: 90.0967\n",
            "iteration: 400/500, train_loss: 0.2883, train_accuracy: 90.0400\n",
            "iteration: 500/500, train_loss: 0.2852, train_accuracy: 90.2120, test_loss: 0.5208, test_accuracy: 85.6200\n",
            "epoch 233/400:\n",
            "iteration: 100/500, train_loss: 0.2590, train_accuracy: 90.9300\n",
            "iteration: 200/500, train_loss: 0.2775, train_accuracy: 90.4900\n",
            "iteration: 300/500, train_loss: 0.2775, train_accuracy: 90.3900\n",
            "iteration: 400/500, train_loss: 0.2786, train_accuracy: 90.3250\n",
            "iteration: 500/500, train_loss: 0.2764, train_accuracy: 90.3960, test_loss: 0.5352, test_accuracy: 85.5100\n",
            "epoch 234/400:\n",
            "iteration: 100/500, train_loss: 0.2652, train_accuracy: 90.6500\n",
            "iteration: 200/500, train_loss: 0.2840, train_accuracy: 90.3250\n",
            "iteration: 300/500, train_loss: 0.2845, train_accuracy: 90.1500\n",
            "iteration: 400/500, train_loss: 0.2910, train_accuracy: 90.0050\n",
            "iteration: 500/500, train_loss: 0.2863, train_accuracy: 90.1180, test_loss: 0.4983, test_accuracy: 85.2500\n",
            "epoch 235/400:\n",
            "iteration: 100/500, train_loss: 0.2682, train_accuracy: 90.7100\n",
            "iteration: 200/500, train_loss: 0.2685, train_accuracy: 90.6200\n",
            "iteration: 300/500, train_loss: 0.2701, train_accuracy: 90.5567\n",
            "iteration: 400/500, train_loss: 0.2741, train_accuracy: 90.4525\n",
            "iteration: 500/500, train_loss: 0.2706, train_accuracy: 90.6280, test_loss: 0.5558, test_accuracy: 85.0600\n",
            "epoch 236/400:\n",
            "iteration: 100/500, train_loss: 0.2518, train_accuracy: 91.1500\n",
            "iteration: 200/500, train_loss: 0.2643, train_accuracy: 90.9150\n",
            "iteration: 300/500, train_loss: 0.2745, train_accuracy: 90.5833\n",
            "iteration: 400/500, train_loss: 0.2783, train_accuracy: 90.3925\n",
            "iteration: 500/500, train_loss: 0.2759, train_accuracy: 90.4200, test_loss: 0.4875, test_accuracy: 85.8300\n",
            "epoch 237/400:\n",
            "iteration: 100/500, train_loss: 0.2587, train_accuracy: 91.0600\n",
            "iteration: 200/500, train_loss: 0.2616, train_accuracy: 90.8450\n",
            "iteration: 300/500, train_loss: 0.2624, train_accuracy: 90.7733\n",
            "iteration: 400/500, train_loss: 0.2651, train_accuracy: 90.6550\n",
            "iteration: 500/500, train_loss: 0.2644, train_accuracy: 90.7040, test_loss: 0.5243, test_accuracy: 85.4500\n",
            "epoch 238/400:\n",
            "iteration: 100/500, train_loss: 0.2614, train_accuracy: 90.4500\n",
            "iteration: 200/500, train_loss: 0.2641, train_accuracy: 90.6400\n",
            "iteration: 300/500, train_loss: 0.2651, train_accuracy: 90.6233\n",
            "iteration: 400/500, train_loss: 0.2651, train_accuracy: 90.6900\n",
            "iteration: 500/500, train_loss: 0.2651, train_accuracy: 90.6980, test_loss: 0.5138, test_accuracy: 84.9700\n",
            "epoch 239/400:\n",
            "iteration: 100/500, train_loss: 0.2653, train_accuracy: 90.8300\n",
            "iteration: 200/500, train_loss: 0.2655, train_accuracy: 90.7200\n",
            "iteration: 300/500, train_loss: 0.2641, train_accuracy: 90.7000\n",
            "iteration: 400/500, train_loss: 0.2708, train_accuracy: 90.5450\n",
            "iteration: 500/500, train_loss: 0.2753, train_accuracy: 90.4460, test_loss: 0.6472, test_accuracy: 84.1200\n",
            "epoch 240/400:\n",
            "iteration: 100/500, train_loss: 0.2632, train_accuracy: 91.0600\n",
            "iteration: 200/500, train_loss: 0.2719, train_accuracy: 90.5050\n",
            "iteration: 300/500, train_loss: 0.2685, train_accuracy: 90.5233\n",
            "iteration: 400/500, train_loss: 0.2691, train_accuracy: 90.5050\n",
            "iteration: 500/500, train_loss: 0.2670, train_accuracy: 90.5220, test_loss: 0.5442, test_accuracy: 85.3600\n",
            "epoch 241/400:\n",
            "iteration: 100/500, train_loss: 0.2872, train_accuracy: 90.4900\n",
            "iteration: 200/500, train_loss: 0.3052, train_accuracy: 90.2800\n",
            "iteration: 300/500, train_loss: 0.2962, train_accuracy: 90.3267\n",
            "iteration: 400/500, train_loss: 0.3188, train_accuracy: 89.7075\n",
            "iteration: 500/500, train_loss: 0.3161, train_accuracy: 89.6660, test_loss: 0.5116, test_accuracy: 84.9300\n",
            "epoch 242/400:\n",
            "iteration: 100/500, train_loss: 0.2725, train_accuracy: 90.2900\n",
            "iteration: 200/500, train_loss: 0.2744, train_accuracy: 90.3300\n",
            "iteration: 300/500, train_loss: 0.2722, train_accuracy: 90.4400\n",
            "iteration: 400/500, train_loss: 0.2755, train_accuracy: 90.3325\n",
            "iteration: 500/500, train_loss: 0.2725, train_accuracy: 90.3980, test_loss: 0.5260, test_accuracy: 85.4400\n",
            "epoch 243/400:\n",
            "iteration: 100/500, train_loss: 0.2623, train_accuracy: 90.5500\n",
            "iteration: 200/500, train_loss: 0.2656, train_accuracy: 90.5050\n",
            "iteration: 300/500, train_loss: 0.2602, train_accuracy: 90.7367\n",
            "iteration: 400/500, train_loss: 0.2641, train_accuracy: 90.6225\n",
            "iteration: 500/500, train_loss: 0.2627, train_accuracy: 90.6800, test_loss: 0.4875, test_accuracy: 85.7500\n",
            "epoch 244/400:\n",
            "iteration: 100/500, train_loss: 0.2690, train_accuracy: 90.5800\n",
            "iteration: 200/500, train_loss: 0.2685, train_accuracy: 90.6500\n",
            "iteration: 300/500, train_loss: 0.2658, train_accuracy: 90.6800\n",
            "iteration: 400/500, train_loss: 0.2784, train_accuracy: 90.4275\n",
            "iteration: 500/500, train_loss: 0.2797, train_accuracy: 90.3200, test_loss: 0.4609, test_accuracy: 85.1800\n",
            "epoch 245/400:\n",
            "iteration: 100/500, train_loss: 0.2679, train_accuracy: 90.4800\n",
            "iteration: 200/500, train_loss: 0.2741, train_accuracy: 90.4300\n",
            "iteration: 300/500, train_loss: 0.2702, train_accuracy: 90.4367\n",
            "iteration: 400/500, train_loss: 0.2707, train_accuracy: 90.4375\n",
            "iteration: 500/500, train_loss: 0.2673, train_accuracy: 90.6020, test_loss: 0.4929, test_accuracy: 85.5200\n",
            "epoch 246/400:\n",
            "iteration: 100/500, train_loss: 0.2752, train_accuracy: 90.7800\n",
            "iteration: 200/500, train_loss: 0.2915, train_accuracy: 90.2500\n",
            "iteration: 300/500, train_loss: 0.2839, train_accuracy: 90.3333\n",
            "iteration: 400/500, train_loss: 0.2840, train_accuracy: 90.1250\n",
            "iteration: 500/500, train_loss: 0.2818, train_accuracy: 90.2040, test_loss: 0.4743, test_accuracy: 85.3200\n",
            "epoch 247/400:\n",
            "iteration: 100/500, train_loss: 0.2622, train_accuracy: 90.6600\n",
            "iteration: 200/500, train_loss: 0.2682, train_accuracy: 90.5500\n",
            "iteration: 300/500, train_loss: 0.2630, train_accuracy: 90.7667\n",
            "iteration: 400/500, train_loss: 0.2642, train_accuracy: 90.7375\n",
            "iteration: 500/500, train_loss: 0.2626, train_accuracy: 90.8080, test_loss: 0.4415, test_accuracy: 85.8900\n",
            "epoch 248/400:\n",
            "iteration: 100/500, train_loss: 0.2520, train_accuracy: 91.0400\n",
            "iteration: 200/500, train_loss: 0.2535, train_accuracy: 91.1750\n",
            "iteration: 300/500, train_loss: 0.2552, train_accuracy: 91.1067\n",
            "iteration: 400/500, train_loss: 0.2616, train_accuracy: 90.8800\n",
            "iteration: 500/500, train_loss: 0.2620, train_accuracy: 90.8860, test_loss: 0.4743, test_accuracy: 85.7400\n",
            "epoch 249/400:\n",
            "iteration: 100/500, train_loss: 0.2596, train_accuracy: 91.1400\n",
            "iteration: 200/500, train_loss: 0.2632, train_accuracy: 90.7900\n",
            "iteration: 300/500, train_loss: 0.2640, train_accuracy: 90.7067\n",
            "iteration: 400/500, train_loss: 0.2683, train_accuracy: 90.5150\n",
            "iteration: 500/500, train_loss: 0.2688, train_accuracy: 90.5040, test_loss: 0.5537, test_accuracy: 84.1500\n",
            "epoch 250/400:\n",
            "iteration: 100/500, train_loss: 0.2809, train_accuracy: 89.7900\n",
            "iteration: 200/500, train_loss: 0.2803, train_accuracy: 90.0050\n",
            "iteration: 300/500, train_loss: 0.2756, train_accuracy: 90.1700\n",
            "iteration: 400/500, train_loss: 0.2717, train_accuracy: 90.3625\n",
            "iteration: 500/500, train_loss: 0.2678, train_accuracy: 90.4760, test_loss: 0.4750, test_accuracy: 85.8400\n",
            "epoch 251/400:\n",
            "iteration: 100/500, train_loss: 0.2653, train_accuracy: 90.6700\n",
            "iteration: 200/500, train_loss: 0.2630, train_accuracy: 90.8650\n",
            "iteration: 300/500, train_loss: 0.2651, train_accuracy: 90.6500\n",
            "iteration: 400/500, train_loss: 0.2644, train_accuracy: 90.6650\n",
            "iteration: 500/500, train_loss: 0.2640, train_accuracy: 90.6800, test_loss: 0.5275, test_accuracy: 85.6200\n",
            "epoch 252/400:\n",
            "iteration: 100/500, train_loss: 0.2495, train_accuracy: 91.1400\n",
            "iteration: 200/500, train_loss: 0.2586, train_accuracy: 90.7300\n",
            "iteration: 300/500, train_loss: 0.2583, train_accuracy: 90.8067\n",
            "iteration: 400/500, train_loss: 0.2630, train_accuracy: 90.6550\n",
            "iteration: 500/500, train_loss: 0.2621, train_accuracy: 90.7260, test_loss: 0.4839, test_accuracy: 85.5400\n",
            "epoch 253/400:\n",
            "iteration: 100/500, train_loss: 0.2487, train_accuracy: 91.2400\n",
            "iteration: 200/500, train_loss: 0.2572, train_accuracy: 90.8800\n",
            "iteration: 300/500, train_loss: 0.2915, train_accuracy: 90.1000\n",
            "iteration: 400/500, train_loss: 0.3089, train_accuracy: 89.6300\n",
            "iteration: 500/500, train_loss: 0.3122, train_accuracy: 89.5100, test_loss: 0.5426, test_accuracy: 85.2400\n",
            "epoch 254/400:\n",
            "iteration: 100/500, train_loss: 0.2802, train_accuracy: 90.0300\n",
            "iteration: 200/500, train_loss: 0.2860, train_accuracy: 90.2000\n",
            "iteration: 300/500, train_loss: 0.2823, train_accuracy: 90.2967\n",
            "iteration: 400/500, train_loss: 0.2816, train_accuracy: 90.3300\n",
            "iteration: 500/500, train_loss: 0.2801, train_accuracy: 90.3500, test_loss: 0.4823, test_accuracy: 85.5200\n",
            "epoch 255/400:\n",
            "iteration: 100/500, train_loss: 0.2640, train_accuracy: 90.4400\n",
            "iteration: 200/500, train_loss: 0.2758, train_accuracy: 90.4700\n",
            "iteration: 300/500, train_loss: 0.2820, train_accuracy: 90.1533\n",
            "iteration: 400/500, train_loss: 0.2874, train_accuracy: 90.0950\n",
            "iteration: 500/500, train_loss: 0.2817, train_accuracy: 90.1820, test_loss: 0.4828, test_accuracy: 85.4400\n",
            "epoch 256/400:\n",
            "iteration: 100/500, train_loss: 0.2526, train_accuracy: 91.0300\n",
            "iteration: 200/500, train_loss: 0.2587, train_accuracy: 90.8800\n",
            "iteration: 300/500, train_loss: 0.2580, train_accuracy: 90.8900\n",
            "iteration: 400/500, train_loss: 0.2617, train_accuracy: 90.6825\n",
            "iteration: 500/500, train_loss: 0.2647, train_accuracy: 90.7080, test_loss: 0.4738, test_accuracy: 85.4600\n",
            "epoch 257/400:\n",
            "iteration: 100/500, train_loss: 0.2722, train_accuracy: 90.6200\n",
            "iteration: 200/500, train_loss: 0.2684, train_accuracy: 90.7450\n",
            "iteration: 300/500, train_loss: 0.2636, train_accuracy: 90.8800\n",
            "iteration: 400/500, train_loss: 0.2630, train_accuracy: 90.8725\n",
            "iteration: 500/500, train_loss: 0.2630, train_accuracy: 90.8980, test_loss: 0.4600, test_accuracy: 85.5200\n",
            "epoch 258/400:\n",
            "iteration: 100/500, train_loss: 0.2566, train_accuracy: 91.1200\n",
            "iteration: 200/500, train_loss: 0.2580, train_accuracy: 91.0350\n",
            "iteration: 300/500, train_loss: 0.2583, train_accuracy: 91.0433\n",
            "iteration: 400/500, train_loss: 0.2617, train_accuracy: 90.9025\n",
            "iteration: 500/500, train_loss: 0.2618, train_accuracy: 90.8980, test_loss: 0.4822, test_accuracy: 85.6800\n",
            "epoch 259/400:\n",
            "iteration: 100/500, train_loss: 0.2513, train_accuracy: 91.2300\n",
            "iteration: 200/500, train_loss: 0.2580, train_accuracy: 91.0200\n",
            "iteration: 300/500, train_loss: 0.2559, train_accuracy: 90.9867\n",
            "iteration: 400/500, train_loss: 0.2595, train_accuracy: 90.9075\n",
            "iteration: 500/500, train_loss: 0.2578, train_accuracy: 90.9440, test_loss: 0.4628, test_accuracy: 86.0300\n",
            "epoch 260/400:\n",
            "iteration: 100/500, train_loss: 0.2681, train_accuracy: 90.7900\n",
            "iteration: 200/500, train_loss: 0.2646, train_accuracy: 90.8500\n",
            "iteration: 300/500, train_loss: 0.2614, train_accuracy: 90.8933\n",
            "iteration: 400/500, train_loss: 0.2666, train_accuracy: 90.8875\n",
            "iteration: 500/500, train_loss: 0.2771, train_accuracy: 90.5880, test_loss: 0.5210, test_accuracy: 84.7500\n",
            "epoch 261/400:\n",
            "iteration: 100/500, train_loss: 0.2743, train_accuracy: 90.4400\n",
            "iteration: 200/500, train_loss: 0.2717, train_accuracy: 90.4850\n",
            "iteration: 300/500, train_loss: 0.2662, train_accuracy: 90.6800\n",
            "iteration: 400/500, train_loss: 0.2671, train_accuracy: 90.6125\n",
            "iteration: 500/500, train_loss: 0.2686, train_accuracy: 90.6420, test_loss: 0.5620, test_accuracy: 85.3800\n",
            "epoch 262/400:\n",
            "iteration: 100/500, train_loss: 0.2566, train_accuracy: 90.7400\n",
            "iteration: 200/500, train_loss: 0.2654, train_accuracy: 90.8350\n",
            "iteration: 300/500, train_loss: 0.2693, train_accuracy: 90.6333\n",
            "iteration: 400/500, train_loss: 0.2701, train_accuracy: 90.5250\n",
            "iteration: 500/500, train_loss: 0.2674, train_accuracy: 90.6300, test_loss: 0.5256, test_accuracy: 85.7500\n",
            "epoch 263/400:\n",
            "iteration: 100/500, train_loss: 0.2551, train_accuracy: 91.0600\n",
            "iteration: 200/500, train_loss: 0.2567, train_accuracy: 91.0150\n",
            "iteration: 300/500, train_loss: 0.2518, train_accuracy: 91.1400\n",
            "iteration: 400/500, train_loss: 0.2562, train_accuracy: 90.9125\n",
            "iteration: 500/500, train_loss: 0.2549, train_accuracy: 90.9780, test_loss: 0.5380, test_accuracy: 85.5300\n",
            "epoch 264/400:\n",
            "iteration: 100/500, train_loss: 0.2472, train_accuracy: 91.2900\n",
            "iteration: 200/500, train_loss: 0.2505, train_accuracy: 91.2800\n",
            "iteration: 300/500, train_loss: 0.2488, train_accuracy: 91.2533\n",
            "iteration: 400/500, train_loss: 0.2559, train_accuracy: 91.0050\n",
            "iteration: 500/500, train_loss: 0.2552, train_accuracy: 91.0380, test_loss: 0.4858, test_accuracy: 85.3700\n",
            "epoch 265/400:\n",
            "iteration: 100/500, train_loss: 0.2553, train_accuracy: 91.1600\n",
            "iteration: 200/500, train_loss: 0.2584, train_accuracy: 91.0900\n",
            "iteration: 300/500, train_loss: 0.2534, train_accuracy: 91.2267\n",
            "iteration: 400/500, train_loss: 0.2915, train_accuracy: 90.1925\n",
            "iteration: 500/500, train_loss: 0.2991, train_accuracy: 89.9280, test_loss: 0.5243, test_accuracy: 84.5800\n",
            "epoch 266/400:\n",
            "iteration: 100/500, train_loss: 0.2805, train_accuracy: 90.0800\n",
            "iteration: 200/500, train_loss: 0.2793, train_accuracy: 90.2000\n",
            "iteration: 300/500, train_loss: 0.2754, train_accuracy: 90.4200\n",
            "iteration: 400/500, train_loss: 0.3085, train_accuracy: 89.8050\n",
            "iteration: 500/500, train_loss: 0.3150, train_accuracy: 89.7240, test_loss: 0.5071, test_accuracy: 84.9000\n",
            "epoch 267/400:\n",
            "iteration: 100/500, train_loss: 0.2918, train_accuracy: 90.0000\n",
            "iteration: 200/500, train_loss: 0.3148, train_accuracy: 89.6300\n",
            "iteration: 300/500, train_loss: 0.3072, train_accuracy: 89.7167\n",
            "iteration: 400/500, train_loss: 0.3036, train_accuracy: 89.7725\n",
            "iteration: 500/500, train_loss: 0.3016, train_accuracy: 89.8840, test_loss: 0.5074, test_accuracy: 84.7700\n",
            "epoch 268/400:\n",
            "iteration: 100/500, train_loss: 0.2775, train_accuracy: 90.4500\n",
            "iteration: 200/500, train_loss: 0.2789, train_accuracy: 90.3400\n",
            "iteration: 300/500, train_loss: 0.2767, train_accuracy: 90.4200\n",
            "iteration: 400/500, train_loss: 0.2760, train_accuracy: 90.4875\n",
            "iteration: 500/500, train_loss: 0.2854, train_accuracy: 90.5800, test_loss: 0.4933, test_accuracy: 85.9400\n",
            "epoch 269/400:\n",
            "iteration: 100/500, train_loss: 0.2613, train_accuracy: 91.0200\n",
            "iteration: 200/500, train_loss: 0.2609, train_accuracy: 90.8600\n",
            "iteration: 300/500, train_loss: 0.2589, train_accuracy: 90.8733\n",
            "iteration: 400/500, train_loss: 0.2620, train_accuracy: 90.7575\n",
            "iteration: 500/500, train_loss: 0.2618, train_accuracy: 90.7620, test_loss: 0.5195, test_accuracy: 85.8100\n",
            "epoch 270/400:\n",
            "iteration: 100/500, train_loss: 0.2589, train_accuracy: 90.6700\n",
            "iteration: 200/500, train_loss: 0.2605, train_accuracy: 90.8100\n",
            "iteration: 300/500, train_loss: 0.2584, train_accuracy: 90.9100\n",
            "iteration: 400/500, train_loss: 0.2614, train_accuracy: 90.7750\n",
            "iteration: 500/500, train_loss: 0.2601, train_accuracy: 90.7720, test_loss: 0.4714, test_accuracy: 85.3500\n",
            "epoch 271/400:\n",
            "iteration: 100/500, train_loss: 0.2448, train_accuracy: 91.2000\n",
            "iteration: 200/500, train_loss: 0.2546, train_accuracy: 90.9800\n",
            "iteration: 300/500, train_loss: 0.2520, train_accuracy: 91.1100\n",
            "iteration: 400/500, train_loss: 0.2556, train_accuracy: 91.0625\n",
            "iteration: 500/500, train_loss: 0.2563, train_accuracy: 90.9900, test_loss: 0.4640, test_accuracy: 86.0900\n",
            "epoch 272/400:\n",
            "iteration: 100/500, train_loss: 0.2389, train_accuracy: 91.4000\n",
            "iteration: 200/500, train_loss: 0.2723, train_accuracy: 90.6950\n",
            "iteration: 300/500, train_loss: 0.2792, train_accuracy: 90.4400\n",
            "iteration: 400/500, train_loss: 0.2805, train_accuracy: 90.3600\n",
            "iteration: 500/500, train_loss: 0.2770, train_accuracy: 90.5000, test_loss: 0.4705, test_accuracy: 85.8200\n",
            "epoch 273/400:\n",
            "iteration: 100/500, train_loss: 0.2575, train_accuracy: 90.7600\n",
            "iteration: 200/500, train_loss: 0.2795, train_accuracy: 90.3700\n",
            "iteration: 300/500, train_loss: 0.2716, train_accuracy: 90.5133\n",
            "iteration: 400/500, train_loss: 0.2691, train_accuracy: 90.6325\n",
            "iteration: 500/500, train_loss: 0.2670, train_accuracy: 90.6760, test_loss: 0.5117, test_accuracy: 85.3300\n",
            "epoch 274/400:\n",
            "iteration: 100/500, train_loss: 0.2516, train_accuracy: 91.4300\n",
            "iteration: 200/500, train_loss: 0.3035, train_accuracy: 90.3050\n",
            "iteration: 300/500, train_loss: 0.2997, train_accuracy: 90.1667\n",
            "iteration: 400/500, train_loss: 0.2969, train_accuracy: 90.1050\n",
            "iteration: 500/500, train_loss: 0.2959, train_accuracy: 90.1740, test_loss: 0.5188, test_accuracy: 85.2300\n",
            "epoch 275/400:\n",
            "iteration: 100/500, train_loss: 0.2665, train_accuracy: 90.5800\n",
            "iteration: 200/500, train_loss: 0.2702, train_accuracy: 90.6700\n",
            "iteration: 300/500, train_loss: 0.2651, train_accuracy: 90.6867\n",
            "iteration: 400/500, train_loss: 0.2672, train_accuracy: 90.6075\n",
            "iteration: 500/500, train_loss: 0.2656, train_accuracy: 90.6540, test_loss: 0.4920, test_accuracy: 85.9600\n",
            "epoch 276/400:\n",
            "iteration: 100/500, train_loss: 0.2478, train_accuracy: 91.3400\n",
            "iteration: 200/500, train_loss: 0.2578, train_accuracy: 90.9200\n",
            "iteration: 300/500, train_loss: 0.2521, train_accuracy: 91.0267\n",
            "iteration: 400/500, train_loss: 0.2590, train_accuracy: 90.9325\n",
            "iteration: 500/500, train_loss: 0.2579, train_accuracy: 90.9480, test_loss: 0.4701, test_accuracy: 85.5300\n",
            "epoch 277/400:\n",
            "iteration: 100/500, train_loss: 0.2490, train_accuracy: 91.0900\n",
            "iteration: 200/500, train_loss: 0.2551, train_accuracy: 91.0250\n",
            "iteration: 300/500, train_loss: 0.2546, train_accuracy: 90.9767\n",
            "iteration: 400/500, train_loss: 0.2559, train_accuracy: 90.9600\n",
            "iteration: 500/500, train_loss: 0.2547, train_accuracy: 90.9520, test_loss: 0.4909, test_accuracy: 85.7200\n",
            "epoch 278/400:\n",
            "iteration: 100/500, train_loss: 0.2516, train_accuracy: 91.1800\n",
            "iteration: 200/500, train_loss: 0.2518, train_accuracy: 91.1300\n",
            "iteration: 300/500, train_loss: 0.2513, train_accuracy: 91.1300\n",
            "iteration: 400/500, train_loss: 0.2531, train_accuracy: 91.1125\n",
            "iteration: 500/500, train_loss: 0.2533, train_accuracy: 91.0860, test_loss: 0.5066, test_accuracy: 85.1900\n",
            "epoch 279/400:\n",
            "iteration: 100/500, train_loss: 0.2464, train_accuracy: 91.3400\n",
            "iteration: 200/500, train_loss: 0.2700, train_accuracy: 91.1700\n",
            "iteration: 300/500, train_loss: 0.2802, train_accuracy: 90.5533\n",
            "iteration: 400/500, train_loss: 0.2833, train_accuracy: 90.4025\n",
            "iteration: 500/500, train_loss: 0.2793, train_accuracy: 90.4280, test_loss: 0.5100, test_accuracy: 85.4300\n",
            "epoch 280/400:\n",
            "iteration: 100/500, train_loss: 0.2594, train_accuracy: 90.9000\n",
            "iteration: 200/500, train_loss: 0.2549, train_accuracy: 91.0250\n",
            "iteration: 300/500, train_loss: 0.2530, train_accuracy: 90.9867\n",
            "iteration: 400/500, train_loss: 0.2562, train_accuracy: 91.0150\n",
            "iteration: 500/500, train_loss: 0.2601, train_accuracy: 90.9300, test_loss: 0.4547, test_accuracy: 85.6100\n",
            "epoch 281/400:\n",
            "iteration: 100/500, train_loss: 0.2465, train_accuracy: 90.8400\n",
            "iteration: 200/500, train_loss: 0.2576, train_accuracy: 90.7000\n",
            "iteration: 300/500, train_loss: 0.2558, train_accuracy: 90.8333\n",
            "iteration: 400/500, train_loss: 0.2571, train_accuracy: 90.7975\n",
            "iteration: 500/500, train_loss: 0.2575, train_accuracy: 90.8300, test_loss: 0.4971, test_accuracy: 85.8100\n",
            "epoch 282/400:\n",
            "iteration: 100/500, train_loss: 0.2997, train_accuracy: 90.5700\n",
            "iteration: 200/500, train_loss: 0.2984, train_accuracy: 90.3750\n",
            "iteration: 300/500, train_loss: 0.2873, train_accuracy: 90.5267\n",
            "iteration: 400/500, train_loss: 0.2867, train_accuracy: 90.4525\n",
            "iteration: 500/500, train_loss: 0.2805, train_accuracy: 90.5720, test_loss: 0.4628, test_accuracy: 85.8500\n",
            "epoch 283/400:\n",
            "iteration: 100/500, train_loss: 0.2537, train_accuracy: 91.0600\n",
            "iteration: 200/500, train_loss: 0.2547, train_accuracy: 91.1250\n",
            "iteration: 300/500, train_loss: 0.2510, train_accuracy: 91.2100\n",
            "iteration: 400/500, train_loss: 0.2544, train_accuracy: 91.1125\n",
            "iteration: 500/500, train_loss: 0.2541, train_accuracy: 91.1420, test_loss: 0.4764, test_accuracy: 85.3500\n",
            "epoch 284/400:\n",
            "iteration: 100/500, train_loss: 0.2511, train_accuracy: 91.2000\n",
            "iteration: 200/500, train_loss: 0.2559, train_accuracy: 91.1350\n",
            "iteration: 300/500, train_loss: 0.2530, train_accuracy: 91.1300\n",
            "iteration: 400/500, train_loss: 0.2638, train_accuracy: 90.8575\n",
            "iteration: 500/500, train_loss: 0.2615, train_accuracy: 90.9500, test_loss: 0.4872, test_accuracy: 85.6700\n",
            "epoch 285/400:\n",
            "iteration: 100/500, train_loss: 0.2552, train_accuracy: 91.1800\n",
            "iteration: 200/500, train_loss: 0.2599, train_accuracy: 90.9000\n",
            "iteration: 300/500, train_loss: 0.2555, train_accuracy: 90.9633\n",
            "iteration: 400/500, train_loss: 0.2583, train_accuracy: 90.9175\n",
            "iteration: 500/500, train_loss: 0.2579, train_accuracy: 90.9400, test_loss: 0.5115, test_accuracy: 85.2500\n",
            "epoch 286/400:\n",
            "iteration: 100/500, train_loss: 0.2514, train_accuracy: 91.0400\n",
            "iteration: 200/500, train_loss: 0.2550, train_accuracy: 90.9200\n",
            "iteration: 300/500, train_loss: 0.2599, train_accuracy: 90.9400\n",
            "iteration: 400/500, train_loss: 0.2619, train_accuracy: 90.8525\n",
            "iteration: 500/500, train_loss: 0.2580, train_accuracy: 90.9620, test_loss: 0.4693, test_accuracy: 85.6900\n",
            "epoch 287/400:\n",
            "iteration: 100/500, train_loss: 0.2360, train_accuracy: 91.5400\n",
            "iteration: 200/500, train_loss: 0.2495, train_accuracy: 91.0500\n",
            "iteration: 300/500, train_loss: 0.2496, train_accuracy: 91.1433\n",
            "iteration: 400/500, train_loss: 0.2558, train_accuracy: 91.0175\n",
            "iteration: 500/500, train_loss: 0.2577, train_accuracy: 90.9460, test_loss: 0.6283, test_accuracy: 84.4700\n",
            "epoch 288/400:\n",
            "iteration: 100/500, train_loss: 0.3025, train_accuracy: 89.3900\n",
            "iteration: 200/500, train_loss: 0.2998, train_accuracy: 89.7300\n",
            "iteration: 300/500, train_loss: 0.2879, train_accuracy: 89.9633\n",
            "iteration: 400/500, train_loss: 0.2953, train_accuracy: 90.1300\n",
            "iteration: 500/500, train_loss: 0.2904, train_accuracy: 90.2480, test_loss: 0.4922, test_accuracy: 85.7200\n",
            "epoch 289/400:\n",
            "iteration: 100/500, train_loss: 0.2465, train_accuracy: 91.4200\n",
            "iteration: 200/500, train_loss: 0.2559, train_accuracy: 91.2650\n",
            "iteration: 300/500, train_loss: 0.2564, train_accuracy: 91.0800\n",
            "iteration: 400/500, train_loss: 0.2568, train_accuracy: 91.0225\n",
            "iteration: 500/500, train_loss: 0.2549, train_accuracy: 91.0580, test_loss: 0.4710, test_accuracy: 85.5300\n",
            "epoch 290/400:\n",
            "iteration: 100/500, train_loss: 0.2420, train_accuracy: 91.6200\n",
            "iteration: 200/500, train_loss: 0.2581, train_accuracy: 91.3700\n",
            "iteration: 300/500, train_loss: 0.2543, train_accuracy: 91.3567\n",
            "iteration: 400/500, train_loss: 0.2556, train_accuracy: 91.2450\n",
            "iteration: 500/500, train_loss: 0.2544, train_accuracy: 91.2760, test_loss: 0.5125, test_accuracy: 85.1100\n",
            "epoch 291/400:\n",
            "iteration: 100/500, train_loss: 0.2638, train_accuracy: 91.0400\n",
            "iteration: 200/500, train_loss: 0.2611, train_accuracy: 90.9050\n",
            "iteration: 300/500, train_loss: 0.2559, train_accuracy: 91.1300\n",
            "iteration: 400/500, train_loss: 0.2559, train_accuracy: 91.0925\n",
            "iteration: 500/500, train_loss: 0.2521, train_accuracy: 91.1860, test_loss: 0.4879, test_accuracy: 85.7200\n",
            "epoch 292/400:\n",
            "iteration: 100/500, train_loss: 0.2869, train_accuracy: 90.4800\n",
            "iteration: 200/500, train_loss: 0.2899, train_accuracy: 90.3150\n",
            "iteration: 300/500, train_loss: 0.2931, train_accuracy: 90.0300\n",
            "iteration: 400/500, train_loss: 0.3044, train_accuracy: 89.8775\n",
            "iteration: 500/500, train_loss: 0.3002, train_accuracy: 89.9940, test_loss: 0.5128, test_accuracy: 85.3100\n",
            "epoch 293/400:\n",
            "iteration: 100/500, train_loss: 0.2595, train_accuracy: 91.0100\n",
            "iteration: 200/500, train_loss: 0.2649, train_accuracy: 90.8000\n",
            "iteration: 300/500, train_loss: 0.2623, train_accuracy: 90.8133\n",
            "iteration: 400/500, train_loss: 0.2640, train_accuracy: 90.7900\n",
            "iteration: 500/500, train_loss: 0.2623, train_accuracy: 90.8100, test_loss: 0.4621, test_accuracy: 85.6500\n",
            "epoch 294/400:\n",
            "iteration: 100/500, train_loss: 0.2577, train_accuracy: 90.7400\n",
            "iteration: 200/500, train_loss: 0.2584, train_accuracy: 90.7500\n",
            "iteration: 300/500, train_loss: 0.2567, train_accuracy: 90.8333\n",
            "iteration: 400/500, train_loss: 0.2586, train_accuracy: 90.7850\n",
            "iteration: 500/500, train_loss: 0.2564, train_accuracy: 90.9120, test_loss: 0.4593, test_accuracy: 85.8400\n",
            "epoch 295/400:\n",
            "iteration: 100/500, train_loss: 0.3147, train_accuracy: 89.8200\n",
            "iteration: 200/500, train_loss: 0.3093, train_accuracy: 89.5950\n",
            "iteration: 300/500, train_loss: 0.2976, train_accuracy: 89.9700\n",
            "iteration: 400/500, train_loss: 0.2897, train_accuracy: 90.1350\n",
            "iteration: 500/500, train_loss: 0.2844, train_accuracy: 90.2420, test_loss: 0.4867, test_accuracy: 85.3200\n",
            "epoch 296/400:\n",
            "iteration: 100/500, train_loss: 0.2441, train_accuracy: 91.3200\n",
            "iteration: 200/500, train_loss: 0.2523, train_accuracy: 91.0700\n",
            "iteration: 300/500, train_loss: 0.2514, train_accuracy: 91.1067\n",
            "iteration: 400/500, train_loss: 0.2549, train_accuracy: 91.0225\n",
            "iteration: 500/500, train_loss: 0.2530, train_accuracy: 91.0580, test_loss: 0.4869, test_accuracy: 85.6900\n",
            "epoch 297/400:\n",
            "iteration: 100/500, train_loss: 0.2404, train_accuracy: 91.4500\n",
            "iteration: 200/500, train_loss: 0.2473, train_accuracy: 91.1550\n",
            "iteration: 300/500, train_loss: 0.2476, train_accuracy: 91.1900\n",
            "iteration: 400/500, train_loss: 0.2481, train_accuracy: 91.1975\n",
            "iteration: 500/500, train_loss: 0.2497, train_accuracy: 91.1540, test_loss: 0.4993, test_accuracy: 85.5500\n",
            "epoch 298/400:\n",
            "iteration: 100/500, train_loss: 0.2479, train_accuracy: 91.2300\n",
            "iteration: 200/500, train_loss: 0.2491, train_accuracy: 91.2100\n",
            "iteration: 300/500, train_loss: 0.2489, train_accuracy: 91.2533\n",
            "iteration: 400/500, train_loss: 0.2507, train_accuracy: 91.1700\n",
            "iteration: 500/500, train_loss: 0.2512, train_accuracy: 91.2500, test_loss: 0.5004, test_accuracy: 85.8300\n",
            "epoch 299/400:\n",
            "iteration: 100/500, train_loss: 0.2570, train_accuracy: 90.7400\n",
            "iteration: 200/500, train_loss: 0.2541, train_accuracy: 90.9100\n",
            "iteration: 300/500, train_loss: 0.2507, train_accuracy: 90.9300\n",
            "iteration: 400/500, train_loss: 0.2534, train_accuracy: 90.9050\n",
            "iteration: 500/500, train_loss: 0.2504, train_accuracy: 90.9880, test_loss: 0.4717, test_accuracy: 85.7500\n",
            "epoch 300/400:\n",
            "iteration: 100/500, train_loss: 0.2474, train_accuracy: 90.9100\n",
            "iteration: 200/500, train_loss: 0.2496, train_accuracy: 91.0850\n",
            "iteration: 300/500, train_loss: 0.2559, train_accuracy: 91.0033\n",
            "iteration: 400/500, train_loss: 0.2618, train_accuracy: 90.7775\n",
            "iteration: 500/500, train_loss: 0.2730, train_accuracy: 90.7400, test_loss: 0.6638, test_accuracy: 82.4900\n",
            "epoch 301/400:\n",
            "iteration: 100/500, train_loss: 0.3178, train_accuracy: 89.3800\n",
            "iteration: 200/500, train_loss: 0.2936, train_accuracy: 89.9050\n",
            "iteration: 300/500, train_loss: 0.2798, train_accuracy: 90.2533\n",
            "iteration: 400/500, train_loss: 0.2781, train_accuracy: 90.2950\n",
            "iteration: 500/500, train_loss: 0.2729, train_accuracy: 90.4540, test_loss: 0.5279, test_accuracy: 85.4000\n",
            "epoch 302/400:\n",
            "iteration: 100/500, train_loss: 0.2518, train_accuracy: 91.3100\n",
            "iteration: 200/500, train_loss: 0.2572, train_accuracy: 91.1000\n",
            "iteration: 300/500, train_loss: 0.2544, train_accuracy: 91.0433\n",
            "iteration: 400/500, train_loss: 0.2607, train_accuracy: 90.7700\n",
            "iteration: 500/500, train_loss: 0.2817, train_accuracy: 90.3140, test_loss: 0.5872, test_accuracy: 82.7500\n",
            "epoch 303/400:\n",
            "iteration: 100/500, train_loss: 0.3915, train_accuracy: 87.9200\n",
            "iteration: 200/500, train_loss: 0.3514, train_accuracy: 88.7300\n",
            "iteration: 300/500, train_loss: 0.3269, train_accuracy: 89.2433\n",
            "iteration: 400/500, train_loss: 0.3151, train_accuracy: 89.5150\n",
            "iteration: 500/500, train_loss: 0.3091, train_accuracy: 89.6900, test_loss: 0.4853, test_accuracy: 85.1000\n",
            "epoch 304/400:\n",
            "iteration: 100/500, train_loss: 0.2937, train_accuracy: 90.5800\n",
            "iteration: 200/500, train_loss: 0.2891, train_accuracy: 90.6100\n",
            "iteration: 300/500, train_loss: 0.2746, train_accuracy: 90.9333\n",
            "iteration: 400/500, train_loss: 0.2720, train_accuracy: 90.8400\n",
            "iteration: 500/500, train_loss: 0.2662, train_accuracy: 91.0280, test_loss: 0.4591, test_accuracy: 86.2200\n",
            "epoch 305/400:\n",
            "iteration: 100/500, train_loss: 0.2405, train_accuracy: 91.7600\n",
            "iteration: 200/500, train_loss: 0.2474, train_accuracy: 91.3450\n",
            "iteration: 300/500, train_loss: 0.2502, train_accuracy: 91.2767\n",
            "iteration: 400/500, train_loss: 0.2524, train_accuracy: 91.1850\n",
            "iteration: 500/500, train_loss: 0.2540, train_accuracy: 91.1600, test_loss: 0.4911, test_accuracy: 85.8000\n",
            "epoch 306/400:\n",
            "iteration: 100/500, train_loss: 0.2524, train_accuracy: 91.0200\n",
            "iteration: 200/500, train_loss: 0.2535, train_accuracy: 91.1050\n",
            "iteration: 300/500, train_loss: 0.2501, train_accuracy: 91.2400\n",
            "iteration: 400/500, train_loss: 0.2561, train_accuracy: 91.1125\n",
            "iteration: 500/500, train_loss: 0.2602, train_accuracy: 91.1700, test_loss: 0.5648, test_accuracy: 85.1000\n",
            "epoch 307/400:\n",
            "iteration: 100/500, train_loss: 0.2536, train_accuracy: 90.9200\n",
            "iteration: 200/500, train_loss: 0.2521, train_accuracy: 91.1650\n",
            "iteration: 300/500, train_loss: 0.2545, train_accuracy: 91.0700\n",
            "iteration: 400/500, train_loss: 0.2598, train_accuracy: 90.8975\n",
            "iteration: 500/500, train_loss: 0.2551, train_accuracy: 91.0220, test_loss: 0.4669, test_accuracy: 85.5800\n",
            "epoch 308/400:\n",
            "iteration: 100/500, train_loss: 0.2424, train_accuracy: 91.7100\n",
            "iteration: 200/500, train_loss: 0.2443, train_accuracy: 91.6100\n",
            "iteration: 300/500, train_loss: 0.2445, train_accuracy: 91.4767\n",
            "iteration: 400/500, train_loss: 0.2466, train_accuracy: 91.3375\n",
            "iteration: 500/500, train_loss: 0.2455, train_accuracy: 91.3900, test_loss: 0.4606, test_accuracy: 85.7000\n",
            "epoch 309/400:\n",
            "iteration: 100/500, train_loss: 0.2535, train_accuracy: 91.4500\n",
            "iteration: 200/500, train_loss: 0.2499, train_accuracy: 91.4250\n",
            "iteration: 300/500, train_loss: 0.2459, train_accuracy: 91.3267\n",
            "iteration: 400/500, train_loss: 0.2480, train_accuracy: 91.2800\n",
            "iteration: 500/500, train_loss: 0.2460, train_accuracy: 91.3120, test_loss: 0.4693, test_accuracy: 85.9100\n",
            "epoch 310/400:\n",
            "iteration: 100/500, train_loss: 0.2398, train_accuracy: 91.5600\n",
            "iteration: 200/500, train_loss: 0.2424, train_accuracy: 91.4800\n",
            "iteration: 300/500, train_loss: 0.2452, train_accuracy: 91.5033\n",
            "iteration: 400/500, train_loss: 0.2485, train_accuracy: 91.3525\n",
            "iteration: 500/500, train_loss: 0.2480, train_accuracy: 91.3700, test_loss: 0.4970, test_accuracy: 85.6000\n",
            "epoch 311/400:\n",
            "iteration: 100/500, train_loss: 0.2370, train_accuracy: 91.6800\n",
            "iteration: 200/500, train_loss: 0.2426, train_accuracy: 91.4600\n",
            "iteration: 300/500, train_loss: 0.2746, train_accuracy: 90.6833\n",
            "iteration: 400/500, train_loss: 0.2756, train_accuracy: 90.5650\n",
            "iteration: 500/500, train_loss: 0.2830, train_accuracy: 90.4060, test_loss: 0.5135, test_accuracy: 85.1900\n",
            "epoch 312/400:\n",
            "iteration: 100/500, train_loss: 0.2598, train_accuracy: 90.8700\n",
            "iteration: 200/500, train_loss: 0.2593, train_accuracy: 90.8650\n",
            "iteration: 300/500, train_loss: 0.2555, train_accuracy: 90.8733\n",
            "iteration: 400/500, train_loss: 0.2566, train_accuracy: 90.8350\n",
            "iteration: 500/500, train_loss: 0.2547, train_accuracy: 90.9140, test_loss: 0.4684, test_accuracy: 85.7200\n",
            "epoch 313/400:\n",
            "iteration: 100/500, train_loss: 0.2448, train_accuracy: 91.1300\n",
            "iteration: 200/500, train_loss: 0.2458, train_accuracy: 91.1800\n",
            "iteration: 300/500, train_loss: 0.2439, train_accuracy: 91.2267\n",
            "iteration: 400/500, train_loss: 0.2470, train_accuracy: 91.1550\n",
            "iteration: 500/500, train_loss: 0.2478, train_accuracy: 91.1300, test_loss: 0.4563, test_accuracy: 86.1400\n",
            "epoch 314/400:\n",
            "iteration: 100/500, train_loss: 0.2552, train_accuracy: 91.6400\n",
            "iteration: 200/500, train_loss: 0.2516, train_accuracy: 91.3650\n",
            "iteration: 300/500, train_loss: 0.2486, train_accuracy: 91.3933\n",
            "iteration: 400/500, train_loss: 0.2555, train_accuracy: 91.1475\n",
            "iteration: 500/500, train_loss: 0.2549, train_accuracy: 91.1540, test_loss: 0.5137, test_accuracy: 86.0200\n",
            "epoch 315/400:\n",
            "iteration: 100/500, train_loss: 0.2469, train_accuracy: 91.2300\n",
            "iteration: 200/500, train_loss: 0.2509, train_accuracy: 91.2050\n",
            "iteration: 300/500, train_loss: 0.2514, train_accuracy: 91.2400\n",
            "iteration: 400/500, train_loss: 0.2522, train_accuracy: 91.1775\n",
            "iteration: 500/500, train_loss: 0.2657, train_accuracy: 90.9320, test_loss: 0.5202, test_accuracy: 84.9900\n",
            "epoch 316/400:\n",
            "iteration: 100/500, train_loss: 0.2744, train_accuracy: 90.6400\n",
            "iteration: 200/500, train_loss: 0.2682, train_accuracy: 90.6850\n",
            "iteration: 300/500, train_loss: 0.2625, train_accuracy: 90.7967\n",
            "iteration: 400/500, train_loss: 0.2628, train_accuracy: 90.7875\n",
            "iteration: 500/500, train_loss: 0.2605, train_accuracy: 90.8300, test_loss: 0.5163, test_accuracy: 85.9300\n",
            "epoch 317/400:\n",
            "iteration: 100/500, train_loss: 0.2443, train_accuracy: 91.4400\n",
            "iteration: 200/500, train_loss: 0.2444, train_accuracy: 91.4250\n",
            "iteration: 300/500, train_loss: 0.2462, train_accuracy: 91.3567\n",
            "iteration: 400/500, train_loss: 0.2494, train_accuracy: 91.2225\n",
            "iteration: 500/500, train_loss: 0.2499, train_accuracy: 91.2220, test_loss: 0.4989, test_accuracy: 85.8000\n",
            "epoch 318/400:\n",
            "iteration: 100/500, train_loss: 0.2458, train_accuracy: 91.2600\n",
            "iteration: 200/500, train_loss: 0.2501, train_accuracy: 91.1300\n",
            "iteration: 300/500, train_loss: 0.2488, train_accuracy: 91.1833\n",
            "iteration: 400/500, train_loss: 0.2503, train_accuracy: 91.1575\n",
            "iteration: 500/500, train_loss: 0.2481, train_accuracy: 91.1820, test_loss: 0.5333, test_accuracy: 85.8800\n",
            "epoch 319/400:\n",
            "iteration: 100/500, train_loss: 0.2503, train_accuracy: 90.8800\n",
            "iteration: 200/500, train_loss: 0.2502, train_accuracy: 91.1000\n",
            "iteration: 300/500, train_loss: 0.2498, train_accuracy: 91.2067\n",
            "iteration: 400/500, train_loss: 0.2494, train_accuracy: 91.2325\n",
            "iteration: 500/500, train_loss: 0.2479, train_accuracy: 91.2840, test_loss: 0.4625, test_accuracy: 85.8700\n",
            "epoch 320/400:\n",
            "iteration: 100/500, train_loss: 0.2466, train_accuracy: 91.7900\n",
            "iteration: 200/500, train_loss: 0.2834, train_accuracy: 91.0600\n",
            "iteration: 300/500, train_loss: 0.2773, train_accuracy: 90.8967\n",
            "iteration: 400/500, train_loss: 0.2709, train_accuracy: 90.9150\n",
            "iteration: 500/500, train_loss: 0.2709, train_accuracy: 90.9660, test_loss: 0.4719, test_accuracy: 85.6900\n",
            "epoch 321/400:\n",
            "iteration: 100/500, train_loss: 0.2493, train_accuracy: 91.2000\n",
            "iteration: 200/500, train_loss: 0.2607, train_accuracy: 90.8350\n",
            "iteration: 300/500, train_loss: 0.2558, train_accuracy: 91.0567\n",
            "iteration: 400/500, train_loss: 0.2562, train_accuracy: 91.1000\n",
            "iteration: 500/500, train_loss: 0.2557, train_accuracy: 91.1240, test_loss: 0.5331, test_accuracy: 85.8700\n",
            "epoch 322/400:\n",
            "iteration: 100/500, train_loss: 0.2487, train_accuracy: 91.2300\n",
            "iteration: 200/500, train_loss: 0.2460, train_accuracy: 91.2550\n",
            "iteration: 300/500, train_loss: 0.2440, train_accuracy: 91.3167\n",
            "iteration: 400/500, train_loss: 0.2475, train_accuracy: 91.2075\n",
            "iteration: 500/500, train_loss: 0.2443, train_accuracy: 91.3220, test_loss: 0.5091, test_accuracy: 85.3800\n",
            "epoch 323/400:\n",
            "iteration: 100/500, train_loss: 0.2589, train_accuracy: 90.9100\n",
            "iteration: 200/500, train_loss: 0.2527, train_accuracy: 91.0950\n",
            "iteration: 300/500, train_loss: 0.2487, train_accuracy: 91.2833\n",
            "iteration: 400/500, train_loss: 0.2497, train_accuracy: 91.2150\n",
            "iteration: 500/500, train_loss: 0.2472, train_accuracy: 91.2760, test_loss: 0.5148, test_accuracy: 85.7000\n",
            "epoch 324/400:\n",
            "iteration: 100/500, train_loss: 0.2449, train_accuracy: 91.3200\n",
            "iteration: 200/500, train_loss: 0.2458, train_accuracy: 91.2750\n",
            "iteration: 300/500, train_loss: 0.2437, train_accuracy: 91.2567\n",
            "iteration: 400/500, train_loss: 0.2442, train_accuracy: 91.3175\n",
            "iteration: 500/500, train_loss: 0.2438, train_accuracy: 91.3540, test_loss: 0.5001, test_accuracy: 85.9200\n",
            "epoch 325/400:\n",
            "iteration: 100/500, train_loss: 0.2409, train_accuracy: 91.5100\n",
            "iteration: 200/500, train_loss: 0.2423, train_accuracy: 91.5650\n",
            "iteration: 300/500, train_loss: 0.2402, train_accuracy: 91.6333\n",
            "iteration: 400/500, train_loss: 0.2548, train_accuracy: 91.2925\n",
            "iteration: 500/500, train_loss: 0.2535, train_accuracy: 91.2820, test_loss: 0.5371, test_accuracy: 85.8100\n",
            "epoch 326/400:\n",
            "iteration: 100/500, train_loss: 0.2462, train_accuracy: 91.1800\n",
            "iteration: 200/500, train_loss: 0.2435, train_accuracy: 91.3200\n",
            "iteration: 300/500, train_loss: 0.2408, train_accuracy: 91.4267\n",
            "iteration: 400/500, train_loss: 0.2472, train_accuracy: 91.3150\n",
            "iteration: 500/500, train_loss: 0.2457, train_accuracy: 91.3960, test_loss: 0.4838, test_accuracy: 85.2000\n",
            "epoch 327/400:\n",
            "iteration: 100/500, train_loss: 0.2374, train_accuracy: 91.8100\n",
            "iteration: 200/500, train_loss: 0.2399, train_accuracy: 91.7950\n",
            "iteration: 300/500, train_loss: 0.2367, train_accuracy: 91.8500\n",
            "iteration: 400/500, train_loss: 0.2374, train_accuracy: 91.7875\n",
            "iteration: 500/500, train_loss: 0.2398, train_accuracy: 91.7280, test_loss: 0.4816, test_accuracy: 85.3900\n",
            "epoch 328/400:\n",
            "iteration: 100/500, train_loss: 0.2475, train_accuracy: 91.4100\n",
            "iteration: 200/500, train_loss: 0.2454, train_accuracy: 91.4400\n",
            "iteration: 300/500, train_loss: 0.2451, train_accuracy: 91.3333\n",
            "iteration: 400/500, train_loss: 0.2498, train_accuracy: 91.1950\n",
            "iteration: 500/500, train_loss: 0.2497, train_accuracy: 91.1920, test_loss: 0.5129, test_accuracy: 85.6000\n",
            "epoch 329/400:\n",
            "iteration: 100/500, train_loss: 0.2399, train_accuracy: 91.4700\n",
            "iteration: 200/500, train_loss: 0.2498, train_accuracy: 91.4900\n",
            "iteration: 300/500, train_loss: 0.2508, train_accuracy: 91.4400\n",
            "iteration: 400/500, train_loss: 0.2501, train_accuracy: 91.4225\n",
            "iteration: 500/500, train_loss: 0.2525, train_accuracy: 91.3960, test_loss: 0.5783, test_accuracy: 84.5000\n",
            "epoch 330/400:\n",
            "iteration: 100/500, train_loss: 0.2570, train_accuracy: 90.9500\n",
            "iteration: 200/500, train_loss: 0.2506, train_accuracy: 91.2000\n",
            "iteration: 300/500, train_loss: 0.2462, train_accuracy: 91.3600\n",
            "iteration: 400/500, train_loss: 0.2488, train_accuracy: 91.2250\n",
            "iteration: 500/500, train_loss: 0.2498, train_accuracy: 91.2060, test_loss: 0.4892, test_accuracy: 85.7700\n",
            "epoch 331/400:\n",
            "iteration: 100/500, train_loss: 0.3066, train_accuracy: 90.9300\n",
            "iteration: 200/500, train_loss: 0.2935, train_accuracy: 90.7250\n",
            "iteration: 300/500, train_loss: 0.2808, train_accuracy: 90.8167\n",
            "iteration: 400/500, train_loss: 0.2785, train_accuracy: 90.7775\n",
            "iteration: 500/500, train_loss: 0.2746, train_accuracy: 90.8480, test_loss: 0.6140, test_accuracy: 85.1000\n",
            "epoch 332/400:\n",
            "iteration: 100/500, train_loss: 0.2557, train_accuracy: 91.1200\n",
            "iteration: 200/500, train_loss: 0.2492, train_accuracy: 91.3550\n",
            "iteration: 300/500, train_loss: 0.2548, train_accuracy: 91.2133\n",
            "iteration: 400/500, train_loss: 0.2580, train_accuracy: 91.0625\n",
            "iteration: 500/500, train_loss: 0.2548, train_accuracy: 91.2040, test_loss: 0.6552, test_accuracy: 84.8200\n",
            "epoch 333/400:\n",
            "iteration: 100/500, train_loss: 0.2930, train_accuracy: 90.3800\n",
            "iteration: 200/500, train_loss: 0.2951, train_accuracy: 90.1800\n",
            "iteration: 300/500, train_loss: 0.2868, train_accuracy: 90.3667\n",
            "iteration: 400/500, train_loss: 0.2809, train_accuracy: 90.4625\n",
            "iteration: 500/500, train_loss: 0.2741, train_accuracy: 90.6380, test_loss: 0.4758, test_accuracy: 85.3700\n",
            "epoch 334/400:\n",
            "iteration: 100/500, train_loss: 0.2588, train_accuracy: 90.7400\n",
            "iteration: 200/500, train_loss: 0.2604, train_accuracy: 90.7650\n",
            "iteration: 300/500, train_loss: 0.2571, train_accuracy: 90.9433\n",
            "iteration: 400/500, train_loss: 0.2737, train_accuracy: 90.5650\n",
            "iteration: 500/500, train_loss: 0.2775, train_accuracy: 90.4520, test_loss: 0.5343, test_accuracy: 84.9200\n",
            "epoch 335/400:\n",
            "iteration: 100/500, train_loss: 0.2658, train_accuracy: 90.8900\n",
            "iteration: 200/500, train_loss: 0.2606, train_accuracy: 91.0200\n",
            "iteration: 300/500, train_loss: 0.2534, train_accuracy: 91.2033\n",
            "iteration: 400/500, train_loss: 0.2550, train_accuracy: 91.0975\n",
            "iteration: 500/500, train_loss: 0.2515, train_accuracy: 91.1860, test_loss: 0.4770, test_accuracy: 85.0600\n",
            "epoch 336/400:\n",
            "iteration: 100/500, train_loss: 0.2610, train_accuracy: 91.2300\n",
            "iteration: 200/500, train_loss: 0.2629, train_accuracy: 91.0150\n",
            "iteration: 300/500, train_loss: 0.2592, train_accuracy: 91.0767\n",
            "iteration: 400/500, train_loss: 0.2696, train_accuracy: 90.7750\n",
            "iteration: 500/500, train_loss: 0.2686, train_accuracy: 90.7660, test_loss: 0.4751, test_accuracy: 85.2600\n",
            "epoch 337/400:\n",
            "iteration: 100/500, train_loss: 0.2481, train_accuracy: 91.3700\n",
            "iteration: 200/500, train_loss: 0.2487, train_accuracy: 91.3800\n",
            "iteration: 300/500, train_loss: 0.2475, train_accuracy: 91.3067\n",
            "iteration: 400/500, train_loss: 0.2501, train_accuracy: 91.1475\n",
            "iteration: 500/500, train_loss: 0.2513, train_accuracy: 91.1240, test_loss: 0.5054, test_accuracy: 85.5500\n",
            "epoch 338/400:\n",
            "iteration: 100/500, train_loss: 0.2444, train_accuracy: 91.5800\n",
            "iteration: 200/500, train_loss: 0.2423, train_accuracy: 91.5550\n",
            "iteration: 300/500, train_loss: 0.2393, train_accuracy: 91.6600\n",
            "iteration: 400/500, train_loss: 0.2438, train_accuracy: 91.3475\n",
            "iteration: 500/500, train_loss: 0.2432, train_accuracy: 91.3800, test_loss: 0.4572, test_accuracy: 85.7500\n",
            "epoch 339/400:\n",
            "iteration: 100/500, train_loss: 0.2347, train_accuracy: 91.4500\n",
            "iteration: 200/500, train_loss: 0.2406, train_accuracy: 91.3100\n",
            "iteration: 300/500, train_loss: 0.2361, train_accuracy: 91.4867\n",
            "iteration: 400/500, train_loss: 0.2365, train_accuracy: 91.4650\n",
            "iteration: 500/500, train_loss: 0.2392, train_accuracy: 91.4660, test_loss: 0.4780, test_accuracy: 85.2100\n",
            "epoch 340/400:\n",
            "iteration: 100/500, train_loss: 0.2528, train_accuracy: 91.1800\n",
            "iteration: 200/500, train_loss: 0.2530, train_accuracy: 91.0750\n",
            "iteration: 300/500, train_loss: 0.2594, train_accuracy: 90.9933\n",
            "iteration: 400/500, train_loss: 0.2594, train_accuracy: 90.9275\n",
            "iteration: 500/500, train_loss: 0.2549, train_accuracy: 91.1160, test_loss: 0.4646, test_accuracy: 86.0600\n",
            "epoch 341/400:\n",
            "iteration: 100/500, train_loss: 0.2386, train_accuracy: 91.6600\n",
            "iteration: 200/500, train_loss: 0.2403, train_accuracy: 91.5800\n",
            "iteration: 300/500, train_loss: 0.2395, train_accuracy: 91.5500\n",
            "iteration: 400/500, train_loss: 0.2419, train_accuracy: 91.4950\n",
            "iteration: 500/500, train_loss: 0.2418, train_accuracy: 91.5480, test_loss: 0.4889, test_accuracy: 85.4900\n",
            "epoch 342/400:\n",
            "iteration: 100/500, train_loss: 0.2274, train_accuracy: 91.7800\n",
            "iteration: 200/500, train_loss: 0.2329, train_accuracy: 91.7500\n",
            "iteration: 300/500, train_loss: 0.2288, train_accuracy: 91.9367\n",
            "iteration: 400/500, train_loss: 0.2304, train_accuracy: 91.8175\n",
            "iteration: 500/500, train_loss: 0.2304, train_accuracy: 91.8260, test_loss: 0.4948, test_accuracy: 85.5400\n",
            "epoch 343/400:\n",
            "iteration: 100/500, train_loss: 0.2371, train_accuracy: 91.4800\n",
            "iteration: 200/500, train_loss: 0.2386, train_accuracy: 91.4250\n",
            "iteration: 300/500, train_loss: 0.2396, train_accuracy: 91.4400\n",
            "iteration: 400/500, train_loss: 0.2417, train_accuracy: 91.3525\n",
            "iteration: 500/500, train_loss: 0.2406, train_accuracy: 91.4420, test_loss: 0.4587, test_accuracy: 86.0600\n",
            "epoch 344/400:\n",
            "iteration: 100/500, train_loss: 0.2444, train_accuracy: 91.5100\n",
            "iteration: 200/500, train_loss: 0.2505, train_accuracy: 91.2550\n",
            "iteration: 300/500, train_loss: 0.2457, train_accuracy: 91.3200\n",
            "iteration: 400/500, train_loss: 0.2462, train_accuracy: 91.3325\n",
            "iteration: 500/500, train_loss: 0.2449, train_accuracy: 91.3880, test_loss: 0.5083, test_accuracy: 85.8300\n",
            "epoch 345/400:\n",
            "iteration: 100/500, train_loss: 0.2423, train_accuracy: 91.3100\n",
            "iteration: 200/500, train_loss: 0.2372, train_accuracy: 91.5450\n",
            "iteration: 300/500, train_loss: 0.2340, train_accuracy: 91.5833\n",
            "iteration: 400/500, train_loss: 0.2362, train_accuracy: 91.5825\n",
            "iteration: 500/500, train_loss: 0.2365, train_accuracy: 91.5980, test_loss: 0.4908, test_accuracy: 86.0000\n",
            "epoch 346/400:\n",
            "iteration: 100/500, train_loss: 0.2372, train_accuracy: 91.7300\n",
            "iteration: 200/500, train_loss: 0.2490, train_accuracy: 91.4300\n",
            "iteration: 300/500, train_loss: 0.2478, train_accuracy: 91.4300\n",
            "iteration: 400/500, train_loss: 0.2505, train_accuracy: 91.2650\n",
            "iteration: 500/500, train_loss: 0.2473, train_accuracy: 91.3920, test_loss: 0.4931, test_accuracy: 85.9700\n",
            "epoch 347/400:\n",
            "iteration: 100/500, train_loss: 0.2641, train_accuracy: 91.0100\n",
            "iteration: 200/500, train_loss: 0.2632, train_accuracy: 91.1000\n",
            "iteration: 300/500, train_loss: 0.2558, train_accuracy: 91.2300\n",
            "iteration: 400/500, train_loss: 0.2583, train_accuracy: 91.0725\n",
            "iteration: 500/500, train_loss: 0.2587, train_accuracy: 91.0700, test_loss: 0.5655, test_accuracy: 85.2100\n",
            "epoch 348/400:\n",
            "iteration: 100/500, train_loss: 0.2363, train_accuracy: 91.8700\n",
            "iteration: 200/500, train_loss: 0.2441, train_accuracy: 91.6450\n",
            "iteration: 300/500, train_loss: 0.2403, train_accuracy: 91.7033\n",
            "iteration: 400/500, train_loss: 0.2417, train_accuracy: 91.6100\n",
            "iteration: 500/500, train_loss: 0.2413, train_accuracy: 91.6080, test_loss: 0.4486, test_accuracy: 86.3100\n",
            "epoch 349/400:\n",
            "iteration: 100/500, train_loss: 0.2314, train_accuracy: 91.9200\n",
            "iteration: 200/500, train_loss: 0.2406, train_accuracy: 91.6750\n",
            "iteration: 300/500, train_loss: 0.2397, train_accuracy: 91.6400\n",
            "iteration: 400/500, train_loss: 0.2544, train_accuracy: 91.3575\n",
            "iteration: 500/500, train_loss: 0.2579, train_accuracy: 91.2520, test_loss: 0.5352, test_accuracy: 85.3300\n",
            "epoch 350/400:\n",
            "iteration: 100/500, train_loss: 0.2497, train_accuracy: 91.2800\n",
            "iteration: 200/500, train_loss: 0.2528, train_accuracy: 91.1550\n",
            "iteration: 300/500, train_loss: 0.2636, train_accuracy: 90.9633\n",
            "iteration: 400/500, train_loss: 0.2646, train_accuracy: 90.8650\n",
            "iteration: 500/500, train_loss: 0.2590, train_accuracy: 90.9840, test_loss: 0.5430, test_accuracy: 85.3000\n",
            "epoch 351/400:\n",
            "iteration: 100/500, train_loss: 0.2524, train_accuracy: 91.4700\n",
            "iteration: 200/500, train_loss: 0.2545, train_accuracy: 91.2500\n",
            "iteration: 300/500, train_loss: 0.2504, train_accuracy: 91.3067\n",
            "iteration: 400/500, train_loss: 0.2492, train_accuracy: 91.3500\n",
            "iteration: 500/500, train_loss: 0.2476, train_accuracy: 91.3860, test_loss: 0.4600, test_accuracy: 85.4200\n",
            "epoch 352/400:\n",
            "iteration: 100/500, train_loss: 0.2494, train_accuracy: 91.5600\n",
            "iteration: 200/500, train_loss: 0.2509, train_accuracy: 91.5400\n",
            "iteration: 300/500, train_loss: 0.2467, train_accuracy: 91.5267\n",
            "iteration: 400/500, train_loss: 0.2475, train_accuracy: 91.4675\n",
            "iteration: 500/500, train_loss: 0.2447, train_accuracy: 91.4720, test_loss: 0.4887, test_accuracy: 85.6500\n",
            "epoch 353/400:\n",
            "iteration: 100/500, train_loss: 0.2419, train_accuracy: 91.8700\n",
            "iteration: 200/500, train_loss: 0.2414, train_accuracy: 91.6450\n",
            "iteration: 300/500, train_loss: 0.2392, train_accuracy: 91.6233\n",
            "iteration: 400/500, train_loss: 0.2405, train_accuracy: 91.5575\n",
            "iteration: 500/500, train_loss: 0.2398, train_accuracy: 91.5580, test_loss: 0.5548, test_accuracy: 85.5600\n",
            "epoch 354/400:\n",
            "iteration: 100/500, train_loss: 0.2344, train_accuracy: 91.6800\n",
            "iteration: 200/500, train_loss: 0.2402, train_accuracy: 91.7750\n",
            "iteration: 300/500, train_loss: 0.2399, train_accuracy: 91.6333\n",
            "iteration: 400/500, train_loss: 0.2426, train_accuracy: 91.5325\n",
            "iteration: 500/500, train_loss: 0.2412, train_accuracy: 91.5320, test_loss: 0.5228, test_accuracy: 85.5600\n",
            "epoch 355/400:\n",
            "iteration: 100/500, train_loss: 0.2383, train_accuracy: 91.6100\n",
            "iteration: 200/500, train_loss: 0.2383, train_accuracy: 91.5300\n",
            "iteration: 300/500, train_loss: 0.2352, train_accuracy: 91.6867\n",
            "iteration: 400/500, train_loss: 0.2369, train_accuracy: 91.6150\n",
            "iteration: 500/500, train_loss: 0.2365, train_accuracy: 91.6120, test_loss: 0.5036, test_accuracy: 85.8000\n",
            "epoch 356/400:\n",
            "iteration: 100/500, train_loss: 0.2345, train_accuracy: 91.5800\n",
            "iteration: 200/500, train_loss: 0.2387, train_accuracy: 91.4350\n",
            "iteration: 300/500, train_loss: 0.2395, train_accuracy: 91.3967\n",
            "iteration: 400/500, train_loss: 0.2436, train_accuracy: 91.2700\n",
            "iteration: 500/500, train_loss: 0.2417, train_accuracy: 91.3540, test_loss: 0.5081, test_accuracy: 85.6200\n",
            "epoch 357/400:\n",
            "iteration: 100/500, train_loss: 0.2281, train_accuracy: 91.9900\n",
            "iteration: 200/500, train_loss: 0.2668, train_accuracy: 91.4400\n",
            "iteration: 300/500, train_loss: 0.2648, train_accuracy: 91.3033\n",
            "iteration: 400/500, train_loss: 0.2634, train_accuracy: 91.2400\n",
            "iteration: 500/500, train_loss: 0.2570, train_accuracy: 91.3220, test_loss: 0.4794, test_accuracy: 85.1900\n",
            "epoch 358/400:\n",
            "iteration: 100/500, train_loss: 0.2406, train_accuracy: 91.3900\n",
            "iteration: 200/500, train_loss: 0.2516, train_accuracy: 91.2850\n",
            "iteration: 300/500, train_loss: 0.2540, train_accuracy: 91.2433\n",
            "iteration: 400/500, train_loss: 0.2568, train_accuracy: 91.1850\n",
            "iteration: 500/500, train_loss: 0.2580, train_accuracy: 91.1820, test_loss: 0.4869, test_accuracy: 85.8300\n",
            "epoch 359/400:\n",
            "iteration: 100/500, train_loss: 0.2617, train_accuracy: 90.9300\n",
            "iteration: 200/500, train_loss: 0.2542, train_accuracy: 91.1350\n",
            "iteration: 300/500, train_loss: 0.2497, train_accuracy: 91.2933\n",
            "iteration: 400/500, train_loss: 0.2484, train_accuracy: 91.3150\n",
            "iteration: 500/500, train_loss: 0.2462, train_accuracy: 91.4300, test_loss: 0.5202, test_accuracy: 85.4000\n",
            "epoch 360/400:\n",
            "iteration: 100/500, train_loss: 0.2396, train_accuracy: 91.5600\n",
            "iteration: 200/500, train_loss: 0.2412, train_accuracy: 91.5450\n",
            "iteration: 300/500, train_loss: 0.2391, train_accuracy: 91.5967\n",
            "iteration: 400/500, train_loss: 0.2405, train_accuracy: 91.5600\n",
            "iteration: 500/500, train_loss: 0.2391, train_accuracy: 91.6000, test_loss: 0.4939, test_accuracy: 85.6000\n",
            "epoch 361/400:\n",
            "iteration: 100/500, train_loss: 0.2217, train_accuracy: 92.1100\n",
            "iteration: 200/500, train_loss: 0.2285, train_accuracy: 91.9200\n",
            "iteration: 300/500, train_loss: 0.2315, train_accuracy: 91.8300\n",
            "iteration: 400/500, train_loss: 0.2341, train_accuracy: 91.6925\n",
            "iteration: 500/500, train_loss: 0.2333, train_accuracy: 91.7260, test_loss: 0.4846, test_accuracy: 86.0900\n",
            "epoch 362/400:\n",
            "iteration: 100/500, train_loss: 0.2314, train_accuracy: 91.9700\n",
            "iteration: 200/500, train_loss: 0.2313, train_accuracy: 91.9150\n",
            "iteration: 300/500, train_loss: 0.2328, train_accuracy: 91.7533\n",
            "iteration: 400/500, train_loss: 0.2338, train_accuracy: 91.7875\n",
            "iteration: 500/500, train_loss: 0.2333, train_accuracy: 91.7960, test_loss: 0.4992, test_accuracy: 85.7800\n",
            "epoch 363/400:\n",
            "iteration: 100/500, train_loss: 0.2354, train_accuracy: 91.9200\n",
            "iteration: 200/500, train_loss: 0.2410, train_accuracy: 91.6900\n",
            "iteration: 300/500, train_loss: 0.2369, train_accuracy: 91.7200\n",
            "iteration: 400/500, train_loss: 0.2361, train_accuracy: 91.6925\n",
            "iteration: 500/500, train_loss: 0.2373, train_accuracy: 91.6880, test_loss: 0.5280, test_accuracy: 85.7100\n",
            "epoch 364/400:\n",
            "iteration: 100/500, train_loss: 0.2362, train_accuracy: 91.4300\n",
            "iteration: 200/500, train_loss: 0.2750, train_accuracy: 90.8800\n",
            "iteration: 300/500, train_loss: 0.2920, train_accuracy: 90.2200\n",
            "iteration: 400/500, train_loss: 0.2916, train_accuracy: 90.0875\n",
            "iteration: 500/500, train_loss: 0.2845, train_accuracy: 90.2540, test_loss: 0.4909, test_accuracy: 85.6500\n",
            "epoch 365/400:\n",
            "iteration: 100/500, train_loss: 0.2436, train_accuracy: 91.4100\n",
            "iteration: 200/500, train_loss: 0.2494, train_accuracy: 91.3250\n",
            "iteration: 300/500, train_loss: 0.2434, train_accuracy: 91.4400\n",
            "iteration: 400/500, train_loss: 0.2430, train_accuracy: 91.4075\n",
            "iteration: 500/500, train_loss: 0.2421, train_accuracy: 91.5020, test_loss: 0.5336, test_accuracy: 85.9900\n",
            "epoch 366/400:\n",
            "iteration: 100/500, train_loss: 0.2368, train_accuracy: 91.7400\n",
            "iteration: 200/500, train_loss: 0.2413, train_accuracy: 91.3600\n",
            "iteration: 300/500, train_loss: 0.2353, train_accuracy: 91.5300\n",
            "iteration: 400/500, train_loss: 0.2369, train_accuracy: 91.5300\n",
            "iteration: 500/500, train_loss: 0.2365, train_accuracy: 91.5300, test_loss: 0.5659, test_accuracy: 86.0100\n",
            "epoch 367/400:\n",
            "iteration: 100/500, train_loss: 0.2288, train_accuracy: 92.1200\n",
            "iteration: 200/500, train_loss: 0.2333, train_accuracy: 91.8150\n",
            "iteration: 300/500, train_loss: 0.2333, train_accuracy: 91.7600\n",
            "iteration: 400/500, train_loss: 0.2327, train_accuracy: 91.7900\n",
            "iteration: 500/500, train_loss: 0.2312, train_accuracy: 91.8180, test_loss: 0.5795, test_accuracy: 85.5300\n",
            "epoch 368/400:\n",
            "iteration: 100/500, train_loss: 0.2353, train_accuracy: 91.5800\n",
            "iteration: 200/500, train_loss: 0.2763, train_accuracy: 91.1650\n",
            "iteration: 300/500, train_loss: 0.2706, train_accuracy: 91.1300\n",
            "iteration: 400/500, train_loss: 0.2658, train_accuracy: 91.1000\n",
            "iteration: 500/500, train_loss: 0.2598, train_accuracy: 91.2180, test_loss: 0.5211, test_accuracy: 85.3200\n",
            "epoch 369/400:\n",
            "iteration: 100/500, train_loss: 0.2513, train_accuracy: 91.1700\n",
            "iteration: 200/500, train_loss: 0.2544, train_accuracy: 91.2250\n",
            "iteration: 300/500, train_loss: 0.2472, train_accuracy: 91.4100\n",
            "iteration: 400/500, train_loss: 0.2481, train_accuracy: 91.3150\n",
            "iteration: 500/500, train_loss: 0.2467, train_accuracy: 91.3580, test_loss: 0.4902, test_accuracy: 85.0800\n",
            "epoch 370/400:\n",
            "iteration: 100/500, train_loss: 0.2266, train_accuracy: 91.6900\n",
            "iteration: 200/500, train_loss: 0.2338, train_accuracy: 91.7600\n",
            "iteration: 300/500, train_loss: 0.2334, train_accuracy: 91.8167\n",
            "iteration: 400/500, train_loss: 0.2334, train_accuracy: 91.8000\n",
            "iteration: 500/500, train_loss: 0.2350, train_accuracy: 91.8600, test_loss: 0.4418, test_accuracy: 85.6900\n",
            "epoch 371/400:\n",
            "iteration: 100/500, train_loss: 0.2384, train_accuracy: 91.3200\n",
            "iteration: 200/500, train_loss: 0.2351, train_accuracy: 91.5550\n",
            "iteration: 300/500, train_loss: 0.2332, train_accuracy: 91.5733\n",
            "iteration: 400/500, train_loss: 0.2359, train_accuracy: 91.5775\n",
            "iteration: 500/500, train_loss: 0.2345, train_accuracy: 91.6940, test_loss: 0.4795, test_accuracy: 86.3200\n",
            "epoch 372/400:\n",
            "iteration: 100/500, train_loss: 0.2283, train_accuracy: 92.0500\n",
            "iteration: 200/500, train_loss: 0.2305, train_accuracy: 91.8700\n",
            "iteration: 300/500, train_loss: 0.2287, train_accuracy: 91.8200\n",
            "iteration: 400/500, train_loss: 0.2304, train_accuracy: 91.7925\n",
            "iteration: 500/500, train_loss: 0.2318, train_accuracy: 91.8080, test_loss: 0.4949, test_accuracy: 85.3500\n",
            "epoch 373/400:\n",
            "iteration: 100/500, train_loss: 0.2258, train_accuracy: 91.9800\n",
            "iteration: 200/500, train_loss: 0.2485, train_accuracy: 91.5850\n",
            "iteration: 300/500, train_loss: 0.2528, train_accuracy: 91.4833\n",
            "iteration: 400/500, train_loss: 0.2547, train_accuracy: 91.3150\n",
            "iteration: 500/500, train_loss: 0.2517, train_accuracy: 91.3640, test_loss: 0.4736, test_accuracy: 85.9400\n",
            "epoch 374/400:\n",
            "iteration: 100/500, train_loss: 0.2239, train_accuracy: 92.3100\n",
            "iteration: 200/500, train_loss: 0.2311, train_accuracy: 92.0850\n",
            "iteration: 300/500, train_loss: 0.2315, train_accuracy: 91.9467\n",
            "iteration: 400/500, train_loss: 0.2350, train_accuracy: 91.8125\n",
            "iteration: 500/500, train_loss: 0.2345, train_accuracy: 91.8220, test_loss: 0.4915, test_accuracy: 85.5100\n",
            "epoch 375/400:\n",
            "iteration: 100/500, train_loss: 0.3140, train_accuracy: 90.0100\n",
            "iteration: 200/500, train_loss: 0.3057, train_accuracy: 90.0400\n",
            "iteration: 300/500, train_loss: 0.2947, train_accuracy: 90.3033\n",
            "iteration: 400/500, train_loss: 0.2869, train_accuracy: 90.3850\n",
            "iteration: 500/500, train_loss: 0.2780, train_accuracy: 90.6320, test_loss: 0.5230, test_accuracy: 85.2500\n",
            "epoch 376/400:\n",
            "iteration: 100/500, train_loss: 0.2380, train_accuracy: 91.2700\n",
            "iteration: 200/500, train_loss: 0.2400, train_accuracy: 91.4800\n",
            "iteration: 300/500, train_loss: 0.2356, train_accuracy: 91.6100\n",
            "iteration: 400/500, train_loss: 0.2402, train_accuracy: 91.4725\n",
            "iteration: 500/500, train_loss: 0.2445, train_accuracy: 91.3880, test_loss: 0.5105, test_accuracy: 85.0400\n",
            "epoch 377/400:\n",
            "iteration: 100/500, train_loss: 0.2390, train_accuracy: 91.7100\n",
            "iteration: 200/500, train_loss: 0.2416, train_accuracy: 91.5700\n",
            "iteration: 300/500, train_loss: 0.2366, train_accuracy: 91.6567\n",
            "iteration: 400/500, train_loss: 0.2408, train_accuracy: 91.5750\n",
            "iteration: 500/500, train_loss: 0.2439, train_accuracy: 91.5180, test_loss: 0.5188, test_accuracy: 84.6200\n",
            "epoch 378/400:\n",
            "iteration: 100/500, train_loss: 0.2602, train_accuracy: 91.1200\n",
            "iteration: 200/500, train_loss: 0.2553, train_accuracy: 90.9850\n",
            "iteration: 300/500, train_loss: 0.2575, train_accuracy: 91.1033\n",
            "iteration: 400/500, train_loss: 0.2627, train_accuracy: 90.8850\n",
            "iteration: 500/500, train_loss: 0.2770, train_accuracy: 90.7020, test_loss: 0.6167, test_accuracy: 83.8800\n",
            "epoch 379/400:\n",
            "iteration: 100/500, train_loss: 0.2647, train_accuracy: 90.8100\n",
            "iteration: 200/500, train_loss: 0.2626, train_accuracy: 90.7100\n",
            "iteration: 300/500, train_loss: 0.2580, train_accuracy: 90.8467\n",
            "iteration: 400/500, train_loss: 0.2587, train_accuracy: 90.9050\n",
            "iteration: 500/500, train_loss: 0.2584, train_accuracy: 91.0000, test_loss: 0.5330, test_accuracy: 85.1400\n",
            "epoch 380/400:\n",
            "iteration: 100/500, train_loss: 0.2689, train_accuracy: 91.1900\n",
            "iteration: 200/500, train_loss: 0.2638, train_accuracy: 91.1000\n",
            "iteration: 300/500, train_loss: 0.2524, train_accuracy: 91.3000\n",
            "iteration: 400/500, train_loss: 0.2505, train_accuracy: 91.2775\n",
            "iteration: 500/500, train_loss: 0.2473, train_accuracy: 91.3760, test_loss: 0.4467, test_accuracy: 85.6500\n",
            "epoch 381/400:\n",
            "iteration: 100/500, train_loss: 0.2366, train_accuracy: 91.6000\n",
            "iteration: 200/500, train_loss: 0.2400, train_accuracy: 91.6450\n",
            "iteration: 300/500, train_loss: 0.2361, train_accuracy: 91.7733\n",
            "iteration: 400/500, train_loss: 0.2412, train_accuracy: 91.6000\n",
            "iteration: 500/500, train_loss: 0.2390, train_accuracy: 91.6120, test_loss: 0.5098, test_accuracy: 85.7600\n",
            "epoch 382/400:\n",
            "iteration: 100/500, train_loss: 0.3165, train_accuracy: 90.0800\n",
            "iteration: 200/500, train_loss: 0.3053, train_accuracy: 90.0000\n",
            "iteration: 300/500, train_loss: 0.2880, train_accuracy: 90.3733\n",
            "iteration: 400/500, train_loss: 0.2768, train_accuracy: 90.7450\n",
            "iteration: 500/500, train_loss: 0.2756, train_accuracy: 90.7960, test_loss: 0.5062, test_accuracy: 84.9800\n",
            "epoch 383/400:\n",
            "iteration: 100/500, train_loss: 0.2415, train_accuracy: 91.4200\n",
            "iteration: 200/500, train_loss: 0.2642, train_accuracy: 91.4600\n",
            "iteration: 300/500, train_loss: 0.2785, train_accuracy: 90.7667\n",
            "iteration: 400/500, train_loss: 0.2972, train_accuracy: 90.6775\n",
            "iteration: 500/500, train_loss: 0.2895, train_accuracy: 90.8340, test_loss: 0.5422, test_accuracy: 84.9700\n",
            "epoch 384/400:\n",
            "iteration: 100/500, train_loss: 0.2533, train_accuracy: 91.1000\n",
            "iteration: 200/500, train_loss: 0.2590, train_accuracy: 90.9200\n",
            "iteration: 300/500, train_loss: 0.2543, train_accuracy: 91.0967\n",
            "iteration: 400/500, train_loss: 0.2529, train_accuracy: 91.0950\n",
            "iteration: 500/500, train_loss: 0.2499, train_accuracy: 91.1820, test_loss: 0.5819, test_accuracy: 86.2500\n",
            "epoch 385/400:\n",
            "iteration: 100/500, train_loss: 0.2321, train_accuracy: 91.9100\n",
            "iteration: 200/500, train_loss: 0.2379, train_accuracy: 91.6200\n",
            "iteration: 300/500, train_loss: 0.2392, train_accuracy: 91.6167\n",
            "iteration: 400/500, train_loss: 0.2413, train_accuracy: 91.4300\n",
            "iteration: 500/500, train_loss: 0.2398, train_accuracy: 91.4840, test_loss: 0.5305, test_accuracy: 85.7000\n",
            "epoch 386/400:\n",
            "iteration: 100/500, train_loss: 0.2231, train_accuracy: 92.1500\n",
            "iteration: 200/500, train_loss: 0.2299, train_accuracy: 91.8700\n",
            "iteration: 300/500, train_loss: 0.2289, train_accuracy: 91.9400\n",
            "iteration: 400/500, train_loss: 0.2429, train_accuracy: 91.6025\n",
            "iteration: 500/500, train_loss: 0.2435, train_accuracy: 91.6220, test_loss: 0.5667, test_accuracy: 85.6400\n",
            "epoch 387/400:\n",
            "iteration: 100/500, train_loss: 0.2453, train_accuracy: 92.0100\n",
            "iteration: 200/500, train_loss: 0.2442, train_accuracy: 91.7250\n",
            "iteration: 300/500, train_loss: 0.2408, train_accuracy: 91.7400\n",
            "iteration: 400/500, train_loss: 0.2394, train_accuracy: 91.7475\n",
            "iteration: 500/500, train_loss: 0.2436, train_accuracy: 91.8180, test_loss: 0.4667, test_accuracy: 85.8500\n",
            "epoch 388/400:\n",
            "iteration: 100/500, train_loss: 0.2442, train_accuracy: 91.3100\n",
            "iteration: 200/500, train_loss: 0.2405, train_accuracy: 91.4800\n",
            "iteration: 300/500, train_loss: 0.2373, train_accuracy: 91.6067\n",
            "iteration: 400/500, train_loss: 0.2423, train_accuracy: 91.5075\n",
            "iteration: 500/500, train_loss: 0.2407, train_accuracy: 91.5220, test_loss: 0.5322, test_accuracy: 85.8400\n",
            "epoch 389/400:\n",
            "iteration: 100/500, train_loss: 0.2562, train_accuracy: 91.1600\n",
            "iteration: 200/500, train_loss: 0.2513, train_accuracy: 91.3000\n",
            "iteration: 300/500, train_loss: 0.2465, train_accuracy: 91.3533\n",
            "iteration: 400/500, train_loss: 0.2478, train_accuracy: 91.3225\n",
            "iteration: 500/500, train_loss: 0.2443, train_accuracy: 91.4340, test_loss: 0.5461, test_accuracy: 85.6900\n",
            "epoch 390/400:\n",
            "iteration: 100/500, train_loss: 0.2289, train_accuracy: 91.8900\n",
            "iteration: 200/500, train_loss: 0.2277, train_accuracy: 91.8350\n",
            "iteration: 300/500, train_loss: 0.2289, train_accuracy: 91.7967\n",
            "iteration: 400/500, train_loss: 0.2344, train_accuracy: 91.6700\n",
            "iteration: 500/500, train_loss: 0.2351, train_accuracy: 91.6320, test_loss: 0.4925, test_accuracy: 85.6700\n",
            "epoch 391/400:\n",
            "iteration: 100/500, train_loss: 0.2309, train_accuracy: 91.7900\n",
            "iteration: 200/500, train_loss: 0.2358, train_accuracy: 91.7350\n",
            "iteration: 300/500, train_loss: 0.2336, train_accuracy: 91.7200\n",
            "iteration: 400/500, train_loss: 0.2358, train_accuracy: 91.6425\n",
            "iteration: 500/500, train_loss: 0.2329, train_accuracy: 91.7340, test_loss: 0.5184, test_accuracy: 85.6400\n",
            "epoch 392/400:\n",
            "iteration: 100/500, train_loss: 0.2278, train_accuracy: 91.7500\n",
            "iteration: 200/500, train_loss: 0.2359, train_accuracy: 91.6950\n",
            "iteration: 300/500, train_loss: 0.2316, train_accuracy: 91.8067\n",
            "iteration: 400/500, train_loss: 0.2359, train_accuracy: 91.7400\n",
            "iteration: 500/500, train_loss: 0.2333, train_accuracy: 91.7880, test_loss: 0.5481, test_accuracy: 85.4200\n",
            "epoch 393/400:\n",
            "iteration: 100/500, train_loss: 0.2435, train_accuracy: 91.5100\n",
            "iteration: 200/500, train_loss: 0.2520, train_accuracy: 91.3100\n",
            "iteration: 300/500, train_loss: 0.2588, train_accuracy: 91.0733\n",
            "iteration: 400/500, train_loss: 0.2606, train_accuracy: 90.9450\n",
            "iteration: 500/500, train_loss: 0.2754, train_accuracy: 90.7600, test_loss: 0.5967, test_accuracy: 84.8500\n",
            "epoch 394/400:\n",
            "iteration: 100/500, train_loss: 0.2980, train_accuracy: 90.4900\n",
            "iteration: 200/500, train_loss: 0.2873, train_accuracy: 90.3600\n",
            "iteration: 300/500, train_loss: 0.2699, train_accuracy: 90.8067\n",
            "iteration: 400/500, train_loss: 0.2810, train_accuracy: 90.5525\n",
            "iteration: 500/500, train_loss: 0.2869, train_accuracy: 90.2700, test_loss: 0.5598, test_accuracy: 84.6400\n",
            "epoch 395/400:\n",
            "iteration: 100/500, train_loss: 0.2974, train_accuracy: 90.3000\n",
            "iteration: 200/500, train_loss: 0.2956, train_accuracy: 90.2450\n",
            "iteration: 300/500, train_loss: 0.2832, train_accuracy: 90.4567\n",
            "iteration: 400/500, train_loss: 0.2786, train_accuracy: 90.5225\n",
            "iteration: 500/500, train_loss: 0.2719, train_accuracy: 90.6880, test_loss: 0.5227, test_accuracy: 85.5300\n",
            "epoch 396/400:\n",
            "iteration: 100/500, train_loss: 0.2353, train_accuracy: 91.3300\n",
            "iteration: 200/500, train_loss: 0.2417, train_accuracy: 91.3750\n",
            "iteration: 300/500, train_loss: 0.2404, train_accuracy: 91.5567\n",
            "iteration: 400/500, train_loss: 0.2411, train_accuracy: 91.4875\n",
            "iteration: 500/500, train_loss: 0.2424, train_accuracy: 91.4920, test_loss: 0.4776, test_accuracy: 85.4100\n",
            "epoch 397/400:\n",
            "iteration: 100/500, train_loss: 0.2449, train_accuracy: 91.5000\n",
            "iteration: 200/500, train_loss: 0.2458, train_accuracy: 91.4300\n",
            "iteration: 300/500, train_loss: 0.2459, train_accuracy: 91.4367\n",
            "iteration: 400/500, train_loss: 0.2432, train_accuracy: 91.5100\n",
            "iteration: 500/500, train_loss: 0.2410, train_accuracy: 91.5700, test_loss: 0.5288, test_accuracy: 85.9500\n",
            "epoch 398/400:\n",
            "iteration: 100/500, train_loss: 0.2316, train_accuracy: 91.9300\n",
            "iteration: 200/500, train_loss: 0.2343, train_accuracy: 91.6300\n",
            "iteration: 300/500, train_loss: 0.2345, train_accuracy: 91.5767\n",
            "iteration: 400/500, train_loss: 0.2350, train_accuracy: 91.6150\n",
            "iteration: 500/500, train_loss: 0.2344, train_accuracy: 91.6920, test_loss: 0.4605, test_accuracy: 85.8900\n",
            "epoch 399/400:\n",
            "iteration: 100/500, train_loss: 0.2204, train_accuracy: 92.1600\n",
            "iteration: 200/500, train_loss: 0.2274, train_accuracy: 92.0200\n",
            "iteration: 300/500, train_loss: 0.2255, train_accuracy: 92.0733\n",
            "iteration: 400/500, train_loss: 0.2289, train_accuracy: 91.8625\n",
            "iteration: 500/500, train_loss: 0.2288, train_accuracy: 91.8400, test_loss: 0.5714, test_accuracy: 86.0900\n",
            "epoch 400/400:\n",
            "iteration: 100/500, train_loss: 0.2223, train_accuracy: 92.0500\n",
            "iteration: 200/500, train_loss: 0.2248, train_accuracy: 91.8100\n",
            "iteration: 300/500, train_loss: 0.2257, train_accuracy: 91.8233\n",
            "iteration: 400/500, train_loss: 0.2291, train_accuracy: 91.7650\n",
            "iteration: 500/500, train_loss: 0.2281, train_accuracy: 91.8320, test_loss: 0.4922, test_accuracy: 85.6400\n",
            "Model saved in file: /content/drive/model/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XoMo45a8IDd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "df7c3f94-7f3a-441f-d294-6e33e5afa4c9"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "LOG_DIR = \"/content/drive/logs/\"\n",
        "get_ipython().system_raw(\n",
        "    \"tensorboard --logdir {} --host 0.0.0.0 --port 6006 &\"\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-17 00:43:46--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.72.245.79, 52.45.84.34, 52.45.248.161, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.72.245.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  9.77MB/s    in 0.5s    \n",
            "\n",
            "2018-12-17 00:43:47 (9.77 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "http://5a787de7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}